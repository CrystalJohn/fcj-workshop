[{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Trần Phan Thanh Phúc\nSố điện thoại: 0944941764\nEmail: phuctptse183992@fpt.edu.vn\nTrường: Đại học FPT\nNgành: Kỹ thuật phần mềm\nLớp: AWS082025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 12/08/2025 đến ngày 12/11/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/4-eventparticipated/4.1-event1/","title":"Event 1","tags":[],"description":"","content":"Bài thu hoạch “BUILDING AGENTIC AI” Mục Đích Của Sự Kiện Tối ưu context với Amazon Bedrock Xây dựng các AI agent automation với Amazon Bedrock thông qua các kỹ thuật thực hành và các trường hợp sử dụng trong thế giới thực Danh Sách Diễn Giả Nguyen Gia Hung - Head of Solutions Architect, AWS Kien Nguyen - Solutions Architect, AWS Viet Pham - Founder \u0026amp; CEO, Diagflow Kha Van - Community Leader, AWS Thang Ton - Co-Founder \u0026amp; COO, Cloud Thinker Henry Bui - Head of Engineering, Cloud Thinker Nội Dung Nổi Bật Các kỹ thuật tối ưu hóa chi phí và hiệu suất cho các hệ thống AI agent Thời gian release sản phẩm lâu → Mất doanh thu/bỏ lỡ cơ hội Hoạt động kém hiệu quả → Mất năng suất, tốn kém chi phí Không tuân thủ các quy định về bảo mật → Mất an ninh, uy tín Bốn kỹ thuật \u0026ldquo;Quick Wins\u0026rdquo; để tối ưu hóa Prompt Caching (Lưu trữ bộ nhớ đệm cho Prompt) Đây là kỹ thuật quan trọng nhất được đề cập, có thể giảm 70-90% chi phí và tăng tốc độ xử lý: Cấu trúc Context: Context window được chia thành 3 phần: (1) System \u0026amp; Tool Schema, (2) Conversation History (Lịch sử hội thoại), và (3) Objective Prompt (Mục tiêu hiện tại). Sai lầm thường gặp: Đa số mọi người chỉ cache phần System Prompt và Tool. Tuy nhiên, phần Conversation History mới là phần tốn kém nhất (có thể chiếm 80-90% chi phí) và thường bị bỏ qua. Chiến lược đúng: Cần đặt \u0026ldquo;checkpoint\u0026rdquo; sao cho toàn bộ lịch sử hội thoại cũng được cache. Mặc dù lần chạy đầu tiên (cache write) tốn thêm 25% chi phí, nhưng các lần sau sẽ tiết kiệm được 90%\nContext Compaction (Nén ngữ cảnh - Summarization) Cloud Thinker đã chỉ ra 1 kỹ thuật tóm tắt (Summarization) thông minh để tránh mất cache Cách cũ: Tạo một agent mới để tóm tắt hội thoại cũ. Cách này làm mất toàn bộ cache trước đó và thường làm giảm chất lượng (performance degradation). Cách mới (Cloudthinker technique): Giữ nguyên agent và lịch sử hội thoại (để tận dụng cache đã có), chỉ thay đổi phần \u0026ldquo;Objective Prompt\u0026rdquo; thành một task mới là \u0026ldquo;hãy tóm tắt đoạn hội thoại này\u0026rdquo;. Cách này giúp tận dụng cache hit, giảm chi phí tóm tắt từ ví dụ 0.3 đô xuống còn 0.03 đô (giảm ~90%) và cải thiện chất lượng đầu ra\nTool Consolidation (Hợp nhất công cụ) Vấn đề với các giao thức mới như MCP (Model Context Protocol) là việc đưa quá nhiều công cụ (ví dụ 50 tool) vào context sẽ làm tràn bộ nhớ (context flooding). Giải pháp: Thay vì đưa toàn bộ schema (cấu trúc dữ liệu) phức tạp vào prompt, hãy sử dụng một \u0026ldquo;dictionary\u0026rdquo; đơn giản và gộp các instruction (hướng dẫn) lại. Just-in-time Instruction: Agent có thể sử dụng một lệnh đặc biệt (get instruction) để lấy hướng dẫn chi tiết về cách dùng công cụ chỉ khi cần thiết. Điều này giúp giảm số lượng token phải nạp vào input liên tục\nParallel Tool Calling (Gọi công cụ song song) Thay vì chạy tuần tự (sequential) như mô hình ReAct cũ (năm 2022), các model hiện đại cho phép chạy song song nhiều tool cùng lúc để tiết kiệm thời gian. Tuy nhiên, tính năng này thường không bật mặc định; lập trình viên cần thêm các câu lệnh instruction cụ thể (ví dụ: \u0026ldquo;maximize efficiency\u0026rdquo;) để ép model chạy song song\nNhững Gì Học Được Chiến lược quản lý chi phí Input cost: chiếm phần lớn chi phí vận hành AI agents chạy loop. Tức là mỗi vòng, Agent phải nạp lại toàn bộ context (Conversation history, system prompt, memory) Nên loop Agent chạy càng lâu thì sẽ càng đốt tiền -\u0026gt; History càng dài thì input tokens mỗi vòng càng tăng. Solution: dùng Prompt Caching và checkpointing để giảm thiểu chi phí này. Giảm cost lên đến 80-90%. Kỹ thuật \u0026ldquo;Tóm tắt\u0026rdquo; (Summarization) thông minh Summarization: Giữ nguyên agent hiện tại và lịch sử hội thoại để tận dụng cache đã có, và giữ được context quality tốt hơn. Với kỹ thuật này, chi phí tóm tắt giảm từ 0.3 đô xuống còn 0.03 đô (giảm ~90%) và chất lượng đầu ra được cải thiện. Thiết kế công cụ (Tool Design): Tránh \u0026ldquo;ngập lụt\u0026rdquo; ngữ cảnh Tool Design: Vấn đề: Quá nhiều tools được đưa vào (ví d: MCP với 50 tools) sẽ làm tràn ngữ cảnh (context flooding). Giải pháp: Tạo 1 lệnh đặc biệt để Agent tự gọi đến lấy instruction chi tiết khi cần, thay vì nhồi nhét toàn bộ schema vào prompt. Giúp context gọn nhẹ, giảm token usage và tăng hiệu suất. Tối ưu hiệu suất: Bắt buộc chạy song song (Parallel Tool Calling) Maximize Efficiency: thêm hướng dẫn cụ thể vào prompt để ép model Implement các tác vụ song song thay vì tuần tự. Trải nghiệm trong event Tham gia workshop “Building Agentic AI” là một trải nghiệm rất thú vị, nâng cao kiến thức về Agentic AI. Một số trải nghiệm nổi bật:\nHọc hỏi từ các diễn giả có chuyên môn cao Các diễn giả đến từ AWS, Cloudthinker, Diaflow đã chia sẻ best practices trong thiết kế ứng dụng hiện đại. Trải nghiệm kỹ thuật thực tế Tham gia cuộc thi Hakathon về CloudThinker sử dụng CloudThinker để tìm ra giải pháp tối ưu hệ thống về chi phí, hiệu suất. Ứng dụng công cụ hiện đại Trực tiếp tìm hiểu về CloudThinker. Một số hình ảnh khi tham gia sự kiện Tổng thể, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn giúp tôi thay đổi cách tư duy về thiết kế ứng dụng, sử dụng AI agents, tối ưu prompt để mang lại results tối ưu nhất cho workflow.\n"},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/3-blogstranslated/3.1-blog1/","title":"Xây dựng nhà khí tượng ảo bằng Amazon Bedrock Agents","tags":[],"description":"","content":"Bởi: Salman Ahmed, Ankush Goyal, Sergio Barraza, và Ravi Kumar Ngày: 11 FEB 2025\nChủ đề: Amazon Bedrock, Amazon Bedrock Agents, Amazon Cognito, AWS Amplify, AWS Lambda, Generative AI, Intermediate (200)\nGiới thiệu Việc tích hợp các khả năng generative AI đang thúc đẩy những thay đổi mang tính chuyển hóa trên nhiều ngành. Mặc dù thông tin thời tiết có thể truy cập qua nhiều kênh, các doanh nghiệp phụ thuộc nhiều vào dữ liệu khí tượng cần những giải pháp vững chắc và có khả năng mở rộng để quản lý và khai thác hiệu quả các insight quan trọng này, đồng thời giảm các quy trình thủ công. Giải pháp trong bài viết này minh họa cách xây dựng một nhà khí tượng ảo vận hành bằng AI có thể trả lời các truy vấn phức tạp liên quan đến thời tiết bằng ngôn ngữ tự nhiên. Chúng tôi sử dụng nhiều dịch vụ AWS để triển khai một giải pháp hoàn chỉnh mà bạn có thể dùng để tương tác với một API cung cấp dữ liệu thời tiết theo thời gian thực. Trong giải pháp này, chúng tôi sử dụng Amazon Bedrock Agents.\nAmazon Bedrock Agents giúp tinh giản quy trình làm việc và tự động hóa các tác vụ lặp lại. Amazon Bedrock Agents có thể kết nối an toàn tới các nguồn dữ liệu của doanh nghiệp bạn và bổ sung cho yêu cầu của người dùng bằng các phản hồi chính xác. Bạn có thể dùng Amazon Bedrock Agents để thiết kế một action schema phù hợp yêu cầu, qua đó kiểm soát được mỗi khi agent khởi tạo hành động được chỉ định. Cách tiếp cận linh hoạt này cho phép bạn tích hợp và thực thi logic nghiệp vụ trong dịch vụ backend ưa dùng, tạo nên một sự kết hợp hài hòa giữa tính năng và tính linh hoạt. Hệ thống cũng có khả năng ghi nhớ xuyên suốt tương tác, mang lại trải nghiệm được cá nhân hóa hơn cho người dùng.\nTrong bài viết này, chúng tôi giới thiệu một cách tiếp cận tinh gọn để triển khai agent dùng AI bằng cách kết hợp Amazon Bedrock Agents và một foundation model (FM). Chúng tôi hướng dẫn bạn quy trình cấu hình agent và hiện thực phần logic chuyên biệt cần thiết để nhà khí tượng ảo đưa ra các phản hồi chính xác liên quan đến thời tiết. Ngoài ra, chúng tôi còn sử dụng nhiều dịch vụ AWS, bao gồm AWS Amplify để lưu trữ front end, các hàm AWS Lambda để xử lý logic yêu cầu, Amazon Cognito để xác thực người dùng, và AWS Identity and Access Management (IAM) để kiểm soát quyền truy cập vào agent.\nTổng quan giải pháp Sơ đồ dưới đây cung cấp cái nhìn tổng thể và làm nổi bật các thành phần chính của hệ thống. Kiến trúc sử dụng Amazon Cognito để xác thực người dùng và AWS Amplify làm môi trường lưu trữ cho ứng dụng giao diện front-end.\nAmazon Bedrock Agents tiếp nhận truy vấn từ người dùng và chuyển thông tin đến các action group, mỗi nhóm này sẽ kích hoạt một Lambda function tùy chỉnh tương ứng. Mỗi action group và Lambda function xử lý một nhiệm vụ riêng biệt:\ngeo-coordinates – Xử lý thông tin tọa độ địa lý để lấy dữ liệu về một địa điểm cụ thể. weather – Thu thập thông tin thời tiết cho vị trí đã được cung cấp. date-time – Xác định ngày và giờ hiện tại theo múi thời gian phù hợp. Giải pháp tận dụng tính năng tự động mở rộng, bảo mật tích hợp và mô hình serverless của AWS để giảm thiểu chi phí vận hành trong khi vẫn đảm bảo khả năng phản hồi thời gian thực.\nCác yêu cầu tiên quyết Để triển khai đầy đủ giải pháp này, bạn cần chuẩn bị những thành phần sau:\nMột tài khoản AWS đang hoạt động. Quyền truy cập vào foundation model (FM) trong Amazon Bedrock, cụ thể là Anthropic Claude 3.5 Sonnet, tại cùng khu vực (Region) mà bạn sẽ triển khai giải pháp. Tải xuống mẫu AWS CloudFormation đi kèm từ aws-samples GitHub repository để tự động khởi tạo tài nguyên. Triển khai tài nguyên bằng AWS CloudFormation Sau khi chuẩn bị các yêu cầu tiên quyết, bạn sẽ triển khai toàn bộ tài nguyên cần thiết bằng AWS CloudFormation. Khi bạn chạy mẫu CloudFormation, hệ thống sẽ tự động tạo ra các thành phần như sau (lưu ý rằng các dịch vụ AWS sử dụng trong giải pháp này sẽ phát sinh chi phí):\nAmazon Cognito User pool: CognitoUserPoolforVirtualMeteorologistApp App client: VirtualMeteorologistApp Identity pool: cognito-identity-pool-vm AWS Lambda \u0026lt;Stack name\u0026gt;-geo-coordinates-\u0026lt;auto-generated\u0026gt; \u0026lt;Stack name\u0026gt;-weather-\u0026lt;auto-generated\u0026gt; \u0026lt;Stack name\u0026gt;-date-time-\u0026lt;auto-generated\u0026gt; Amazon Bedrock Agents Agent: virtual-meteorologist Action group (1): obtain-latitude-longitude-from-place-name Action group (2): obtain-weather-information-with-coordinates Action group (3): get-current-date-time-from-timezone Sau khi stack CloudFormation được triển khai thành công, bạn cần sao chép các giá trị từ tab Outputs trong AWS CloudFormation Console để cấu hình ứng dụng trong AWS Amplify. Các giá trị cần lưu lại bao gồm:\nAWSRegion BedrockAgentAliasId BedrockAgentId BedrockAgentName IdentityPoolId UserPoolClientId UserPoolId Triển khai ứng dụng AWS Amplify Ứng dụng giao diện người dùng được lưu trữ trong tệp AWS-Amplify-Frontend.zip có sẵn trên GitHub.\nBạn cần thực hiện các bước sau để triển khai thủ công ứng dụng:\nTải tệp mã nguồn AWS-Amplify-Frontend.zip từ kho GitHub. Sử dụng tệp .zip này để triển khai thủ công ứng dụng trong AWS Amplify. Sau khi triển khai hoàn tất, quay lại trang AWS Amplify Console và sử dụng tên miền (domain) được tạo tự động để truy cập ứng dụng web. Sử dụng Amazon Cognito để xác thực người dùng Amazon Cognito là dịch vụ quản lý danh tính (identity service) cho phép bạn xác thực (authenticate) và phân quyền (authorize) người dùng. Trong giải pháp này, chúng tôi sử dụng Amazon Cognito để xác minh danh tính người dùng trước khi họ có thể truy cập và sử dụng ứng dụng. Bên cạnh đó, chúng tôi còn sử dụng Identity Pool để cấp các thông tin xác thực tạm thời (temporary AWS credentials) cho người dùng trong quá trình họ tương tác với Amazon Bedrock API.\nSử dụng Amazon Bedrock Agents để tự động hóa các tác vụ trong ứng dụng Với Amazon Bedrock Agents, bạn có thể xây dựng và cấu hình các agent tự động trong ứng dụng của mình. Một agent giúp người dùng cuối thực hiện các hành động dựa trên dữ liệu của tổ chức và thông tin mà họ cung cấp. Các agent này điều phối toàn bộ quá trình tương tác giữa foundation models (FMs), nguồn dữ liệu, phần mềm ứng dụng và cuộc hội thoại với người dùng. Nhờ đó, hệ thống có thể hiểu và thực thi các yêu cầu phức tạp theo ngữ cảnh tự nhiên, đồng thời tự động hóa các quy trình xử lý dữ liệu một cách hiệu quả.\nSử dụng Action Group để định nghĩa các hành động mà Amazon Bedrock Agent thực hiện Một action group xác định tập hợp các hành động có liên quan mà một Amazon Bedrock Agent có thể thực hiện để hỗ trợ người dùng. Khi cấu hình một action group, bạn có nhiều lựa chọn để xử lý dữ liệu do người dùng cung cấp, bao gồm: thêm thông tin đầu vào của người dùng vào action group của agent, chuyển dữ liệu đến một AWS Lambda để xử lý logic nghiệp vụ tùy chỉnh, hoặc trả quyền điều khiển trực tiếp lại cho ứng dụng thông qua phản hồi từ phương thức InvokeAgent.\nTrong ứng dụng này, chúng tôi tạo ra ba action group giúp Amazon Bedrock Agent có thể thực hiện các chức năng cốt lõi: lấy tọa độ của địa điểm cụ thể, truy xuất ngày giờ hiện tại, và thu thập dữ liệu thời tiết tại địa điểm đó. Các nhóm hành động này cho phép agent truy cập và xử lý những thông tin quan trọng, giúp nâng cao độ chính xác và khả năng phản hồi toàn diện đối với các truy vấn liên quan đến vị trí địa lý và điều kiện thời tiết của người dùng.\nSử dụng AWS Lambda cho các Action Group của Amazon Bedrock Trong giải pháp này, ba hàm AWS Lambda được triển khai để hỗ trợ các action group mà Amazon Bedrock Agent định nghĩa:\nLocation Coordinates Lambda Function – Hàm này được kích hoạt bởi action group obtain-latitude-longitude-from-place-name. Nó nhận tên địa điểm làm đầu vào và trả về tọa độ địa lý (vĩ độ và kinh độ) tương ứng. Hàm sử dụng một dịch vụ hoặc cơ sở dữ liệu định vị (geocoding service) để tìm kiếm thông tin này. Date and Time Lambda Function – Hàm này được kích hoạt bởi action group get-current-date-time-from-timezone. Nó xác định múi giờ và trả về thông tin ngày giờ hiện tại. Weather Information Lambda Function – Hàm này được kích hoạt bởi action group obtain-weather-information-with-coordinates. Nó nhận tọa độ được cung cấp từ hàm đầu tiên và truy xuất dữ liệu thời tiết hiện tại hoặc dự báo cho khu vực tương ứng thông qua API thời tiết. Mỗi hàm Lambda nhận một sự kiện đầu vào (input event) chứa các metadata và trường dữ liệu được điền từ thao tác API của Amazon Bedrock Agent hoặc các tham số của hàm. Các hàm này xử lý dữ liệu, thực thi nhiệm vụ tương ứng và trả về phản hồi chứa thông tin cần thiết. Phản hồi đó sau đó được Amazon Bedrock Agent tổng hợp để hình thành câu trả lời hoàn chỉnh cho người dùng.\nNhờ việc sử dụng các hàm Lambda, Amazon Bedrock Agent có thể truy cập vào các nguồn dữ liệu bên ngoài và thực hiện các phép tính phức tạp, giúp tăng đáng kể năng lực của agent trong việc xử lý các yêu cầu liên quan đến vị trí, thời gian và điều kiện thời tiết.\nSử dụng AWS Amplify cho mã nguồn giao diện AWS Amplify cung cấp môi trường phát triển cho các ứng dụng web và di động an toàn, có khả năng mở rộng. Các nhà phát triển có thể tập trung vào việc viết mã thay vì quản lý cơ sở hạ tầng. Amplify còn tích hợp với nhiều nền tảng lưu trữ mã nguồn như GitHub, Bitbucket hoặc GitLab. Trong giải pháp này, chúng tôi tải thủ công mã nguồn front-end lên AWS Amplify, theo quy trình đã được mô tả trong phần trước của bài viết.\nTrải nghiệm ứng dụng Sau khi triển khai ứng dụng trong AWS Amplify, bạn có thể truy cập URL được tạo tự động để mở giao diện người dùng. Khi truy cập vào đường dẫn này, ứng dụng sẽ yêu cầu nhập các thông tin liên quan đến Amazon Cognito và Amazon Bedrock Agents. Những thông tin này cần thiết để xác thực người dùng an toàn và cho phép giao diện front-end tương tác với agent trên Bedrock. Nhờ vậy, ứng dụng có thể quản lý phiên đăng nhập (user session) và thực hiện các lệnh gọi API được ủy quyền tới các dịch vụ AWS thay mặt người dùng.\nBạn cần nhập các thông tin được lấy từ phần Outputs của CloudFormation, bao gồm:\nUser Pool ID User Pool Client ID Identity Pool ID Region Agent Name Agent ID Agent Alias ID Đăng nhập bằng tên người dùng và mật khẩu của bạn. Một mật khẩu tạm thời đã được tạo tự động trong quá trình triển khai và gửi đến email bạn đã cung cấp khi chạy mẫu CloudFormation. Ở lần đăng nhập đầu tiên, bạn sẽ được yêu cầu thay đổi mật khẩu để hoàn tất quá trình xác thực. Sau khi đăng nhập thành công, bạn có thể bắt đầu đặt câu hỏi cho ứng dụng, ví dụ:\n\u0026ldquo;Hôm nay ở Dallas, Texas có thể tổ chức tiệc nướng BBQ được không?\u0026rdquo; Chỉ trong vài giây, ứng dụng sẽ hiển thị câu trả lời chi tiết cho biết liệu hôm nay có thích hợp để tổ chức tiệc BBQ ở Dallas hay không.\nCác ví dụ truy vấn mẫu Dưới đây là một số câu hỏi minh họa khả năng hội thoại của nhà khí tượng ảo:\n\u0026ldquo;Thời tiết hôm nay ở New York City như thế nào?\u0026rdquo; \u0026ldquo;Tôi có nên lên kế hoạch tổ chức tiệc sinh nhật ngoài trời ở Miami vào cuối tuần tới không?\u0026rdquo; \u0026ldquo;Denver có tuyết rơi vào ngày Giáng sinh không?\u0026rdquo; \u0026ldquo;Hôm nay tôi có thể đi bơi ở bãi biển Chicago được không?\u0026rdquo; Những truy vấn này thể hiện cách mà agent có thể cung cấp thông tin thời tiết hiện tại, tư vấn hoạt động dựa trên dự báo, và dự đoán điều kiện thời tiết trong tương lai. Người dùng có thể hỏi những câu liên quan đến hoạt động cụ thể (như bơi lội, tiệc ngoài trời…), và hệ thống sẽ tự động phân tích điều kiện thời tiết để đưa ra khuyến nghị phù hợp.\nDọn dẹp tài nguyên Nếu bạn không còn muốn sử dụng nhà khí tượng ảo (virtual meteorologist), hãy thực hiện các bước sau để xóa ứng dụng và toàn bộ tài nguyên liên quan được triển khai bằng AWS CloudFormation và AWS Amplify:\n1. Xóa stack CloudFormation Trong AWS CloudFormation Console, chọn Stacks trong thanh điều hướng. Xác định stack mà bạn đã tạo trong quá trình triển khai (tên stack được đặt khi khởi tạo). Chọn stack đó và nhấp Delete để xóa toàn bộ tài nguyên liên quan. 2. Xóa ứng dụng Amplify và các tài nguyên đi kèm Để biết hướng dẫn chi tiết, vui lòng tham khảo phần Clean Up Resources trong tài liệu chính thức của AWS.\nKết luận Giải pháp này minh họa sức mạnh của việc kết hợp Amazon Bedrock Agents với các dịch vụ AWS khác để tạo nên một trợ lý thời tiết thông minh, có khả năng hội thoại. Thông qua việc ứng dụng AI và công nghệ điện toán đám mây, doanh nghiệp có thể tự động hóa các truy vấn phức tạp và mang đến cho người dùng các thông tin có giá trị thực tế.\nTài nguyên bổ sung Để tìm hiểu thêm về Amazon Bedrock, bạn có thể tham khảo:\nGitHub repo: Amazon Bedrock Workshop Amazon Bedrock User Guide Workshop: Using Generative AI on AWS for diverse content types Để biết thêm về mô hình Anthropic Claude 3.5 Sonnet, xem tại:\nAnthropic\u0026rsquo;s Claude in Amazon Bedrock Về các tác giả Salman Ahmed là Senior Technical Account Manager tại AWS Enterprise Support. Anh hỗ trợ các khách hàng trong ngành du lịch và khách sạn thiết kế, triển khai và vận hành hạ tầng đám mây. Với niềm đam mê về các dịch vụ mạng và nhiều năm kinh nghiệm, anh giúp khách hàng áp dụng hiệu quả các giải pháp AWS Networking. Ngoài công việc, Salman yêu thích nhiếp ảnh, du lịch và thể thao.\nSergio Barraza là Senior Enterprise Support Lead tại AWS, hỗ trợ khách hàng ngành năng lượng thiết kế và tối ưu giải pháp đám mây. Với niềm đam mê phát triển phần mềm, anh hướng dẫn khách hàng khai thác các dịch vụ AWS. Ngoài công việc, Sergio là nhạc công chơi nhiều nhạc cụ như guitar, piano, trống, và luyện tập Wing Chun Kung Fu.\nRavi Kumar là Senior Technical Account Manager tại AWS Enterprise Support, giúp khách hàng ngành du lịch và khách sạn tối ưu hóa hoạt động trên AWS. Ông có hơn 20 năm kinh nghiệm CNTT và luôn chú trọng hiệu quả vận hành. Ngoài công việc, Ravi thích hội họa, chơi cricket và khám phá các địa điểm mới.\nAnkush Goyal là Enterprise Support Lead tại AWS Enterprise Support, giúp khách hàng đơn giản hóa hoạt động đám mây. Với hơn 20 năm kinh nghiệm, anh tập trung vào việc tối ưu hóa hạ tầng và mang lại giá trị lâu dài cho doanh nghiệp.\n"},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/4-eventparticipated/4.2-event2/","title":"Event 2","tags":[],"description":"","content":"Bài thu hoạch “AWS Cloud Mastery Series #3 workshop” Mục Đích Của Sự Kiện Chia sẻ và củng cố kiến thức cốt lõi trong AWS Well-Architected Framework – Security Pillar. Trang bị tư duy và kỹ năng xây dựng hệ thống an toàn, bền vững, tuân thủ chuẩn AWS. Danh Sách Diễn Giả FCJ Team Kha Van - Cloud Security Engineer Nội Dung Nổi Bật Security Foundation – Nền tảng bảo mật AWS Least Privilege – Zero Trust – Defense in Depth: 3 nguyên tắc nền tảng cho mọi hệ thống bảo mật modern. Shared Responsibility Model: AWS bảo mật của cloud, khách hàng bảo mật trong cloud. Top Cloud Threats tại Việt Nam Public S3 / DB / Redis Lộ access key IAM cấu hình sai EC2 bị malware (mining) Thiếu logging hoặc không bật GuardDuty Pillar 1 — Identity \u0026amp; Access Management (IAM) Pillar 1 — Identity \u0026amp; Access Management (IAM) IAM Users: gần như không còn phù hợp — ưu tiên sử dụng Roles + SSO + OIDC. IAM Identity Center (SSO): dùng cho quản lý đa tài khoản (multi-account management). Quyền tổ chức: áp dụng SCP và permission boundaries để kiểm soát quyền ở mức tổ chức. Bảo mật chứng thực \u0026amp; giám sát: bắt buộc credential rotation, MFA; dùng Access Analyzer để phát hiện các policy quá rộng. Pillar 2 — Detection \u0026amp; Monitoring CloudTrail (organization level): lưu tất cả API activity để audit và điều tra sự cố. GuardDuty: phát hiện hành vi bất thường trên EC2, IAM, S3, EKS. Security Hub: tổng hợp findings từ nhiều dịch vụ vào một dashboard trung tâm. Logging sources: VPC Flow Logs, S3 access logs, ALB logs — dùng để truy vết network \u0026amp; access patterns. Alerting \u0026amp; Automation: sử dụng EventBridge để gửi cảnh báo và khởi chạy phản ứng tự động (remediation). Detection-as-Code: quản lý các rule detection như mã nguồn (IaC) để dễ review và triển khai. Case study: Nếu không có logs thì không có bằng chứng — không thể điều tra incident.\nPillar 3 — Infrastructure Protection VPC segmentation: giảm \u0026ldquo;blast radius\u0026rdquo; khi hệ thống bị tấn công bằng cách cô lập các vùng mạng. Subnet placement (Public vs Private): Public: ALB, NAT Gateway. Private: EC2 (app), Databases, internal services. Security Group (SG) vs Network ACL (NACL): SG = stateful, áp dụng ở mức instance. NACL = stateless, áp dụng ở mức subnet. Edge protection: WAF, Shield Advanced, Network Firewall cho lớp phòng thủ biên. Workload hardening: best practices cho EC2, ECS, EKS security (patching, minimal IAM, image scanning, runtime protections). Case study: Hầu hết lỗi bảo mật đến từ việc đặt sai tài nguyên vào public subnet — luôn kiểm tra placement trước khi deploy.\nPillar 4 — Data Protection Encryption everywhere: bật mã hóa cho S3, EBS, RDS, DynamoDB (at-rest). AWS KMS: Quản lý Key policies, Grants, và Rotation cho key lifecycle. Encryption layers: tách biệt encryption at-rest và in-transit (TLS/HTTPS). Secrets management: dùng Secrets Manager / Parameter Store: Secret rotation tự động. Quản lý credential theo best-practice của AWS. Data classification \u0026amp; guardrails: phân loại dữ liệu theo mức độ nhạy cảm và áp dụng guardrails (IAM, encryption, access controls). Case study: Nếu encrypt từ đầu, rủi ro data breach có thể giảm ~50%.\nPillar 5 — Incident Response (IR) AWS IR lifecycle: Prepare → Detect → Investigate → Respond → Recover.\nPlaybooks (ví dụ thực tế):\nIAM key bị compromise S3 bucket public EC2 nhiễm malware / mining Công cụ \u0026amp; kỹ thuật xử lý:\nSnapshot (EBS/instance snapshot) để lưu evidence. Isolation bằng thay đổi Security Group để ngắt kết nối instance. Evidence collection cho forensic và audit. Tự động hóa Incident Response:\nLambda – chạy remediation nhỏ, cleanup. Step Functions – điều phối quy trình IR phức tạp. EventBridge – trigger playbooks khi phát hiện sự kiện. Case study: Incident response không thể phụ thuộc hoàn toàn vào con người — cần tự động hóa càng nhiều càng tốt.\nNhững Gì Học Được Tư Duy Bảo Mật Hiện Đại Zero Trust \u0026amp; Least Privilege: ưu tiên mô hình không tin tưởng mặc định và hạn chế quyền ở mức tối thiểu. Defense in Depth: xây dựng nhiều lớp phòng thủ để giảm rủi ro khi một lớp bị vượt qua. Traceability \u0026amp; IaC: mọi thay đổi phải traceable và reproducible — triển khai hạ tầng bằng Infrastructure as Code (IaC). Không tin vào cấu hình tay: tránh cấu hình thủ công, ưu tiên mã hoá và kiểm thử. Kiến Trúc Kỹ Thuật Quan Trọng IAM\nRoles \u0026gt; Users SSO \u0026gt; local credentials OIDC \u0026gt; Access Keys Network\nPrivate-first: luôn ưu tiên đặt tài nguyên trong private placement. Security Group (SG) là \u0026ldquo;wall chính\u0026rdquo; (stateful); NACL là lớp bổ trợ (stateless). Outbound filtering quan trọng tương đương inbound filtering. Data\nEncrypt by default (S3, EBS, RDS, DynamoDB). Secret rotation theo chính sách. Zero exposure cho S3/DB — hạn chế public access. Detection\nCloudTrail ON GuardDuty ON Logging đầy đủ để phục vụ điều tra sự cố. Incident Response (IR)\nCó playbook rõ ràng. Có automation (remediation, rollback). Có rollback / snapshot cho phục hồi nhanh. Chiến Lược Hiện Đại Hóa Không làm ồ ạt → Phased approach.\nDùng multi-account architecture để giảm rủi ro.\nỨng Dụng Vào Công Việc Thiết kế IAM của dự án theo Roles + Permission Sets.\nÁp dụng VPC segmentation và “private-first design”.\nThêm GuardDuty + CloudTrail org-level cho toàn môi trường dev/prod.\nSetup Alerting \u0026amp; IR automation (EventBridge → Lambda).\nÁp dụng Secret Manager + rotation → không hard-code secret.\nTriển khai IaC (Terraform/CDK) để giảm drift.\nTrải nghiệm trong event Tham gia workshop “AWS Cloud Mastery Series #3” là một trải nghiệm rất bổ ích, giúp tôi có cái nhìn toàn diện về cách hiện đại hóa ứng dụng và cơ sở dữ liệu bằng các phương pháp và công cụ hiện đại. Một số trải nghiệm nổi bật: Học hỏi từ các diễn giả có chuyên môn cao Hiểu chi tiết cách AWS xử lý incident \u0026amp; detection thực tế. Trải nghiệm kỹ thuật thực tế Học cách phân tích policy bằng IAM Simulator. Nhìn thấy flow thực của S3 public exposure → auto-remediation. Quan sát IR automation xử lý compromised EC2. Ứng dụng công cụ hiện đại Thấy rõ vai trò của security automation \u0026amp; đa tầng. Học OIDC, cross-account guardrails, detection as code. Kết nối và tư duy Nhận ra cách doanh nghiệp lớn tổ chức bảo mật theo multi-account. Tư duy “secure by design”, không chờ đến khi bị tấn công mới sửa. Bài học rút ra Security = culture, not a feature. Cấu hình sai là nguyên nhân lớn nhất → IaC là cứu cánh. Không thể vận hành cloud an toàn nếu thiếu IAM + Logging + IR Một số hình ảnh khi tham gia sự kiện Tổng thể, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn giúp tôi hiểu rõ hơn về tư duy bảo mật hiện đại, tự động hóa quy trình bảo mật và cải thiện khả năng ứng phó sự cố trong môi trường cloud.\n"},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/4-eventparticipated/4.3-event3/","title":"Event 3","tags":[],"description":"","content":"Bài thu hoạch “AWS Cloud Mastery Series #2 workshop” Mục Đích Của Sự Kiện Trang bị tư duy DevOps hiện đại và cách áp dụng trên hệ sinh thái AWS. Hướng dẫn triển khai CI/CD, IaC, container orchestration, và monitoring đúng chuẩn AWS. Tối ưu tốc độ phát triển, chất lượng release và độ tin cậy của hệ thống. Danh Sách Diễn Giả FCJ Team Kha Van - Cloud Security Engineer AWS Developer Advocate Team Nội Dung Nổi Bật AWS DevOps Services – CI/CD Pipeline Build: tối ưu buildspec.yml (build caching \u0026amp; parallel test). Demo: pipeline end-to-end — Commit → Build → Test → Deploy → Monitor. Deployment: phải tự động hóa 100% — không click-ops (no manual deployments). Infrastructure as Code Tools: CloudFormation / Terraform / CDK — dùng để triển khai hạ tầng (CloudFormation là dịch vụ quản lý của AWS). Template anatomy (YAML): Resources → Parameters → Outputs → Mappings. CDK model: Constructs → Stacks → Apps. Hỗ trợ nhiều ngôn ngữ (TypeScript, Python, Java\u0026hellip;). Benefits: dễ reuse, dễ modular hóa, dễ test. When to choose: CloudFormation: declarative, phù hợp teams enterprise. CDK: developer-friendly, phù hợp Agile teams. “Không IaC = không DevOps.”\nContainer Services on AWS Docker fundamentals Dockerfile → Build → Image → Registry → Run container Registry: Docker Hub hoặc Amazon ECR Amazon ECR Image scanning, lifecycle policies, permissions per repository Amazon ECS Chạy container với Fargate hoặc EC2 Application Load Balancer, auto-scaling theo CPU, memory, queue length Amazon EKS Managed Kubernetes service Use cases: large-scale, multi-team, portable workloads AWS App Runner Dành cho teams muốn “deploy container như deploy Vercel” Case study: So sánh ECS, EKS, App Runner cho microservices, “Containers = scalability + portability. ECS/EKS giúp production hoạt động trơn tru.”\nMonitoring \u0026amp; Observability CloudWatch\nMetrics, Logs, Dashboards Composite alarms Custom metrics cho business KPIs AWS X-Ray\nDistributed tracing Debug latency, bottlenecks, service maps Best practices\nThiết kế alerting để tránh noise On-call workflow và runbook rõ ràng Giám sát theo Golden Signals: Latency, Traffic, Errors, Saturation “Không observability = không biết hệ thống đang chết như thế nào.”\nNhững Gì Học Được Tư Duy DevOps Hiện Đại Tập trung vào outcome, không phải tools. DORA metrics: tiêu chuẩn đo hiệu suất phần mềm. Continuous Integration → Continuous Delivery → Continuous Learning. Kiến Trúc Kỹ Thuật Quan Trọng CI/CD (AWS): CodePipeline, CodeBuild, CodeDeploy — thiết kế pipeline theo chuẩn. IaC là xương sống của automation (CloudFormation / Terraform / CDK). Containerization giúp microservices scale và di động. Observability: phát hiện lỗi nhanh, giảm MTTR bằng metrics, logs và tracing. Chiến Lược DevOps Bắt đầu từ small pipeline → mở rộng dần. Dùng blue/green và canary để giảm rủi ro khi deploy. Áp dụng IaC + GitOps cho môi trường multi-team. Ứng Dụng Vào Công Việc Xây dựng CI/CD cho các dự án backend/web (CodePipeline / CodeBuild / CodeDeploy). Đóng gói service bằng Docker và deploy lên ECS (Fargate) hoặc App Runner. Sử dụng CDK để build hạ tầng AWS thay vì thao tác thủ công trên console. Quan sát hệ thống bằng CloudWatch (dashboards, alarms, custom metrics). Thiết lập incident workflow cho dự án: alert → investigate → fix → postmortem (runbooks \u0026amp; on-call). Trải nghiệm trong event Tham gia workshop “AWS Cloud Mastery Series #2” là một trải nghiệm rất bổ ích, giúp tôi có thêm tư duy của 1 DevOps cần có. Học hỏi từ các diễn giả có chuyên môn cao Hiểu chi tiết cách AWS xử lý incident \u0026amp; detection thực tế. Trải nghiệm kỹ thuật thực tế Demo pipeline từ commit → deploy live. Demo drift detection, CDK synth/deploy. Triển khai container real-time trên ECS/ECR. Ứng dụng công cụ hiện đại CloudFormation + CDK giúp IaC rõ ràng, lặp lại được. ECR scanning tăng bảo mật. X-Ray giúp debug microservices dễ dàng. Kết nối và tư duy Hiểu rõ cách teamwork Dev/Product/DevOps phối hợp trong CI/CD pipeline. Tư duy “automate everything” ăn sâu hơn. Bài học rút ra Không có CI/CD → không có DevOps. IaC là điều kiện tiên quyết. Containers → scalability + speed. Observability → reliability. Một số hình ảnh khi tham gia sự kiện Tổng thể, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn giúp tôi thay đổi cách tư duy DevOps, tự động hóa quy trình phát triển phần mềm và cải thiện hợp tác giữa các nhóm.\n"},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/4-eventparticipated/4.4-event4/","title":"Event 4","tags":[],"description":"","content":"Bài thu hoạch “AWS Cloud Mastery Series #1 workshop” Mục Đích Của Sự Kiện Giới thiệu hệ sinh thái AI/ML/GenAI trên AWS.\nHướng dẫn triển khai ML end-to-end bằng SageMaker.\nXây dựng ứng dụng Generative AI qua Amazon Bedrock, RAG, Agents.\nLàm quen với MLOps, IaC, CICD, container workflows phục vụ AI/ML.\nXây dựng tư duy vận hành AI ở môi trường doanh nghiệp.\nDanh Sách Diễn Giả AWS AI/ML Specialist Team – AWS Vietnam AWS Solutions Architect AI/ML Community Leader in Vietnam Nội Dung Nổi Bật AWS AI/ML Services Overview Amazon SageMaker — nền tảng ML end-to-end\nData preparation: SageMaker Data Wrangler, Ground Truth (data labeling), Feature Store (quản lý feature tái sử dụng) Training \u0026amp; Tuning\nTraining jobs → autoscaling GPU/CPU Hỗ trợ distributed training Hyperparameter tuning (Auto-tuning, Bayesian Optimization) Deployment Options\nReal-time endpoint Serverless inference Multi-model endpoint Asynchronous (async) inference MLOps\nModel registry CI/CD pipelines bằng SageMaker Pipelines Monitoring drift: data drift, feature drift, model drift Live demo\nTrải nghiệm SageMaker Studio: notebook, xử lý dữ liệu, chạy training và deploy model. Generative AI with Amazon Bedrock Generative AI with Amazon Bedrock Foundation models introduced\nClaude 3.5 — strong reasoning, long context, good for coding tasks Llama 3 — open-weight, suitable for fine-tuning, cost-effective Titan — high-quality embeddings for RAG (retrieval-augmented generation) Mistral — fast, lightweight Prompt engineering techniques\nZero-shot, few-shot Chain-of-Thought Role prompting Multi-step reasoning Prompt templates Best practices\nChunking hợp lý (chunking inputs appropriately) Metadata filtering Re-ranking Apply guardrails to ensure safety and control Bedrock Agents Agents có thể tự thực thi workflow multi-step. Kích hoạt Lambda để gọi API, database và các workflow bên ngoài. Có thể thay thế logic backend trong nhiều use case (orchestration của business logic). Kết hợp chặt chẽ với EventBridge và Step Functions trong pipeline AI để điều phối và retry. CICD Workflow for Containers (ECR + ECS) Developer commit → CodeCommit CodeBuild builds the image Push image vào ECR ECS pull image để deploy (Fargate / EC2) CloudWatch giám sát logs \u0026amp; metrics CodePipeline orchestrate toàn bộ quy trình Add security (DevSecOps):\nCodeBuild validation (unit tests, static analysis) Image scanning trong ECR (vulnerability scan) Deployment policies / IAM controls để kiểm soát việc deploy → Đây là DevSecOps chuẩn AWS.\nNhững Gì Học Được Kiến thức AI/ML nền tảng, GenAI ML lifecycle Feature engineering Model deployment \u0026amp; monitoring Cost optimization cho training/inference Cách chọn Foundation Model phù hợp với use case Prompt engineering nâng cao RAG architecture cho production (retrieval-augmented generation) Build Agents để thực thi workflow tự động Kiến Trúc Kỹ Thuật Quan Trọng Kiến Trúc Kỹ Thuật Quan Trọng IaC (Infrastructure as Code): Terraform vs CloudFormation vs CDK Container inference workflow: ECS / ECR cho AI inference container Monitoring \u0026amp; Observability: giám sát AI workloads với CloudWatch + X-Ray Ứng Dụng Vào Công Việc Build chatbot doanh nghiệp với Bedrock + RAG (retrieval-augmented generation) Thiết kế kiến trúc AI end-to-end (data → ML → app) Dùng Lambda + Step Functions để điều phối RAG pipeline Dùng Terraform / CDK để xây hạ tầng GenAI Triển khai inference container qua ECS / Fargate Trải nghiệm trong event Tham gia workshop “AWS Cloud Mastery Series #1” tôi thấy rõ cách AWS triển khai AI/ML real-world, hiểu sự khác nhau ML truyền thống và GenAI, tăng tư duy thiết kế AI architecture. Học hỏi từ các diễn giả có chuyên môn cao Hiểu chi tiết cách AWS xây dựng hệ sinh thái AI/ML/GenAI toàn diện. Ứng dụng công cụ hiện đại SageMaker — SageMaker giúp làm ML end-to-end: chuẩn bị dữ liệu, training, tuning, deployment và MLOps. Bedrock — cung cấp Foundation Models (Claude, Llama, Titan) và hỗ trợ RAG + Agents để xây chatbot và workflow AI nhanh. IaC \u0026amp; DevOps — CloudFormation, CDK, Terraform, CodePipeline giúp triển khai AI/ML có kiểm soát và tự động. Data \u0026amp; ETL Tools — Glue, S3 (Data Lake), EventBridge, Step Functions hỗ trợ pipeline dữ liệu cho AI. Monitoring — CloudWatch cho giám sát AI/ML, logging và drift detection. Kết nối và tư duy Học tư duy AI system thay vì chỉ làm mô hình ML riêng lẻ. Nắm xu hướng AI/ML tại Việt Nam và cách doanh nghiệp ứng dụng. Bài học rút ra GenAI và ML truyền thống kết hợp để tạo giải pháp AI mạnh trong thực tế.\nGenAI và ML truyền thống kết hợp để tạo giải pháp AI mạnh trong thực tế.\nBedrock là nền tảng GenAI doanh nghiệp: an toàn, triển khai nhanh, không cần tự train model.\nMLOps + IaC là bắt buộc để AI chạy production ổn định.\nRAG là cách “đưa kiến thức doanh nghiệp vào mô hình” hiệu quả nhất.\nMột số hình ảnh khi tham gia sự kiện Tổng thể, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn mang đến cho tôi tư duy thiết kế hệ thống AI/ML toàn diện, từ data đến deployment và vận hành, giúp tôi tự tin hơn trong việc xây dựng các giải pháp AI thực tế cho doanh nghiệp.\n"},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/5-workshop/1-introduction/","title":"Giới thiệu","tags":[],"description":"","content":"Tuyên bố vấn đề Các hệ thống chatbot truyền thống gặp khó khăn khi không có khả năng truy cập thông tin cụ thể từ tài liệu nội bộ, dẫn đến trả lời không chính xác hoặc không liên quan. Workshop này giải quyết vấn đề bằng cách xây dựng một kiến trúc có khả năng:\nTự động hóa: Xử lý và đánh chỉ mục tài liệu PDF tự động Hỏi nội dung: Nhận truy vấn và điều hướng người dùng đến nội dung liên quan Truy xuất tài liệu: Trả lời các câu hỏi phức tạp với trích dẫn nguồn chính xác từ tài liệu Kiến trúc giải pháp Hệ thống được thiết kế theo mô hình RAG (Retrieval-Augmented Generation) kết hợp với AWS Serverless để đảm bảo khả năng mở rộng:\nFrontend Interface: Người dùng tương tác qua React Web Application\nAmazon API Gateway nhận requests từ Frontend AWS Amplify hosting với CloudFront CDN Amazon Cognito xử lý authentication Request Handling:\nApplication Load Balancer định tuyến traffic đến EC2 FastAPI Backend xử lý REST API requests Amazon SQS (FIFO) đảm bảo thứ tự xử lý documents Backend Processing:\nChatHandler: Quản lý hội thoại, lưu session vào Amazon DynamoDB RAG Service: Orchestrate vector search và LLM generation Qdrant Vector Database: Self-hosted trên EC2 cho vector search AI \u0026amp; Data Layer:\nAmazon Bedrock: Sử dụng Claude 3.5 Sonnet (LLM) và Cohere Embed Multilingual v3 (Embeddings) Amazon Textract: OCR và trích xuất text từ PDF Amazon S3: Lưu trữ documents Amazon DynamoDB: Metadata và chat history Admin Dashboard:\nReact-based interface hosted trên AWS Amplify Upload và quản lý documents Monitor processing status View chat history Architect Key Technologies Trong workshop này, bạn sẽ làm việc với các dịch vụ AWS chính sau:\nAmazon Bedrock: Trái tim của AI, cung cấp các Foundation Models (Claude, Cohere) để xử lý ngôn ngữ và sinh embeddings Amazon Textract: Xây dựng IDP pipeline để trích xuất text từ PDF documents Amazon EC2 \u0026amp; VPC: Cơ sở hạ tầng compute và network cho backend services Amazon S3: Lưu trữ documents và static assets Amazon DynamoDB: Lưu trữ metadata, chat history và document status Amazon Cognito: Authentication và user management AWS Amplify: Hosting frontend application với CI/CD tích hợp Amazon SQS: Message queue cho document processing pipeline Qdrant (Self-hosted): Vector database cho semantic search Terraform (IaC): Triển khai toàn bộ hạ tầng dưới dạng mã "},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":"Worklog được thực hiện trong 12 tuần thực tập tại First Cloud Journey, tập trung vào việc xây dựng ARC-Chatbot — một ứng dụng RAG Chatbot trên AWS.\nTuần 1: Làm quen với AWS và các dịch vụ cơ bản\nTuần 2: Làm quen với AWS VPC và thực hành lab\nTuần 3: Triển khai EC2 instance trong VPC Public/Private Subnet\nTuần 4: Triển khai ứng dụng trên Linux Instance\nTuần 5: Tìm hiểu S3, IAM và Security best practices\nTuần 6: Nghiên cứu Serverless: Lambda, API Gateway, DynamoDB\nTuần 7: Tìm hiểu Container: Docker, ECR, ECS\nTuần 8: Nghiên cứu AI/ML Services: Bedrock, Textract\nTuần 9: Thiết kế Architecture và lập kế hoạch dự án ARC-Chatbot\nTuần 10: Assessment (M0) — Setup AWS Account, Bedrock \u0026amp; Textract APIs, Architecture\nTuần 11: Setup Infrastructure (M0) \u0026amp; IDP Pipeline (M1) — S3, DynamoDB, Cognito, SQS, PDF Processing\nTuần 12: RAG Chat (M2) \u0026amp; Testing (M3) — Rate Limiting, Chat UI, Admin Dashboard\n"},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/1-worklog/1.1-week1/","title":"Worklog Tuần 1","tags":[],"description":"","content":"Mục tiêu tuần 1: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 08/08/2025 08/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 09/08/2025 09/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 10/08/2025 10/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 11/08/2025 11/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 1: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng widget, dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Thiết lập region mặc định Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n"},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/1-worklog/1.2-week2/","title":"Worklog Tuần 2","tags":[],"description":"","content":"Mục tiêu tuần 2: Hiểu được AWS VPC và Bảo Mật Làm quen với Amazon EC2 Thực hành toàn bộ các bài lab liên quan đến VPC Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Học về Virtual Private Cloud, Subnet, Elastic Network Interface, Elastic IP Address, Internet Gateway, Nat Gateway\n- Thực hành AWS Identity and Access Management (IAM) 15/09/2025 15/09/2025 https://cloudjourney.awsstudygroup.com/ 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 16/09/2025 16/09/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 17/09/2025 17/09/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tham dự sự kiện AWS Cloud Day Việt Nam 2025 18/09/2025 18/09/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + CloudWatch Monitoring \u0026amp; Alerting 19/09/2025 19/09/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 2: Thiết kế và triển khai được VPC theo tiêu chuẩn AWS Well-Architected Framework Subnet Route Table Public \u0026amp; Private Subnet Availability Zone (AZ) "},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/1-worklog/1.3-week3/","title":"Worklog Tuần 3","tags":[],"description":"","content":"Mục tiêu tuần 3: Triển khai và cấu hình EC2 instance trong VPC Public/Private Subnet Thực hành các bài lab về EC2 cơ bản như Site-to-Site VPN, CloudWatch Monitoring \u0026amp; Alerting Triển khai ứng dụng Node.js trên Amazon Linux Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Thực hành + Triển khai Hạ tầng EC2 Production-Ready + + Cách đưa file aws-keypair.pem lên EC2 22/09/2025 23/09/2025 https://cloudjourney.awsstudygroup.com/ 3 - Thực hành + Triển khai Hạ tầng EC2 Production-Ready + + Cách kết nối với EC2 Private qua bostion 23/09/2025 23/09/2025 https://cloudjourney.awsstudygroup.com/ 4 - Thiết lập AWS Systems Manager Session Manager và CloudWatch Monitoring \u0026amp; Alerting cho tài nguyên VPC 24/09/2025 24/09/2025 https://cloudjourney.awsstudygroup.com/ 5 - Thực hành + Cấu hình Site to Site VPN 25/09/2025 25/09/2025 https://cloudjourney.awsstudygroup.com/ 6 - cấu hình Virtual Private Gateway (VGW) và Customer Gateway (CGW). 26/09/2025 26/09/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 3: Triển khai được EC2 instance Thực hành các bài lab cơ bản về EC2 Kết nối được với EC2 instance qua SSH Tạo Elastic IP Address và gán vào EC2 instance Sử dụng NAT Gateway để truy cập Internet từ EC2 instance trong Private Subnet Học được cách cấu hình Site-to-site VPN giữa VPC Cloud (AWS Cloud) và VPC ASG VPN (mô phỏng On-premises) thông qua cùng 10.10.0.0/16 Bài học \u0026amp; Khó khăn: Học được cách phân biệt Public Subnet và Private Subnet.\nRoute propagation tự động cập nhật bảng định tuyến khi có thay đổi.\nKhó khăn: Lúc đầu SSH qua VSCode không được, cần chỉnh lại cấu hình Security Group.\n"},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/1-worklog/1.4-week4/","title":"Worklog Tuần 4","tags":[],"description":"","content":"Mục tiêu tuần 4: Triển khai ứng dụng trên Linux Instance Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Kiến thức cơ bản về máy chủ ảo với Amazon Elastic Compute Cloud (EC2) + Clean resource 29/09/2025 29/09/2025 https://cloudjourney.awsstudygroup.com/ 3 - Lên văn phòng - Thực hành: + Amazon EC2 cơ bản + Tạo snapshot + Xây dựng AMI optional + Truy cập khi mất keypair\n+ Cài đặt phpMyAdmin 30/09/2025 30/09/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tìm hiểu về AWS Cloud9 - Chuẩn bị với Amazon S3 01/10/2025 01/10/2025 https://cloudjourney.awsstudygroup.com/ 5 - Thực hành + Tạo S3 và thiết lập hosting static web 02/10/2025 02/10/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 03/10/2025 03/10/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 4: Hiểu được các loại EC2 instance types để lựa chọn phù hợp với workload, giúp tôi tối ưu chi phí phát triển và hiệu suất\nSử dụng instance dòng T cho workload nhẹ, như cầu CPU thấp. Sử dụng instance dòng M cho workload cân bằng giữa CPU, bộ nhớ và mạng. Sử dụng instance dòng R cho workload cần nhiều bộ nhớ. Cấu hình inbound rules trong SG:\nSSH, cổng 22 để kết nối qua PuTTY hoặc SSH client All ICMP-IPv4 cho phép ping và các thông báo lỗi ICMP All ICMP-IPv6 cho phép ping và các thông báo lỗi qua IPv6 HTTP, cổng 80 cho truy cập web không bảo mật HTTPS, cổng 443 cho truy cập web bảo mật MySQL/Aurora, cổng 3306 sử dụng cho Database MySQL Custom TCP, cổng 5000 để chạy ứng dụng Node.js Đã tạo và cấu hình VPC Linux và VPC Windows thành công.\nTạo và nhận keypair windows để bảo mật kết nối EC2 instance thông qua RDP (Remote Desktop Protocol) qua port 3389\n1gqFSE53bGQJJKeE@)u;Hsi7xOphbTqv mật khẩu root để sử dụng cấu hình Database cho Nodejs app: 123Admin\nKết nối Amazon Linux 2 bằng MobaXterm: Thay đổi cấu hình EC2 Instance Type: từ t2.micro sang t3.micro Thực hiện EC2 snapshot thành công. Đã snapshot(backup) lại dữ liệu trước khi thay đổi cấu hình. -\u0026gt; bao gồm backup dữ liệu + trạng thái EBS volume Cài đặt LAMP stack (Linux, Apache, MySQL, PHP) trên Amazon Linux 2 Cấu hình và sử dụng phpMyAdmin để quản lý cơ sở dữ liệu Cài đặt Node.js Runtime Environment Triển khai và chạy ứng dụng AWS User Management "},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/1-worklog/1.5-week5/","title":"Worklog Tuần 5","tags":[],"description":"","content":"Mục tiêu tuần 5: Dịch các bài blog AWS theo sự phân công. Tìm hiểu về Amazon RDS và các dịch vụ AWS cơ bản. Thực hành tạo và quản lý EC2 instance. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Thực hành - Dịch 3 bài blog theo sự phân công từ AWS 06/10/2025 06/10/2025 https://cloudjourney.awsstudygroup.com/ 3 - Tìm hiểu về Amazon Relational Database Service (Amazon RDS) 07/10/2025 07/10/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 08/10/2025 08/10/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 09/10/2025 09/10/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 10/10/2025 10/10/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 5: Hoàn thành dịch 3 bài blog AWS theo sự phân công. Hiểu được các khái niệm cơ bản về Amazon RDS (Relational Database Service). Tạo thành công AWS Free Tier account và cấu hình AWS CLI. Nắm vững kiến thức EC2 cơ bản: Instance types, AMI, EBS, Elastic IP. Thực hành thành công việc tạo EC2 instance, kết nối SSH và gắn EBS volume. "},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/1-worklog/1.6-week6/","title":"Worklog Tuần 6","tags":[],"description":"","content":"Mục tiêu tuần 6: Nắm được kiến thức liên quan đến Route 53 nằm trong pillar Reliability của AWS Well-Architected Framework. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với Route 53 + Định nghĩa và chức năng 13/10/2025 13/10/2025 3 - Thực hành - Thiết lập Hybrid DNS với Route 53 Resolver 14/10/2025 14/10/2025 https://cloudjourney.awsstudygroup.com/ 4 - Học về các khái niệm: + Nguyên tắc Least Privilege (chỉ cấp quyền cần thiết) + Cách hoạt động của KMS (Key Management Service) 15/10/2025 15/10/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu về Amazon DynamoDB và thực hành bài lab về DynamoDB - Học về tạo Global secondary index 16/10/2025 16/10/2025 https://000060.awsstudygroup.com/vi/1-introduce/ 6 - Thực hành: + Phát triển với Python và DynamoDB 17/10/2025 17/10/2025 https://000060.awsstudygroup.com/vi/3-gettingstartedwithawssdk/3.2-pythonandynamodb/ Kết quả đạt được tuần 6: Hiểu được cách thiết kế hệ thống DNS với Route 53 Resolver\nSử dụng AWS Quick Start để triển khai Hybrid DNS Sử dụng AWS Managed Microsoft Active Directory Kết quả thực hành: https://drive.google.com/drive/folders/1-ZtnhA9PyAjANC9loPAZApB7TQHBCAox?usp=sharing Biết được việc tạo một Global Secondary Index (GSI) trong DynamoDB có tác dụng chính là cho phép truy vấn dữ liệu nhanh chóng dựa trên các thuộc tính chứ không phải là khóa chính (PK). Thay vì sử dụng PK bằng Partition key và Sort Key để truy vấn\nPartition Key: Thuộc tính dùng để phân phối dữ liệu trên các phân vùng lưu trữ vật lý. Sort Key: Thuộc tính dùng để sắp xếp và lọc dữ liệu trong cùng một phân vùng. "},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/1-worklog/1.7-week7/","title":"Worklog Tuần 7","tags":[],"description":"","content":"Mục tiêu tuần 7: Làm quen với SageMaker Studio và thực hành workshop Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Học về Qdrant EC2 20/10/2025 20/10/2025 https://aws.amazon.com/marketplace/pp/prodview-rtphb42tydtzg 3 - Học về cách setup với Amazon Bedrock APIs 21/10/2025 21/10/2025 https://github.com/aws-samples/amazon-bedrock-samples/tree/main/introduction-to-bedrock/bedrock_apis 4 - Tạo domain SageMaker để test Amazon Bedrock trong SageMaker - Setup Bedrock và prompt với model Claude 3.5 Sonet - Cách làm việc với Amazon Bedrock APIs 22/10/2025 22/10/2025 https://cloudjourney.awsstudygroup.com/ 5 - Thực hành: Cài đặt Bedrock Claude 3.5 Sonnet Gọi API cơ bản Xử lý hàng loạt Kỹ thuật viết prompt Xử lý giới hạn tốc độ 23/10/2025 23/10/2025 https://cloudjourney.awsstudygroup.com/ 6 - Học các khái niệm: Amazon Simple Queue Service (Amazon SQS) Amazon Simple Notification Service (SNS) AWS Organizations Amazon Macie AWS Direct Connect 24/10/2025 24/10/2025 https://skillbuilder.aws/learn/94T2BEN85A/aws-cloud-practitioner-essentials/ Kết quả đạt được tuần 7: Biết được Qdrant trên EC2 chính là vector database. Với EC2 tức là bạn tự host Qdrant trên EC2.\nQdrant trên EC2 là giải pháp vector DB tự quản lý, dùng để lưu và tìm kiếm embedding (vector) trong hệ thống RAG. Nó thay thế các dịch vụ đắt tiền như OpenSearch Serverless (~$90–150/tháng).\nQdrant được dùng để\nLưu embedding từ Titan Text Embeddings v2, sau khi bạn chunk tài liệu PDF/OCR Tìm top-K vectors cho mỗi truy vấn → feed cho Claude Sonnet để RAG Thực hành tạo domain SageMaker và kiểm thử kết nối tới Amazon Bedrock\nĐã tạo được domain đơn giản trên SageMaker để thử nghiệm gọi Bedrock APIs từ môi trường notebook. Xác nhận flow: gửi prompt → nhận response từ Claude 3.5 Sonnet. Triển khai và gọi thử Amazon Bedrock APIs\nViết script mẫu để gọi API (sync/async), kiểm tra giới hạn tần suất và xử lý lỗi (retry/backoff). Thử nghiệm batch processing: gửi nhiều prompt/embedding jobs và quan sát quota/rate limits. Kiến thức bảo mật \u0026amp; hạ tầng\nTìm hiểu nhanh AWS Organizations và IAM role để quản lý tài khoản và quyền truy cập dịch vụ Bedrock/Textract. Làm quen với Amazon Macie (data classification) và ý nghĩa của Direct Connect trong kịch bản kết nối on-prem. Bài học thực tế \u0026amp; bước tiếp theo\nNắm rõ flow end-to-end: Upload PDF → SQS message → EC2 Worker (Textract → chunk → Titan Embeddings) → index vào Qdrant → RAG với Claude Sonnet. Kế hoạch tiếp theo: triển khai worker mẫu trên EC2 để tự động hoá ingest, test performance và tối ưu batch size/throughput. "},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/1-worklog/1.8-week8/","title":"Worklog Tuần 8","tags":[],"description":"","content":"Mục tiêu tuần 8: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Thực hành: Sử dụng Lambda function để tối ưu hóa chi phí cho hệ thống của bạn trên môi trường AWS 24/10/2025 24/10/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 27/10/2025 27/10/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 28/10/2025 28/10/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 29/10/2025 30/10/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 31/10/2025 31/10/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 8: Học được cách sử dụng Lambda function để tối ưu hóa chi phí cho hệ thống trên môi trường AWS. Log công việc thứ 2: https://drive.google.com/file/d/1FvJtA5q1DCmf5l2AToMHMPDEDIHK1EE-/view?usp=drive_link "},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/1-worklog/1.9-week9/","title":"Worklog Tuần 9","tags":[],"description":"","content":"Mục tiêu tuần 9: Hoàn thành tài khoản mới AWS để chuẩn bị làm project proposal. Tìm hiểu kỹ về S3 và các khái niệm liên quan. Thiết kế kiến trúc cho project nộp proposal. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Thực hành Chiến lược nhận đủ $200 credit (bài lab mentor Thịnh Nguyễn) + Tạo EC2 + Amazon Bedrock Playground + Set up AWS Budgets + Tạo Lambda Web App + Tạo RDS Database 03/11/2025 03/11/2025 https://thinhnguyen1211.github.io/fcj-first-lab/ 3 - Tìm hiểu về Amazon S3 - Access Point - Storage Class - Tìm hiểu về AWS Security Hub 04/11/2025 04/11/2025 https://www.youtube.com/watch?v=_yunukwcAwc\u0026t=2s https://www.youtube.com/watch?v=YnLo4MgOXyA 4 - Thực hành lab Serverless - Hướng dẫn viết Front-end gọi API Gateway - Làm việc với Amazon DynamoDB 05/11/2025 05/11/2025 https://000079.awsstudygroup.com/vi/ 5 - Tìm hiểu Amazon DynamoDB - Thiết kế kiến trúc cho project nộp proposal 06/11/2025 06/11/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thiết kế kiến trúc cho project nộp proposal 07/11/2025 07/11/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 9: Account AWS với credit đã bị expire dẫn đến việc tạo account mới để tiếp tục thực hành.\nKết quả thực hành: đã nhận được $200 credit. Tạo Budgets Cost để theo dõi chi phí sử dụng dịch vụ AWS. Daily Cost Monitoring Nắm được các services “nguy hiểm” cần tránh Hiểu được S3 Access Point và Storage Class.\nS3 Access Point giúp quản lý quyền truy cập dữ liệu trong S3 bucket dễ dàng hơn, đặc biệt trong môi trường có nhiều người dùng hoặc ứng dụng. Storage Class trong S3 chia vùng lưu trữ ra nhiều lớp lưu trữ khác nhau để tối ưu hóa chi phí và hiệu suất dựa trên tần suất truy cập dữ liệu. S3 Standard: Dữ liệu truy cập thường xuyên. S3 Standard-IA: Dữ liệu truy cập không thường xuyên. Nếu đưa dữ liệu truy cập thường xuyên' vào lớp này sẽ bị tính phí cao hơn cả S3 Standard. S3 Intelligent-Tiering: Tự động chuyển đổi đối tượng giữa cấp lưu trữ theo số ngày đối với object không được truy cập. S3 One Zone-IA: Dữ liệu truy cập không thường xuyên, chỉ lưu trữ trong một vùng duy nhất, không replicate. Amazon Glacier /Deep Archive: Lưu trữ dữ liệu dài hạn. Không thể GET dữ liệu trực tiếp ngay trong class này mà phải chuyển về 1 trong 4 class trên. Hiểu được AWS Backup thiết lập chính sách bảo vệ dữ liệu tự động cho các dịch vụ AWS và on-premises.\nHiểu được API RESTful và API WebSocket\nAPI RESTful sẽ tạo ra 1 kết nối mới mỗi khi có yêu cầu từ client đến server. Sau khi server phản hồi xong, kết nối sẽ đóng lại. API WebSocket sẽ duy trì kết nối mở giữa client và server, cho phép giao tiếp hai chiều liên tục mà không cần thiết lập lại kết nối cho mỗi yêu cầu. -\u0026gt; phù hợp cho các ứng dụng real-time như chat, game,\u0026hellip; Vấn đề gặp phải:\nKhi làm lab chưa hiểu về DynamoDB nên chưa thể làm và tìm hiểu về các khái niệm cơ bản của DynamoDB. "},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/3-blogstranslated/3.2-blog2/","title":"Xây dựng pipeline Apache Spark end-to-end với Amazon MWAA, Batch Processing Gateway và Amazon EMR trên EKS","tags":[],"description":"","content":"Bởi: Avinash Desireddy và Suvojit Dasgupta Ngày: 01 tháng 5 năm 2025\nChủ đề: Amazon EMR on EKS, Amazon Managed Workflows for Apache Airflow (Amazon MWAA), AWS Big Data, Cấp độ Trung cấp (200), Mã nguồn mở\nCác workload Apache Spark chạy trên Amazon EMR on EKS là nền tảng của nhiều nền tảng dữ liệu hiện đại. EMR trên EKS mang lại lợi ích bằng cách cung cấp một môi trường Spark được quản lý, tích hợp liền mạch với các dịch vụ AWS khác và các mẫu triển khai dựa trên Kubernetes hiện có của tổ chức bạn.\nCác nền tảng dữ liệu xử lý khối lượng dữ liệu quy mô lớn thường yêu cầu nhiều cụm EMR on EKS. Trong bài viết Sử dụng Batch Processing Gateway để tự động hóa quản lý công việc trong môi trường Amazon EMR on EKS đa cụm, chúng tôi đã giới thiệu Batch Processing Gateway (BPG) như một giải pháp để quản lý các workload Spark trên các cụm này. Mặc dù BPG cung cấp chức năng nền tảng để phân phối workload và hỗ trợ định tuyến cho các công việc Spark trong môi trường đa cụm, các nền tảng dữ liệu doanh nghiệp đòi hỏi các tính năng bổ sung cho một pipeline xử lý dữ liệu toàn diện.\nBài viết này chỉ ra cách nâng cao giải pháp đa cụm bằng cách tích hợp Amazon Managed Workflows for Apache Airflow (Amazon MWAA) với BPG. Bằng cách sử dụng Amazon MWAA, chúng tôi thêm vào khả năng lập lịch và điều phối công việc, cho phép bạn xây dựng một pipeline xử lý dữ liệu dựa trên Spark end-to-end toàn diện.\nTổng quan về giải pháp Hãy xem xét HealthTech Analytics, một công ty phân tích y tế quản lý hai workload xử lý dữ liệu riêng biệt. Đội ngũ Khoa học Dữ liệu Clinical Insights của họ xử lý dữ liệu nhạy cảm về kết quả bệnh nhân, yêu cầu tuân thủ HIPAA và tài nguyên chuyên dụng. Trong khi đó, đội ngũ Digital Analytics xử lý dữ liệu tương tác website với các yêu cầu linh hoạt hơn. Khi hoạt động của họ phát triển, họ đối mặt với những thách thức ngày càng tăng trong việc quản lý hiệu quả các workload đa dạng này.\nCông ty cần duy trì sự tách biệt nghiêm ngặt giữa việc xử lý thông tin sức khỏe được bảo vệ (PHI) và dữ liệu không phải PHI, đồng thời giải quyết các yêu cầu về trung tâm chi phí khác nhau. Đội ngũ Clinical Insights chạy các quy trình batch quan trọng vào cuối ngày cần tài nguyên được đảm bảo, trong khi đội ngũ Digital Analytics có thể sử dụng các spot instance được tối ưu hóa về chi phí cho các workload biến đổi của họ. Ngoài ra, các nhà khoa học dữ liệu từ cả hai đội đều yêu cầu môi trường để thử nghiệm và tạo mẫu khi cần.\nKịch bản này là một trường hợp sử dụng lý tưởng để triển khai pipeline dữ liệu bằng Amazon MWAA, BPG và nhiều cụm EMR on EKS. Giải pháp cần định tuyến các workload Spark khác nhau đến các cụm phù hợp dựa trên yêu cầu bảo mật và hồ sơ chi phí, trong khi vẫn duy trì sự cô lập và các biện pháp kiểm soát tuân thủ cần thiết. Để quản lý hiệu quả một môi trường như vậy, chúng ta cần một giải pháp duy trì sự tách biệt rõ ràng giữa các mối quan tâm về quản lý ứng dụng và cơ sở hạ tầng, và kết nối nhiều thành phần lại với nhau thành một pipeline mạnh mẽ.\nGiải pháp của chúng tôi bao gồm việc tích hợp Amazon MWAA với BPG thông qua một Airflow custom operator cho BPG được gọi là BPGOperator. Operator này đóng gói logic quản lý cơ sở hạ tầng cần thiết để tương tác với BPG. BPGOperator cung cấp một giao diện rõ ràng để gửi công việc thông qua Amazon MWAA. Khi được thực thi, operator giao tiếp với BPG, sau đó BPG sẽ định tuyến các workload Spark đến các cụm EMR on EKS có sẵn dựa trên các quy tắc định tuyến được xác định trước.\nSơ đồ kiến trúc sau đây minh họa các thành phần và sự tương tác của chúng.\nGiải pháp hoạt động qua các bước sau:\nAmazon MWAA thực thi các DAGs đã được lập lịch bằng BPGOperator. Các kỹ sư dữ liệu tạo DAG bằng operator này, chỉ yêu cầu tệp cấu hình ứng dụng Spark và các tham số lập lịch cơ bản. BPGOperator xác thực và gửi công việc đến endpoint của BPG POST:/apiv2/spark. Nó xử lý tất cả các chi tiết giao tiếp HTTP, quản lý token xác thực và cung cấp việc truyền tải an toàn các cấu hình công việc. BPG định tuyến các công việc đã gửi đến các cụm EMR on EKS dựa trên các quy tắc định tuyến được xác định trước. Các quy tắc này được quản lý tập trung thông qua cấu hình của BPG, cho phép phân phối workload dựa trên quy tắc trên nhiều cụm. BPGOperator giám sát trạng thái công việc, ghi lại log và xử lý việc thử lại thực thi. Nó thăm dò endpoint trạng thái công việc của BPG GET:/apiv2/spark/{subID}/status và truyền log đến Airflow bằng cách thăm dò endpoint GET:/apiv2/log mỗi giây. Endpoint log của BPG lấy thông tin log mới nhất trực tiếp từ Spark Driver Pod. Việc thực thi DAG tiến tới các task tiếp theo dựa trên trạng thái hoàn thành của công việc và các phụ thuộc đã xác định. BPGOperator truyền đạt trạng thái công việc thông qua hệ thống giao tiếp task tích hợp của Airflow, cho phép điều phối workflow phức tạp. Tham khảo tài liệu giao diện REST API của BPG để biết thêm chi tiết.\nKiến trúc này cung cấp một số lợi ích chính:\nTách biệt trách nhiệm – Các đội Kỹ thuật Dữ liệu và Kỹ thuật Nền tảng trong các tổ chức doanh nghiệp thường duy trì các trách nhiệm riêng biệt. Thiết kế mô-đun trong giải pháp này cho phép các kỹ sư nền tảng cấu hình BPGOperator và quản lý các cụm EMR on EKS, trong khi các kỹ sư dữ liệu duy trì DAGs. Quản lý mã nguồn tập trung – BPGOperator đóng gói tất cả các chức năng cốt lõi cần thiết để các DAG của Amazon MWAA gửi công việc Spark thông qua BPG vào một mô-đun Python duy nhất, có thể tái sử dụng. Việc tập trung này giảm thiểu sự trùng lặp mã nguồn giữa các DAG và cải thiện khả năng bảo trì bằng cách cung cấp một giao diện chuẩn hóa để gửi công việc. Airflow custom operator cho BPG Một Operator trong Airflow là một mẫu cho một Task được xác định trước mà bạn có thể định nghĩa một cách khai báo bên trong DAG của mình. Airflow cung cấp nhiều operator tích hợp sẵn như BashOperator để thực thi các lệnh bash, PythonOperator để thực thi các hàm Python, và EmrContainerOperator để gửi công việc mới đến một cụm EMR on EKS. Tuy nhiên, không có operator tích hợp nào để thực hiện tất cả các bước cần thiết cho việc tích hợp Amazon MWAA với BPG.\nAirflow cho phép bạn tạo các operator mới để phù hợp với yêu cầu cụ thể của mình. Loại operator này được gọi là custom operator. Một custom operator đóng gói logic liên quan đến cơ sở hạ tầng tùy chỉnh vào một thành phần duy nhất, có thể bảo trì. Custom operator được tạo bằng cách mở rộng lớp airflow.models.baseoperator.BaseOperator. Chúng tôi đã phát triển và mã nguồn mở một Airflow custom operator cho BPG có tên là BPGOperator, thực hiện các bước cần thiết để cung cấp sự tích hợp liền mạch của Amazon MWAA với BPG.\nSơ đồ lớp sau đây cung cấp một cái nhìn chi tiết về việc triển khai BPGOperator.\nKhi một DAG bao gồm một task BPGOperator, instance của Amazon MWAA sẽ kích hoạt operator để gửi một yêu cầu công việc đến BPG. Operator thường thực hiện các bước sau:\nKhởi tạo công việc – BPGOperator chuẩn bị payload của công việc, bao gồm các tham số đầu vào, cấu hình, chi tiết kết nối và các siêu dữ liệu khác mà BPG yêu cầu. Gửi công việc – BPGOperator xử lý các yêu cầu HTTP POST để gửi công việc đến các endpoint của BPG với các cấu hình đã cung cấp. Giám sát thực thi công việc – BPGOperator kiểm tra trạng thái công việc, thăm dò BPG cho đến khi công việc hoàn thành thành công hoặc thất bại. Quá trình giám sát bao gồm xử lý các trạng thái công việc khác nhau, quản lý các kịch bản timeout và phản ứng với các lỗi xảy ra trong quá trình thực thi công việc. Xử lý hoàn thành công việc – Khi hoàn thành, BPGOperator ghi lại kết quả của công việc, log các chi tiết liên quan và có thể kích hoạt các task sau đó dựa trên kết quả thực thi. Sơ đồ tuần tự sau đây minh họa luồng tương tác giữa Airflow DAG, BPGOperator và BPG.\nTriển khai giải pháp Trong phần còn lại của bài viết này, bạn sẽ triển khai pipeline end-to-end để chạy các công việc Spark trên nhiều cụm EMR on EKS. Bạn sẽ bắt đầu bằng cách triển khai các thành phần chung làm nền tảng để xây dựng các pipeline. Tiếp theo, bạn sẽ triển khai và cấu hình BPG trên một cụm EKS, sau đó là triển khai và cấu hình BPGOperator trên Amazon MWAA. Cuối cùng, bạn sẽ thực thi các công việc Spark trên nhiều cụm EMR on EKS từ Amazon MWAA.\nĐể hợp lý hóa quá trình cài đặt, chúng tôi đã tự động hóa việc triển khai tất cả các thành phần cơ sở hạ tầng cần thiết cho bài viết này, vì vậy bạn có thể tập trung vào các khía cạnh thiết yếu của việc gửi công việc để xây dựng một pipeline end-to-end. Chúng tôi cung cấp thông tin chi tiết để giúp bạn hiểu từng bước, đơn giản hóa việc thiết lập trong khi vẫn giữ được trải nghiệm học hỏi.\nĐể trình diễn giải pháp, bạn sẽ tạo ba cụm và một môi trường Amazon MWAA:\nHai cụm EMR on EKS: analytics-cluster và datascience-cluster Một cụm EKS: gateway-cluster Một môi trường Amazon MWAA: airflow-environment analytics-cluster và datascience-cluster đóng vai trò là các cụm xử lý dữ liệu chạy các workload Spark, gateway-cluster lưu trữ BPG, và airflow-environment lưu trữ Airflow để điều phối và lập lịch công việc.\nBạn có thể tìm mã nguồn trong kho lưu trữ GitHub.\nĐiều kiện tiên quyết Trước khi triển khai giải pháp này, hãy đảm bảo rằng các điều kiện tiên quyết sau đã được đáp ứng:\nQuyền truy cập vào một tài khoản AWS hợp lệ AWS Command Line Interface (AWS CLI) được cài đặt trên máy cục bộ của bạn Các tiện ích Git, Docker, eksctl, kubectl, Helm, và jq được cài đặt trên máy cục bộ của bạn Quyền tạo tài nguyên AWS Quen thuộc với Kubernetes, Amazon MWAA, Apache Spark, Amazon Elastic Kubernetes Service (Amazon EKS), và Amazon EMR on EKS Cài đặt cơ sở hạ tầng chung Bước này xử lý việc cài đặt cơ sở hạ tầng mạng, bao gồm virtual private cloud (VPC) và subnets, cùng với việc cấu hình các vai trò AWS Identity and Access Management (IAM), lưu trữ Amazon Simple Storage Service (Amazon S3), kho lưu trữ Amazon Elastic Container Registry (Amazon ECR) cho các image BPG, cơ sở dữ liệu Amazon Aurora PostgreSQL-Compatible Edition, môi trường Amazon MWAA, và cả cụm EKS và EMR on EKS với một Spark operator được cấu hình sẵn. Với cơ sở hạ tầng này được cấp phát tự động, bạn có thể tập trung vào các bước tiếp theo mà không bị vướng vào các tác vụ cài đặt cơ bản.\nClone kho lưu trữ về máy cục bộ của bạn và đặt hai biến môi trường. Thay thế \u0026lt;AWS_REGION\u0026gt; bằng Vùng AWS nơi bạn muốn triển khai các tài nguyên này.\ngit clone https://github.com/aws-samples/sample-mwaa-bpg-emr-on-eks-spark-pipeline.git cd sample-mwaa-bpg-emr-on-eks-spark-pipeline export REPO_DIR=$(pwd) export AWS_REGION=\u0026lt;AWS_REGION\u0026gt; Thực thi script sau để tạo cơ sở hạ tầng chung:\ncd ${REPO_DIR}/infra ./setup.sh Để xác minh việc triển khai cơ sở hạ tầng thành công, hãy điều hướng đến bảng điều khiển AWS CloudFormation, mở stack của bạn và kiểm tra các tab Events, Resources, và Outputs để xem trạng thái hoàn thành, chi tiết và danh sách các tài nguyên đã tạo.\nBạn đã hoàn thành việc thiết lập các thành phần chung làm nền tảng cho phần còn lại của việc triển khai.\nCài đặt Batch Processing Gateway Phần này xây dựng image Docker cho BPG, triển khai helm chart trên cụm EKS gateway-cluster, và phơi bày endpoint của BPG bằng cách sử dụng service Kubernetes loại LoadBalancer. Hoàn thành các bước sau:\nTriển khai BPG trên cụm EKS gateway-cluster: cd ${REPO_DIR}/infra/bpg ./configure_bpg.sh Xác minh việc triển khai bằng cách liệt kê các pod và xem log của pod: kubectl get pods --namespace bpg kubectl logs \u0026lt;BPG-PODNAME\u0026gt; --namespace bpg Xem lại các log và xác nhận không có lỗi hoặc ngoại lệ.\nExec vào pod BPG và xác minh health check: kubectl exec -it \u0026lt;BPG-PODNAME\u0026gt; -n bpg -- bash curl -u admin:admin localhost:8080/skatev2/healthcheck/status API healthcheck sẽ trả về phản hồi thành công là {\u0026quot;status\u0026quot;:\u0026quot;OK\u0026quot;}, xác nhận việc triển khai BPG thành công trên cụm EKS gateway-cluster.\nChúng ta đã cấu hình thành công BPG trên gateway-cluster và thiết lập EMR on EKS cho cả datascience-cluster và analytics-cluster. Đây là điểm chúng ta đã dừng lại trong bài blog trước. Trong các bước tiếp theo, chúng ta sẽ cấu hình Amazon MWAA với BPGOperator, sau đó viết và gửi DAG để minh họa một pipeline dữ liệu dựa trên Spark end-to-end.\nCấu hình Airflow operator cho BPG trên Amazon MWAA Phần này cấu hình plugin BPGOperator trên môi trường Amazon MWAA airflow-environment.\nCấu hình BPGOperator trên Amazon MWAA: cd ${REPO_DIR}/bpg_operator ./configure_bpg_operator.sh Trên bảng điều khiển Amazon MWAA, điều hướng đến môi trường airflow-environment. Chọn Open Airflow UI, và trong giao diện Airflow, chọn menu thả xuống Admin và chọn Plugins. Bạn sẽ thấy plugin BPGOperator được liệt kê trong giao diện Airflow. Cấu hình Airflow connections cho tích hợp BPG Phần này hướng dẫn bạn thiết lập các Airflow connection cho phép giao tiếp an toàn giữa môi trường Amazon MWAA và BPG. BPGOperator sử dụng connection đã cấu hình để xác thực và tương tác với các endpoint của BPG.\nThực thi script sau để cấu hình Airflow connection bpg_connection:\ncd $REPO_DIR/airflow ./configure_connections.sh Trong giao diện Airflow, chọn menu thả xuống Admin và chọn Connections. Bạn sẽ thấy bpg_connection được liệt kê.\nCấu hình Airflow DAG để thực thi các công việc Spark Bước này cấu hình một Airflow DAG để chạy một ứng dụng mẫu. Cụ thể, chúng tôi sẽ gửi một DAG chứa nhiều công việc Spark mẫu bằng Amazon MWAA đến các cụm EMR on EKS sử dụng BPG. Vui lòng đợi vài phút để DAG xuất hiện trong giao diện Airflow.\ncd $REPO_DIR/jobs ./configure_job.sh Kích hoạt Amazon MWAA DAG Trong bước này, chúng tôi kích hoạt Airflow DAG và quan sát hành vi thực thi công việc, bao gồm cả việc xem lại log Spark trong giao diện Airflow:\nTrong giao diện Airflow, xem lại DAG MWAASparkPipelineDemoJob và chọn biểu tượng play để kích hoạt DAG. Đợi DAG hoàn thành thành công. Khi DAG hoàn thành thành công, bạn sẽ thấy Success:1 dưới cột Runs. Trong giao diện Airflow, tìm và chọn DAG MWAASparkPipelineDemoJob. Trên tab Graph, chọn bất kỳ task nào (ví dụ, chúng tôi chọn task calculate_pi) và sau đó chọn Logs. Xem log Spark trong giao diện Airflow. Di chuyển các DAG Airflow hiện có để sử dụng BPG Trong các nền tảng dữ liệu doanh nghiệp, một pipeline dữ liệu điển hình bao gồm Amazon MWAA gửi các công việc Spark đến nhiều cụm EMR on EKS bằng cách sử dụng SparkKubernetesOperator và một Airflow Connection loại Kubernetes. Một Airflow Connection là một tập hợp các tham số và thông tin xác thực được sử dụng để thiết lập giao tiếp giữa Amazon MWAA và các hệ thống hoặc dịch vụ bên ngoài. Một DAG tham chiếu đến tên connection và kết nối đến hệ thống bên ngoài.\nSơ đồ sau đây cho thấy kiến trúc điển hình.\nTrong thiết lập này, các DAG Airflow thường sử dụng SparkKubernetesOperator và SparkKubernetesSensor để gửi công việc Spark đến một cụm EMR on EKS từ xa bằng cách sử dụng kubernetes_conn_id=\u0026lt;connection_name\u0026gt;.\n# Gửi công việc Spark-Pi bằng Kubernetes connection submit_spark_pi = SparkKubernetesOperator( task_id=\u0026#39;submit_spark_pi\u0026#39;, namespace=\u0026#39;default\u0026#39;, application_file=spark_pi_yaml, kubernetes_conn_id=\u0026#39;emr_on_eks_connection_[1|2]\u0026#39;, # Connection ID được định nghĩa trong Airflow dag=dag) Để di chuyển cơ sở hạ tầng sang cơ sở hạ tầng dựa trên BPG mà không ảnh hưởng đến tính liên tục của môi trường, chúng ta có thể triển khai một cơ sở hạ tầng song song sử dụng BPG, tạo một Airflow Connection mới cho BPG, và di chuyển dần các DAG để sử dụng connection mới. Bằng cách làm như vậy, chúng ta sẽ không làm gián đoạn cơ sở hạ tầng hiện có cho đến khi cơ sở hạ tầng dựa trên BPG hoàn toàn hoạt động, bao gồm cả việc di chuyển tất cả các DAG hiện có.\nSơ đồ sau đây giới thiệu trạng thái tạm thời nơi cả kết nối Kubernetes và kết nối BPG đều hoạt động. Mũi tên màu xanh chỉ ra các đường dẫn workflow hiện có, và mũi tên màu đỏ đại diện cho các đường dẫn di chuyển mới dựa trên BPG.\nĐoạn mã được sửa đổi cho DAG như sau:\n# Gửi công việc Spark-Pi bằng BPG connection submit_spark_pi = BPGOperator( task_id=\u0026#39;submit_spark_pi\u0026#39;, application_file=spark_pi_yaml, application_file_type=\u0026#39;yaml\u0026#39;, connection_id=\u0026#39;bpg_connection\u0026#39;, # Connection ID được định nghĩa trong Airflow dag=dag) Cuối cùng, khi tất cả các DAG đã được sửa đổi để sử dụng BPGOperator thay vì SparkKubernetesOperator, bạn có thể ngừng hoạt động bất kỳ tàn dư nào của workflow cũ. Trạng thái cuối cùng của cơ sở hạ tầng sẽ trông giống như sơ đồ sau.\nSử dụng phương pháp này, chúng ta có thể tích hợp BPG một cách liền mạch vào một môi trường hiện chỉ sử dụng Amazon MWAA và các cụm EMR on EKS.\nDọn dẹp Để tránh phát sinh các khoản phí trong tương lai từ các tài nguyên được tạo trong hướng dẫn này, hãy dọn dẹp môi trường của bạn sau khi đã hoàn thành các bước. Bạn có thể làm điều này bằng cách chạy script cleanup.sh, script này sẽ xóa an toàn tất cả các tài nguyên đã được cấp phát trong quá trình thiết lập:\ncd ${REPO_DIR}/setup ./cleanup.sh Kết luận Trong bài viết Sử dụng Batch Processing Gateway để tự động hóa quản lý công việc trong môi trường Amazon EMR on EKS đa cụm, chúng tôi đã giới thiệu Batch Processing Gateway như một giải pháp để định tuyến các workload Spark trên nhiều cụm EMR on EKS. Trong bài viết này, chúng tôi đã chứng minh cách nâng cao nền tảng này bằng cách tích hợp BPG với Amazon MWAA. Thông qua BPGOperator tùy chỉnh của chúng tôi, chúng tôi đã chỉ ra cách xây dựng các pipeline xử lý dữ liệu dựa trên Spark end-to-end mạnh mẽ trong khi vẫn duy trì sự tách biệt rõ ràng về trách nhiệm và quản lý mã nguồn tập trung. Cuối cùng, chúng tôi đã chứng minh cách tích hợp liền mạch giải pháp vào nền tảng dữ liệu Amazon MWAA và EMR on EKS hiện có của bạn mà không ảnh hưởng đến tính liên tục hoạt động.\nChúng tôi khuyến khích bạn thử nghiệm kiến trúc này trong môi trường của riêng mình, điều chỉnh nó để phù hợp với các workload và yêu cầu hoạt động độc đáo của bạn. Bằng cách triển khai giải pháp này, bạn có thể xây dựng các pipeline xử lý dữ liệu hiệu quả và có khả năng mở rộng, tận dụng toàn bộ tiềm năng của EMR on EKS và Amazon MWAA. Hãy khám phá thêm bằng cách triển khai giải pháp trong tài khoản AWS của bạn trong khi tuân thủ các phương pháp bảo mật tốt nhất của tổ chức và chia sẻ kinh nghiệm của bạn với cộng đồng Dữ liệu lớn của AWS.\nVề các tác giả Suvojit Dasgupta là một Kiến trúc sư Dữ liệu Chính tại AWS. Anh dẫn dắt một đội ngũ kỹ sư lành nghề trong việc thiết kế và xây dựng các giải pháp dữ liệu có khả năng mở rộng cho khách hàng của AWS. Anh chuyên phát triển và triển khai các kiến trúc dữ liệu sáng tạo để giải quyết các thách thức kinh doanh phức tạp.\nAvinash Desireddy là một Kiến trúc sư Cơ sở hạ tầng Đám mây tại AWS, đam mê xây dựng các ứng dụng và nền tảng dữ liệu an toàn. Anh có kinh nghiệm sâu rộng về Kubernetes, DevOps và kiến trúc doanh nghiệp, giúp khách hàng container hóa ứng dụng, hợp lý hóa việc triển khai và tối ưu hóa môi trường cloud-native.\n"},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/2-proposal/","title":"Bản đề xuất","tags":[],"description":"","content":"Academic Research Chatbot Giải pháp AWS RAG-based hỗ trợ học thuật và nghiên cứu học tập thông minh 1. Tóm tắt điều hành Academic Research Chatbot là trợ lý AI hỗ trợ nghiên cứu học thuật, giúp sinh viên và giảng viên tra cứu, tóm tắt và phân tích tài liệu khoa học (PDF, bài báo) thông qua hội thoại tự nhiên có trích dẫn nguồn chính xác.\nĐiểm nổi bật của giải pháp:\nCông nghệ lõi: Kết hợp IDP (Amazon Textract) để xử lý tài liệu (kể cả bản scan) và RAG (Amazon Bedrock - Claude 3.5 Sonnet) để sinh câu trả lời thông minh. Kiến trúc tối ưu: Mô hình Hybrid sử dụng 1 EC2 t3.small kết hợp các dịch vụ Serverless (Amplify, Cognito, S3, DynamoDB) để cân bằng hiệu năng và chi phí. Tính khả thi: Phục vụ ~50 người dùng nội bộ với chi phí vận hành ~60 USD/tháng, thời gian triển khai nhanh (20 ngày) và tận dụng tối đa AWS Free Tier. 2. Tuyên bố vấn đề Vấn đề hiện tại Sinh viên và researcher phải làm việc với số lượng lớn tài liệu học thuật (paper hội nghị, journal, luận văn, báo cáo kỹ thuật). Nhiều tài liệu là scan PDF cũ (trước năm 2000), không có text layer, khiến việc tìm kiếm nội dung, số liệu, bảng biểu rất tốn thời gian. Các công cụ AI công cộng (ChatGPT, Perplexity, NotebookLM, v.v.) không được kết nối trực tiếp với kho tài liệu nội bộ của trường/khoa, khó đảm bảo bảo mật và quyền truy cập theo môn học hoặc nhóm nghiên cứu. Hạ tầng hiện tại không có một điểm truy cập thống nhất để:\nQuản lý tài liệu nghiên cứu theo bộ môn/đề tài. Cho phép researcher đặt câu hỏi trực tiếp trên chính các paper của mình. Đảm bảo câu trả lời có trích dẫn rõ ràng (paper, trang, bảng, mục). Hệ quả: nghiên cứu viên phải đọc thủ công, note tay, copy số liệu từ nhiều paper; giảng viên khó tổng hợp nhanh thông tin khi chuẩn bị bài giảng hoặc đề tài; dữ liệu học thuật phân tán trên nhiều máy cá nhân, khó chuẩn hóa và tái sử dụng. Giải pháp Academic Research Chatbot đề xuất xây dựng một nền tảng hỏi – đáp học thuật nội bộ dựa trên AWS, nơi:\nDev/Admin nạp kho tài liệu nghiên cứu: Upload PDF vào Amazon S3, metadata được lưu trong Amazon DynamoDB. Một EC2 worker tiêu thụ hàng đợi Amazon SQS, gọi Amazon Textract để OCR, trích xuất text, bảng, biểu mẫu, kể cả tài liệu scan. Worker chuẩn hóa/chunk nội dung, gửi sang Amazon Bedrock Titan Text Embeddings v2 để sinh embedding, và index vào Qdrant trên EC2. Researchers đặt câu hỏi qua giao diện web (Amplify + CloudFront): Câu hỏi được embed, truy vấn Qdrant để lấy các đoạn liên quan nhất (Retrieval). Các đoạn này được chuyển vào Claude 3.5 Sonnet trên Amazon Bedrock để sinh câu trả lời có citation chính xác (paper, page, section, table) và giải thích theo ngữ cảnh học thuật. Toàn bộ truy cập được bảo vệ bởi Amazon Cognito (phân quyền researcher vs admin), log \u0026amp; metric được giám sát qua Amazon CloudWatch + SNS (cảnh báo khi có lỗi worker, queue backlog, CPU EC2 cao). Lợi ích và hoàn vốn đầu tư (ROI) Hiệu quả học thuật:\nGiảm 40–60% thời gian researcher phải bỏ ra để tìm số liệu, F1-score, p-value, sample size, thiết bị thí nghiệm hoặc mô tả phương pháp từ nhiều paper khác nhau. Giảm sai sót khi trích dẫn do quên trang/bảng, vì chatbot luôn trả kèm nguồn và vị trí. Quản lý tri thức nội bộ: Tài liệu nghiên cứu được tập trung về một kho S3 + DynamoDB, dễ backup, phân quyền, và mở rộng. Có thể tái sử dụng cho nhiều khoá học, đề tài và lab khác nhau mà không phải xây hệ thống mới. Chi phí hạ tầng thấp \u0026amp; dễ kiểm soát: Mô hình hybrid 1 EC2 + managed AI services giúp chi phí vận hành cho 50 users nội bộ giữ ở mức khoảng \u0026lt; 50 USD/tháng, chủ yếu trả cho EC2, 2–3 VPC endpoint interface và phần sử dụng Bedrock/Textract. Hệ thống được thiết kế để triển khai trong khoảng 20 ngày bởi team 4 người, phù hợp làm dự án nghiên cứu/thực tập nhưng vẫn có chất lượng kiến trúc sản phẩm. Giá trị dài hạn: Tạo nền tảng để sau này tích hợp thêm dashboard phân tích hành vi học tập, module recommend paper, hoặc mở rộng sang trợ lý học tập đa ngôn ngữ và đa lĩnh vực. 3. Kiến trúc giải pháp Academic Research Chatbot áp dụng mô hình AWS Hybrid RAG Architecture với IDP (Intelligent Document Processing), kết hợp một EC2 duy nhất (FastAPI + Qdrant + Worker) với các dịch vụ AI managed (Textract, Bedrock) để vừa tối ưu chi phí, vừa đảm bảo hiệu năng cho khoảng 50 người dùng nội bộ.\nLuồng xử lý dữ liệu và hội thoại\nDịch vụ AWS sử dụng\nFrontend: Route 53, CloudFront, Amplify (DNS, CDN, Host React App). Auth: Cognito (Xác thực \u0026amp; phân quyền researcher/admin). Compute: EC2 t3.small (FastAPI + Qdrant + Worker). AI/ML: Bedrock (Claude 3.5 Sonnet, Titan Embeddings v2). IDP: Textract (OCR cho PDF scan). Storage: S3, DynamoDB (File PDF gốc + Metadata/Status). Queue: SQS (Hàng đợi xử lý tài liệu). Network: VPC, ALB, VPC Endpoints (Bảo mật, routing, kết nối AWS Services). Monitoring: CloudWatch, SNS (Logs, Metrics, Alerts). CI/CD: CodePipeline, CodeBuild (Auto deploy backend). Thiết kế thành phần\nNgười dùng: Researchers: hỏi – đáp, tra cứu nội dung học thuật. Dev/Admin: upload, quản lý và re-index tài liệu. Xử lý tài liệu (IDP): PDF được Dev/Admin upload lên S3. Worker trên EC2 gọi Textract để OCR và trích xuất text/bảng. Lập chỉ mục (Indexing \u0026amp; Vector DB): Worker chuẩn hoá, chia chunk nội dung. Gọi Bedrock Titan Embeddings v2 tạo embedding. Lưu embedding + metadata vào Qdrant trên EC2. Hội thoại AI (RAG): FastAPI embed câu hỏi, truy vấn Qdrant lấy top-k đoạn liên quan. Gửi context + câu hỏi vào Claude 3.5 Sonnet (Bedrock) để sinh câu trả lời kèm citation. Quản lý người dùng: Cognito xác thực và phân quyền researcher / admin. Lưu trữ \u0026amp; trạng thái: DynamoDB lưu metadata tài liệu (doc_id, status, owner, …) và (tuỳ chọn) lịch sử chat. 4. Triển khai kỹ thuật Các giai đoạn triển khai\nDự án gồm 2 phần chính — nền tảng web (UI + auth) và backend RAG + IDP — triển khai qua 4 giai đoạn:\nNghiên cứu \u0026amp; chốt kiến trúc: Rà soát yêu cầu (50 researcher, 1 EC2, IDP + RAG). Chốt kiến trúc VPC, EC2 (FastAPI + Qdrant + Worker), Amplify, Cognito, S3, SQS, DynamoDB, Textract, Bedrock. POC \u0026amp; kiểm tra kết nối: Tạo EC2, VPC endpoints, thử gọi Textract, Titan Embeddings, Claude 3.5 Sonnet. Chạy Qdrant đơn giản trên EC2, test insert/search vector. Tạo skeleton FastAPI + một màn hình Chat UI tối giản trên Amplify. Hoàn thiện tính năng chính: Xây /api/chat (FastAPI) + RAG pipeline: embed query → Qdrant → Claude + citation. Xây /api/admin/: upload PDF, lưu S3 + DynamoDB, đưa message vào SQS. Viết Worker trên EC2: SQS → Textract → normalize/chunk → Titan → Qdrant → update DynamoDB. Hoàn thiện Chat UI và Admin UI (upload + xem trạng thái tài liệu). Kiểm thử, tối ưu, triển khai demo nội bộ: Test end-to-end với một tập ~50–100 paper. Thêm CloudWatch Logs/Alarms, SNS notify khi lỗi hoặc queue backlog. Điều chỉnh cấu hình EC2, Qdrant, batch size để tối ưu thời gian và chi phí. Chuẩn bị tài liệu hướng dẫn sử dụng và demo cho nhóm 50 researcher. Yêu cầu kỹ thuật Frontend \u0026amp; Auth: React/Next.js host trên AWS Amplify, CDN CloudFront, DNS Route 53. Amazon Cognito quản lý định danh và phân quyền (Researcher/Admin). Backend \u0026amp; Compute: EC2 t3.small (Private Subnet) chạy All-in-one: FastAPI, Qdrant Vector DB và Worker. Xử lý bất đồng bộ: Worker đọc SQS, kích hoạt Textract và Bedrock để index dữ liệu. IDP \u0026amp; RAG: Lưu trữ: S3 (File gốc), DynamoDB (Metadata \u0026amp; Trạng thái). AI Core: Textract (OCR tài liệu scan), Bedrock Titan (Embedding), Claude 3.5 Sonnet (Trả lời câu hỏi). Mạng \u0026amp; Observability: Network: VPC Private Subnet, VPC Endpoints để kết nối bảo mật tới AWS Services. Monitoring: CloudWatch Logs/Metrics + SNS cảnh báo sự cố (CPU cao, lỗi Worker). 5. Lộ trình \u0026amp; Mốc triển khai Dự án được thực hiện trong khoảng 6 tuần với các giai đoạn cụ thể:\nTuần 1-2 (Ngày 1-10): Nghiên cứu \u0026amp; Thiết kế Thiết kế kiến trúc chi tiết, xác định scope, dịch vụ sử dụng. Lên kế hoạch tối ưu chi phí vận hành và triển khai. Tuần 3 (Ngày 11-15): Thiết lập hạ tầng AWS Cấu hình VPC, Subnets, Security Groups, IAM Roles. Triển khai EC2 t3.small, S3 bucket, DynamoDB tables. Thiết lập VPC Endpoints (Gateway + Interface). Tuần 4 (Ngày 16-20): Backend APIs \u0026amp; IDP Pipeline Xây dựng FastAPI endpoints (/api/chat, /api/admin/upload). Tích hợp IDP pipeline: SQS → Worker → Textract → Embeddings → Qdrant. Kết nối Bedrock (Titan Embeddings + Claude 3.5 Sonnet). Tuần 5 (Ngày 21-25): Testing \u0026amp; Error Handling Kiểm thử end-to-end với tập ~50-100 papers. Xử lý edge cases, retry logic, error handling. Tối ưu chunking strategy và retrieval accuracy. Tuần 6 (Ngày 26-30): Deployment \u0026amp; Documentation Hoàn thiện UI/UX cho Admin và Researcher. Thiết lập CloudWatch Alarms + SNS notifications. Chuẩn bị tài liệu hướng dẫn và demo cho nhóm 50 researcher. 6. Ước tính ngân sách Chi phí hạ tầng (ước tính theo tháng)\nCompute \u0026amp; Storage: EC2 t3.small: $10.08 (720h). EBS gp3: $2.40 (30GB). Network: NAT Gateway: $21.60. VPC Interface Endpoints: $14.60 (2 endpoints cho Textract, Bedrock). VPC Gateway Endpoints: FREE (S3, DynamoDB). AI \u0026amp; Operations: Bedrock Claude 3.5 Sonnet: $25.00 (50 users). Bedrock Titan Embeddings: $0.75 (750 papers). CloudWatch + Data Transfer: $1.90. Free Tier (12 tháng đầu)\nWeb \u0026amp; Auth: S3, CloudFront, Cognito, Amplify (FREE). Serverless: DynamoDB, SQS, SNS (Always FREE). IDP: Textract AnalyzeDocument (100 pages/month trong 3 tháng đầu). Tổng cộng: ~$60-76/tháng (tùy mức sử dụng Bedrock).\n7. Đánh giá rủi ro Ma trận rủi ro\nHallucination (AI bịa đặt): Ảnh hưởng cao, xác suất trung bình. Vượt ngân sách (AI Services): Ảnh hưởng trung bình, xác suất trung bình. Sự cố hạ tầng (EC2/Qdrant): Ảnh hưởng cao, xác suất thấp. Chiến lược giảm thiểu\nChất lượng AI: Bắt buộc trích dẫn nguồn (citation), giới hạn context đầu vào từ Qdrant. Chi phí: Thiết lập AWS Budgets/Alarms, kiểm soát số lượng tài liệu ingest. Hạ tầng \u0026amp; Bảo mật: Backup EBS định kỳ, mã hóa dữ liệu (S3/DynamoDB), phân quyền chặt chẽ qua Cognito/IAM. Kế hoạch dự phòng\nSự cố hệ thống: Khôi phục từ Snapshot, tạm dừng ingestion (buffer qua SQS). Vượt chi phí: Tạm khóa tính năng upload mới, giới hạn hạn ngạch truy vấn trong ngày. 8. Kết quả kỳ vọng Cải tiến kỹ thuật\nChuyển đổi kho tài liệu rời rạc (PDF/Scan) thành tri thức số có thể truy vấn và trích dẫn tự động. Giảm đáng kể thời gian tra cứu thủ công nhờ công nghệ RAG + IDP. Giá trị dài hạn Xây dựng nền tảng nghiên cứu số hóa cho 50+ researcher, dễ dàng mở rộng quy mô. Tạo tiền đề phát triển các tính năng nâng cao: Gợi ý tài liệu, phân tích xu hướng nghiên cứu và hỗ trợ viết tổng quan (Literature Review). Đính kèm Bạn có thể tải về bản đề xuất chi tiết của nhóm ARC tại đây:\nDownload Proposal of ARC Team.docx\n"},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/5-workshop/2-preparation/","title":"Các bước chuẩn bị","tags":[],"description":"","content":"Yêu cầu Tiên quyết Các yêu cầu cần có để thực hiện workshop này:\nMáy tính khách AWS: Được cấu hình với quyền truy cập vào các dịch vụ AWS cần thiết Môi trường phát triển: Windows, macOS hoặc Linux với các công cụ development cơ bản Kiến thức cơ bản: Hiểu biết về AWS, Python, JavaScript và Docker Tài khoản GitHub: Để clone source code và theo dõi changes Ngân sách AWS: Khoảng $65/tháng cho các resources (EC2, Bedrock, NAT Gateway) Cài đặt công cụ 1. AWS CLI AWS Command Line Interface (AWS CLI) là công cụ để tương tác với AWS services.\nWindows:\n# Download và cài đặt MSI installer msiexec.exe /i https://awscli.amazonaws.com/AWSCLIV2.msi macOS:\nbrew install awscli Linux:\ncurl \u0026#34;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\u0026#34; -o \u0026#34;awscliv2.zip\u0026#34; unzip awscliv2.zip sudo ./aws/install Verify installation:\naws --version # aws-cli/2.x.x Python/3.x.x 2. Terraform Terraform là công cụ Infrastructure as Code để provision AWS resources.\nWindows:\nchoco install terraform macOS:\nbrew tap hashicorp/tap brew install hashicorp/tap/terraform Linux:\nwget -O- https://apt.releases.hashicorp.com/gpg | sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg echo \u0026#34;deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main\u0026#34; | sudo tee /etc/apt/sources.list.d/hashicorp.list sudo apt update \u0026amp;\u0026amp; sudo apt install terraform Verify:\nterraform --version 3. Docker Docker để chạy Qdrant vector database locally và trên EC2.\nWindows/macOS: Download Docker Desktop\nLinux:\ncurl -fsSL https://get.docker.com -o get-docker.sh sudo sh get-docker.sh sudo usermod -aG docker $USER Verify:\ndocker --version docker run hello-world 4. Node.js (\u0026gt;= 18) Node.js cho frontend development với React + Vite.\nSử dụng nvm (khuyến nghị):\n# Install nvm curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash # Install Node.js 18 nvm install 18 nvm use 18 Verify:\nnode --version # v18.x.x npm --version # 9.x.x 5. Python (\u0026gt;= 3.11) Python cho backend FastAPI application.\nWindows: Download từ python.org (chọn \u0026ldquo;Add to PATH\u0026rdquo;)\nmacOS:\nbrew install python@3.11 Linux:\nsudo apt update sudo apt install python3.11 python3.11-venv python3-pip Verify:\npython --version # Python 3.11.x pip --version 6. Git Git cho version control.\nWindows: Download từ git-scm.com\nmacOS:\nbrew install git Linux:\nsudo apt install git Verify:\ngit --version Clone Repository git clone https://github.com/CrystalJohn/ARC-project.git cd ARC-project Cấu hình AWS Credentials Tạo IAM User Đăng nhập AWS Console Navigate to IAM → Users → Create user User name: arc-workshop-user Attach policies: AmazonEC2FullAccess AmazonS3FullAccess AmazonDynamoDBFullAccess AmazonCognitoPowerUser AmazonSQSFullAccess AmazonTextractFullAccess AmazonBedrockFullAccess CloudWatchFullAccess IAMFullAccess Create access key → Download credentials Configure AWS CLI aws configure Nhập thông tin:\nAWS Access Key ID: AKIAXXXXXXXXXXXXXXXX AWS Secret Access Key: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx Default region name: ap-southeast-1 Default output format: json Verify:\naws sts get-caller-identity Kích hoạt Amazon Bedrock Models Request Model Access AWS Console → Amazon Bedrock → Model access Click Manage model access Chọn models: Anthropic - Claude 3.5 Sonnet (anthropic.claude-3-5-sonnet-20241022-v2:0) Cohere - Embed Multilingual v3 (cohere.embed-multilingual-v3) Click Request model access → Accept Terms → Submit Verify Access # Test Claude aws bedrock get-foundation-model \\ --model-identifier anthropic.claude-3-5-sonnet-20241022-v2:0 \\ --region ap-southeast-1 # Test Cohere aws bedrock get-foundation-model \\ --model-identifier cohere.embed-multilingual-v3 \\ --region ap-southeast-1 Expected: Status Access granted\nChuẩn bị Sample Documents Project có sẵn sample PDFs trong samples/:\nls samples/ # data-structures-sample.pdf # test-sample.pdf Yêu cầu documents Limit Value Format PDF (text-based hoặc scanned) Max size 50 MB Max pages 500 pages Recommended 10-100 pages Checklist Trước khi tiếp tục, đảm bảo:\nAWS CLI installed và configured Terraform installed Docker installed và running Node.js 18+ installed Python 3.11+ installed Git installed Repository cloned IAM user created với đủ permissions Bedrock models được approve (Claude + Cohere) Sample documents sẵn sàng "},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/1-worklog/1.10-week10/","title":"Worklog Tuần 10","tags":[],"description":"","content":"Mục tiêu tuần 10: Setup AWS Account, IAM Users \u0026amp; Policies Nghiên cứu Bedrock Claude 3.5 \u0026amp; Cohere Embed APIs Nghiên cứu Textract AnalyzeDocument API Thiết kế architecture Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Setup AWS Account - Tạo IAM Users \u0026amp; Policies - Cấu hình quyền truy cập cho các dịch vụ AI/ML 10/11/2025 10/11/2025 https://docs.aws.amazon.com/IAM/ 3 - Nghiên cứu Amazon Bedrock - Tìm hiểu Claude 3.5 model - Tìm hiểu Cohere Embed APIs 11/11/2025 11/11/2025 https://docs.aws.amazon.com/bedrock/ 4 - Viết sample code test_bedrock.py - Test Claude 3.5 API calls - Test Cohere Embedding 12/11/2025 12/11/2025 https://docs.aws.amazon.com/bedrock/ 5 - Nghiên cứu Amazon Textract - Tìm hiểu AnalyzeDocument API - Viết sample code test_textract.py 13/11/2025 13/11/2025 https://docs.aws.amazon.com/textract/ 6 - Thiết kế Architecture diagram - Ước tính chi phí (~$65/month) - Review và hoàn thiện tài liệu 14/11/2025 14/11/2025 Kết quả đạt được tuần 10: AWS Account Setup:\nTạo AWS Account 427995028618 với IAM users Cấu hình IAM Policies cho Bedrock, Textract Sample Code:\ntest_bedrock.py — test Claude 3.5 \u0026amp; Cohere Embed APIs test_textract.py — test AnalyzeDocument API Architecture:\nHoàn thành Architecture diagram cho ARC-Chatbot Xác định các dịch vụ cần sử dụng: Bedrock, Textract, S3, Lambda, \u0026hellip; Cost Estimation:\nƯớc tính chi phí khoảng ~$65/month cho môi trường dev/test "},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/1-worklog/1.11-week11/","title":"Worklog Tuần 11","tags":[],"description":"","content":"Mục tiêu tuần 11: Hoàn thiện setup base infrastructure (M0) — S3, DynamoDB, Cognito, ALB Bắt đầu triển khai IDP Pipeline (M1) — SQS, PDF Detection, PyPDF2 extraction Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Setup S3 bucket arc-chatbot-documents-427995028618 - Tạo DynamoDB tables (metadata, chat-history) - Cấu hình table schema và indexes 17/11/2025 17/11/2025 https://docs.aws.amazon.com/dynamodb/ 3 - Configure Cognito User Pool ap-southeast-1_8KB4JYvsX - Setup user authentication flow - Test sign-up/sign-in process 18/11/2025 18/11/2025 https://docs.aws.amazon.com/cognito/ 4 - Setup ALB arc-chatbot-dev-alb với health checks - Cấu hình target groups và listeners - Test load balancer routing 19/11/2025 19/11/2025 https://docs.aws.amazon.com/elasticloadbalancing/ 5 - Tạo SQS queue arc-chatbot-dev-document-processing - Implement PDF detection service (digital vs scanned) - Viết unit tests cho PDF detector 20/11/2025 20/11/2025 https://docs.aws.amazon.com/sqs/ 6 - Implement PyPDF2 extraction cho digital PDFs - Xử lý các edge cases (encrypted, corrupted PDFs) - Viết tests và đạt 30 tests passed 21/11/2025 21/11/2025 https://pypdf2.readthedocs.io/ Kết quả đạt được tuần 11: Hoàn thiện Base Infrastructure (M0):\nS3 bucket arc-chatbot-documents-427995028618 — lưu trữ documents DynamoDB tables: metadata (document info), chat-history (conversation logs) Cognito User Pool ap-southeast-1_8KB4JYvsX — xác thực người dùng ALB arc-chatbot-dev-alb với health checks — load balancing cho API Bắt đầu IDP Pipeline (M1):\nSQS Queue arc-chatbot-dev-document-processing — queue xử lý documents PDF Detector service — phân biệt digital vs scanned PDFs (17 tests passed) PDF Extractor service với PyPDF2 — extract text từ digital PDFs (30 tests passed) Học được:\nCách thiết kế DynamoDB schema cho chatbot application Cognito authentication flow và JWT tokens SQS message processing patterns Xử lý các loại PDF khác nhau trong Python "},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/1-worklog/1.12-week12/","title":"Worklog Tuần 12","tags":[],"description":"","content":"Mục tiêu tuần 12: Hoàn thiện RAG Chat component (M2) — Rate limiting, fallback, error handling Bắt đầu Testing \u0026amp; Golive (M3) — Login page, Chat UI, Admin dashboard Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Implement Rate Limiter (60 RPM, 100K TPM) - Add Budget Manager ($10/day, $200/month) - Viết tests cho rate limiting logic 24/11/2025 24/11/2025 https://docs.aws.amazon.com/bedrock/ 3 - Implement fallback to Claude Haiku - Add error handling \u0026amp; retry logic với exponential backoff - Viết tests (35 tests passed) 25/11/2025 25/11/2025 https://docs.aws.amazon.com/bedrock/ 4 - Implement login page với Cognito - Build AuthService với JWT validation - Test authentication flow end-to-end 26/11/2025 26/11/2025 https://docs.aws.amazon.com/cognito/ 5 - Build Chat interface UI - Implement ChatPage với message bubbles, citations - Tạo CitationCard, DocumentViewerModal components 27/11/2025 27/11/2025 https://react.dev/ 6 - Build Admin dashboard với drag-drop upload - Show document processing status (real-time auto-refresh) - Bắt đầu integration testing E2E 28/11/2025 28/11/2025 https://react.dev/ Kết quả đạt được tuần 12: Hoàn thiện RAG Chat (M2):\nRate Limiter Budget Manager: $10/day, $200/month limit (22 tests passed) Bedrock Retry với exponential backoff (35 tests passed) Fallback từ Claude 3.5 Sonnet → Claude Haiku khi rate limit Bắt đầu Testing \u0026amp; Golive (M3):\nAuthService với JWT validation — xác thực người dùng qua Cognito ChatPage với message bubbles và citations — giao diện chat chính CitationCard, DocumentViewerModal components — hiển thị nguồn tài liệu AdminPage với drag-drop upload — quản lý documents Real-time status monitoring với auto-refresh Học được:\nRate limiting patterns cho AI APIs (token-based \u0026amp; request-based) Cost management strategies cho Bedrock (budget alerts, fallback models) Exponential backoff với jitter cho retry logic React components cho chat UI (message streaming, citations) Cognito JWT validation trong frontend "},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/3-blogstranslated/","title":"Các Blog Đã Dịch","tags":[],"description":"","content":"Blog 1 - Xây dựng một nhà khí tượng học ảo bằng cách sử dụng Amazon Bedrock Agents Bài viết trình bày cách xây dựng một nhà khí tượng ảo sử dụng Amazon Bedrock Agents, giúp trả lời các câu hỏi liên quan tới thời tiết theo ngôn ngữ tự nhiên. Bạn sẽ được hướng dẫn cách cấu hình agent, định nghĩa \u0026ldquo;action groups\u0026rdquo; để xử lý vị trí địa lý, thời gian và dữ liệu thời tiết; đồng thời tích hợp các dịch vụ AWS như Lambda, Cognito và Amplify để triển khai đầu cuối.\nBlog 2 - Xây dựng pipeline Apache Spark end-to-end với Amazon MWAA, Batch Processing Gateway và Amazon EMR trên EKS Bài viết hướng dẫn cách xây dựng pipeline Spark đầu-cuối bằng cách kết hợp Amazon MWAA (Managed Workflows for Apache Airflow) với Batch Processing Gateway để điều phối công việc Spark trên nhiều cluster EMR chạy trên EKS. Bạn sẽ tìm hiểu cách tích hợp, kiến trúc xử lý nhiều cluster, cách định tuyến và giám sát công việc, cũng như cách triển khai môi trường thực tế cho hệ thống dữ liệu quy mô lớn.\nBlog 3 - Xây dựng Golden Image với CIS Linux Build Kit trong Amazon EC2 Image Builder Bài viết trình bày cách sử dụng CIS Linux Build Kit (LBK) để tự động hóa quá trình harden (củng cố bảo mật) và kiểm tra các Amazon Machine Image (AMI) thông qua EC2 Image Builder. Bạn sẽ được hướng dẫn hai cách tiếp cận — dùng các thành phần CIS có sẵn từ AWS Marketplace hoặc tự quản các script LBK — để tạo \u0026ldquo;Golden Images\u0026rdquo; theo mức chuẩn CIS Level 1, đồng thời tích hợp Amazon Inspector và EventBridge để giám sát, bật thông báo \u0026amp; kiểm duyệt kết quả.\n"},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/3-blogstranslated/3.3-blog3/","title":"Xây dựng Golden Image với CIS Linux Build Kit trong Amazon EC2 Image Builder","tags":[],"description":"","content":"Bởi: Rajat Chatterjee Ngày: 11 Tháng 5, 2025\nChủ đề: Amazon Inspector, Enterprise Governance and Control, Expert (400), Management Tools, Technical How-to\nGiới thiệu Việc xây dựng và triển khai các hệ điều hành (Operating System – OS) đã được harden và chứng nhận bảo mật là yêu cầu thiết yếu đối với bất kỳ đội ngũ Cloud Operations (CloudOps) hoặc Cloud Center of Excellence (CCoE) nào trong tổ chức. Các hướng dẫn và biện pháp kiểm soát bảo mật được sử dụng để chứng nhận các image này thường đến từ đội ngũ bảo mật nội bộ, dựa trên các tiêu chuẩn được công nhận rộng rãi trong ngành.\nTuy nhiên, bạn cũng cần khả năng kiểm soát quy trình hardening, với sự linh hoạt để chọn lựa các bước khắc phục và kịch bản triển khai ứng dụng phù hợp. Kết quả là hình thành nên \u0026ldquo;Golden Amazon Machine Images (AMI)\u0026rdquo; – các image được các đơn vị nghiệp vụ (Business Units) sử dụng trực tiếp.\nQuy trình này cần có tự động hóa, để việc xây dựng và kiểm thử diễn ra ở quy mô lớn và các image được phân phối thông qua Amazon Machine Images (AMI) đã được phê duyệt. Một trong những tiêu chuẩn phổ biến được sử dụng làm cơ sở (baseline) cho việc harden image là Center for Internet Security (CIS) — tổ chức tạo và duy trì một bộ hướng dẫn cấu hình được gọi là CIS Benchmarks, cung cấp các thực hành cấu hình tốt nhất (best practices) cho các công nghệ cụ thể như hệ điều hành, nền tảng đám mây, ứng dụng và cơ sở dữ liệu.\nCIS Benchmarks được công nhận rộng rãi trong ngành và được nhiều tiêu chuẩn như PCI DSS, HIPAA, DoD Cloud Computing SRG, FISMA, DFARS, và FEDRAMP tham chiếu.\nTrong bài viết này, chúng tôi chọn benchmark của CIS cho Amazon Linux, và xây dựng một quy trình để tạo AMI được chứng nhận thông qua tự động hóa có thể vận hành ở quy mô lớn.\nBạn có thể sử dụng một trong hai cách tiếp cận để tạo Golden Images bằng cách áp dụng CIS Benchmark cho hệ điều hành (OS) tương ứng nhằm harden AMI:\nSử dụng component được quản lý với CIS AMI từ AWS Marketplace – Bạn cũng sẽ có quyền truy cập vào hardening component đi kèm, chạy các script để áp dụng hướng dẫn CIS Benchmark Level 1 cho cấu hình của mình. Các component này do tổ chức CIS sở hữu và duy trì để đảm bảo luôn cập nhật theo hướng dẫn mới nhất. (Chi tiết về cách tiếp cận này có thể xem tại bài viết Building CIS hardened Golden Images and Pipelines with EC2 Image Builder).\nSử dụng quy trình hardening tự quản bằng Amazon EC2 Image Builder – Cách tiếp cận này mang lại sự linh hoạt cho đội ngũ CloudOps trong việc tùy chỉnh quy trình hardening, giúp họ có thể loại trừ các khuyến nghị trong benchmark có thể ảnh hưởng đến ứng dụng dự kiến triển khai trên instance sử dụng AMI.\nBạn có thể chọn một trong hai phương án trên sau khi phân tích kỹ các yếu tố đã được giải thích trong bài viết How to Decide Between Building or Buying a CIS Hardened Image.\nTrong bài này, chúng tôi sẽ minh họa cách sử dụng các script được công bố bởi CIS Linux Build Kit (LBK) để tạo quy trình hardening và xác thực tự quản sử dụng EC2 Image Builder và Amazon Inspector. Các script cần thiết để harden hệ điều hành cụ thể (theo CIS Benchmark) được công bố trên trang CIS Workbench, có thể tải về nếu tổ chức của bạn là thành viên CIS SecureSuite®. Những script này có thể sử dụng lại với rất ít chỉnh sửa để tạo EC2 Image Builder Component, sau đó dùng trong các Image Builder Pipeline.\nChúng ta sẽ thực hiện cách tiếp cận này bằng việc tạo một AMI Amazon Linux 2 đã được harden, và kiểm tra (validate) nó bằng Amazon Inspector.\nTổng quan giải pháp Giải pháp bao gồm các bước chính sau:\nTiền đề (Prerequisites):\nCó tài khoản AWS với quyền thích hợp. Tải xuống, khám phá và cập nhật CIS LBK Utility. Tạo bucket Amazon S3 làm môi trường staging để tải lên CIS LBK Utility. Cấu hình bucket S3 để phát thông báo qua Amazon EventBridge. Các bước triển khai chính:\nXây dựng Image Building Pipeline bằng EC2 Image Builder. Xác thực image và tạo báo cáo bằng Amazon Inspector. Tiền đề cho giải pháp Tải xuống, khám phá và cập nhật CIS LBK Utility LBK dành cho Amazon Linux 2 có thể được tải từ trang CIS. Bộ công cụ này được cộng đồng CIS phát triển và duy trì, hiện được phân phối dưới dạng file amazon_linux_2.tar.gz.\nSau khi giải nén file tar, bạn sẽ thấy cấu trúc thư mục như sau:\nHình 1: Cấu trúc thư mục của Bộ công cụ xây dựng CIS Linux\nThư mục chính chứa file amazon_linux_2.sh — script chính gọi các script phụ trong thư mục \u0026ldquo;functions\u0026rdquo;. Nếu bạn muốn loại trừ một số khuyến nghị, hãy thêm chúng vào file exclusion_list.txt.\nHướng dẫn sử dụng và nội dung của bộ công cụ được mô tả chi tiết trong Quick Start Guide đi kèm trong package. Script amazon_linux_2.sh bao gồm hai bước tương tác khi chạy. Để tự động hóa, bạn nên chỉnh sửa script này để cố định (hardcode) các giá trị đầu vào.\nCụ thể, bạn cần:\nChấp nhận điều khoản sử dụng (Terms and Conditions) – nên comment dòng này trong script, và nhóm CloudOps có thể cung cấp nội dung điều khoản riêng cho người dùng trong tài liệu nội bộ.\nChọn profile hardening – có bốn profile: L1S, L2S, L1W, L2W tương ứng với Level 1/2 của CIS Benchmark, và loại Server (S) hoặc Workstation (W).\nTrong ví dụ này, chúng ta sẽ dùng profile L1S để harden Amazon Linux 2 theo chuẩn CIS Benchmark Level 1.\nCác dòng cần chỉnh trong script:\n#terms_of_use #Display CIS Linux Build Kit warning banner #WARBNR ---\u0026gt; Comment dòng này run_profile=L1S # Uncomment dòng này để chỉ định profile được chạy Sau khi chỉnh sửa, đóng gói lại file LBK:\ntar cvf amazon_linux_2.tar.gz CIS-LBK Tạo bucket S3 staging và tải lên LBK Tạo bucket S3 (ví dụ: cis-lbk-al2) bằng AWS Management Console hoặc AWS CLI. Bucket này được dùng để lưu trữ script LBK, phục vụ cho EC2 Image Builder tải xuống và tải log sau khi chạy.\naws s3api put-object --bucket cis-lbk-al2 --key amazon_linux_2.tar.gz --body amazon_linux_2.tar.gz Cấu hình bucket S3 để gửi thông báo qua Amazon EventBridge Bật Amazon S3 Event Notifications cho bucket, chọn gửi thông báo đến Amazon EventBridge. Bạn có thể kích hoạt tính năng này trong tab Properties của bucket.\nHình 2: Cho phép gửi thông báo đến EventBridge từ thùng S3\nCác bước triển khai Hình 3: Kiến trúc của giải pháp\nXây dựng Image Building Pipeline bằng EC2 Image Builder Giải pháp này sử dụng các dịch vụ AWS sau:\nEC2 Image Builder: chạy LBK từ Amazon S3 để harden và đóng gói AMI. EC2 Image Builder dùng AWS Task Orchestrator and Executor (AWSTOE) để điều phối workflow phức tạp. Bạn sẽ tạo custom component để gọi LBK từ S3, đồng thời định nghĩa image recipe làm image cơ sở (base image) và image workflow xác định trình tự các bước build.\nAmazon Inspector: thực hiện kiểm tra bảo mật (CIS scan) để xác thực AMI sau khi harden.\nAmazon EventBridge: tích hợp sẵn với EC2 Image Builder và S3 để phát sự kiện (event). Các sự kiện này có thể được chuyển tiếp đến Amazon SNS hoặc AWS Lambda.\nAmazon SNS: dùng để gửi thông báo qua email về các bước kiểm duyệt (approval step).\nTạo Component tùy chỉnh cho EC2 Image Builder Bạn có thể sử dụng AWS CloudFormation template (được cung cấp trong bài gốc) để khởi tạo stack tạo toàn bộ các tài nguyên được đề cập trong các phần dưới đây.\nLệnh ví dụ để triển khai stack:\naws cloudformation create-stack --stack-name cis-al2-harden-stack \\ --template-body file://cis-lbk-automation-template.yml \\ --parameters CloudFormation template này sẽ tự động tạo các thành phần được mô tả trong kiến trúc giải pháp.\nTrong bài viết này, ta định nghĩa một custom component có tên CIS-AL2-L1S-Hardening, với các đặc điểm sau:\nType: build Platform: Linux và các hệ điều hành tương thích OS Version: Amazon Linux 2 Mỗi component được định nghĩa bằng một tài liệu YAML, trong đó bucket S3 được tạo ở bước tiền đề được dùng để tải script và tải log lên. Bảng sau đây liệt kê một loạt các bước trong giai đoạn xây dựng.\nHình 4: Các bước của giai đoạn Xây dựng\nVí dụ định nghĩa component:\nname: \u0026#39;CIS-Build-AL2-Level1\u0026#39; description: \u0026#39;Applies the L1S CIS settings for Amazon Linux 2 (AL2)\u0026#39; schemaVersion: 1.0 parameters: - StagingS3BucketName: type: string - FileName: type: string default: \u0026#39;amazon_linux_2.tar.gz\u0026#39; - Version: type: string default: \u0026#39;2024.2.0\u0026#39; - Level: type: string default: \u0026#39;L1S\u0026#39; phases: - name: build steps: - name: OperatingSystemRelease action: ExecuteBash inputs: commands: - | FILE=/etc/os-release if [ -e $FILE ]; then . $FILE echo \u0026#34;$ID${VERSION_ID:+.${VERSION_ID}}\u0026#34; else echo \u0026#34;The file $FILE does not exist. Exiting.\u0026#34; exit 1 fi - name: GetPackageManager action: ExecuteBash inputs: commands: - | RELEASE=\u0026#39;{{build.OperatingSystemRelease.outputs.stdout}}\u0026#39; case \u0026#34;${RELEASE}\u0026#34; in amzn*|centos*|rhel*) echo \u0026#39;yum\u0026#39; ;; ubuntu*) echo \u0026#39;apt\u0026#39; ;; *) echo \u0026#34;Operating System \u0026#39;${RELEASE}\u0026#39; is not supported. Exiting.\u0026#34; exit 1 ;; esac - name: VerifyPrerequisite action: ExecuteBash onFailure: Abort inputs: commands: - | INSTALL_TYPE=\u0026#39;{{build.GetPackageManager.outputs.stdout}}\u0026#39; case \u0026#34;${INSTALL_TYPE}\u0026#34; in \u0026#39;yum\u0026#39;) if ! yum -q list installed tar \u0026amp;\u0026gt;/dev/null; then yum install -q -y tar echo \u0026#34;Installed tar.\u0026#34; else echo \u0026#34;Tar is already installed.\u0026#34; fi ;; \u0026#39;apt\u0026#39;) apt install -q -y tar echo \u0026#34;Installed tar.\u0026#34; ;; *) echo \u0026#34;Install type \u0026#39;${INSTALL_TYPE}\u0026#39; is not supported at this time. Exiting.\u0026#34; exit 1 ;; esac - name: MakeStagingDIR action: ExecuteBash inputs: commands: - | mkdir cis-stage cd cis-stage pwd - name: SettingStagingDirPermissions action: SetFolderPermissions inputs: - path: \u0026#39;{{build.MakeStagingDIR.outputs.stdout}}\u0026#39; permissions: 0700 - name: Download_CIS_LBK action: S3Download inputs: - source: s3://{{ StagingS3BucketName }}/{{ FileName }} destination: \u0026#39;{{build.MakeStagingDIR.outputs.stdout}}/{{ FileName }}\u0026#39; - name: Unzip_CIS_LBK action: ExecuteBash onFailure: Continue inputs: commands: - sudo tar -xvf \u0026#39;{{build.MakeStagingDIR.outputs.stdout}}/{{ FileName }}\u0026#39; -C \u0026#39;{{build.MakeStagingDIR.outputs.stdout}}/\u0026#39; || ( echo \u0026#34;File extraction failed. Exiting\u0026#34; ; exit 1; ) - name: AL2_ConfigureCIS action: ExecuteBash onFailure: Continue inputs: commands: - | RELEASE=\u0026#39;{{ build.OperatingSystemRelease.outputs.stdout }}\u0026#39; if [ ! `echo \u0026#34;$RELEASE\u0026#34; | grep -E \u0026#34;^(amzn\\.2$|(centos|rhel)\\.7)\u0026#34;` ]; then echo \u0026#39;Skipping this step for the current operating system.\u0026#39; exit 0 fi cd {{build.MakeStagingDIR.outputs.stdout}}/CIS-LBK/cis_lbk_amazon_linux_2 sudo ./amazon_linux_2.sh || ( echo \u0026#34;CIS configuration script failed to run. Exiting.\u0026#34; ; exit 1; ) - name: UploadLogFiles action: S3Upload onFailure: Abort maxAttempts: 3 inputs: - source: \u0026#39;{{build.MakeStagingDIR.outputs.stdout}}/CIS-LBK/cis_lbk_amazon_linux_2/logs/*\u0026#39; destination: \u0026#39;s3://{{ StagingS3BucketName }}/logs/\u0026#39; recurse: true expectedBucketOwner: \u0026lt;\u0026lt;your account number\u0026gt;\u0026gt; Tạo Image Recipe dựa trên Component Image Recipe là một tài liệu định nghĩa các component được áp dụng lên base image để tạo ra cấu hình mong muốn cho output image.\nRecipe có tên CIS-AL2-L1S-Hardening-Recipe được tạo bằng component tùy chỉnh CIS-AL2-L1S-Hardening làm giai đoạn build chính.\nMẫu AWS CloudFormation template có dạng như sau:\nImageRecipeCISAL2L1S: Type: \u0026#34;AWS::ImageBuilder::ImageRecipe\u0026#34; Properties: Components: - ComponentArn: !GetAtt CISAL2HardeningComponent.Arn Parameters: - Value: - !Sub \u0026#34;${StagingS3BucketName}\u0026#34; Name: \u0026#34;StagingS3BucketName\u0026#34; WorkingDirectory: \u0026#34;/var/tmp\u0026#34; ParentImage: !Sub \u0026#34;arn:aws:imagebuilder:${AWS::Region}:aws:image/amazon-linux-2-x86/x.x.x\u0026#34; Version: \u0026#34;1.0.0\u0026#34; AdditionalInstanceConfiguration: SystemsManagerAgent: UninstallAfterBuild: true Name: \u0026#34;CIS-AL2-L1S-Hardening\u0026#34; DependsOn: - CISAL2HardeningComponent Như bạn thấy, component tùy chỉnh (custom component) được tham chiếu trong recipe, đồng thời recipe cũng tham chiếu phiên bản mới nhất của Amazon Linux 2 làm base image thông qua thuộc tính ParentImage.\nComponent CIS-AL2-L1S-Hardening nhận WorkingDirectory làm đầu vào.\nGiá trị này phải được đặt là /var/tmp, vì thư mục /tmp mặc định sẽ bị thay đổi quyền truy cập (permission) bởi script CIS LBK, gây lỗi truy cập khi chạy.\nTạo Workflow tùy chỉnh cho quá trình Build Image Image Workflow định nghĩa chuỗi các bước EC2 Image Builder thực hiện trong giai đoạn build và test của quy trình tạo image.\nWorkflow này giới thiệu hành động WaitForAction, giúp thêm bước phê duyệt thủ công (manual approval) sau khi quá trình hardening hoàn tất. Tại bước này, người vận hành có thể xem log và tiếp tục tạo image. Đồng thời, đây cũng là lúc có thể kích hoạt và xem kết quả Amazon Inspector scan.\nHành động WaitForAction sẽ tạm dừng workflow đang chạy và chờ phản hồi từ API SendWorkflowStepAction của EC2 Image Builder. Sự kiện này sẽ phát EventBridge event với detail-type là \u0026ldquo;EC2 Image Builder Workflow Step Waiting\u0026rdquo;.\nĐối với bài blog này, nhóm tác giả tạo workflow tùy chỉnh có tên build-cis-hardened-manual-action, loại BUILD, với nội dung YAML như sau:\nname: build-cis-hardened-manual-action description: Workflow to build an AMI schemaVersion: 1.0 steps: - name: LaunchBuildInstance action: LaunchInstance onFailure: Abort inputs: waitFor: \u0026#34;ssmAgent\u0026#34; - name: ApplyBuildComponents action: ExecuteComponents onFailure: Abort inputs: instanceId.$: \u0026#34;$.stepOutputs.LaunchBuildInstance.instanceId\u0026#34; - name: InventoryCollection action: CollectImageMetadata onFailure: Abort if: and: - stringEquals: \u0026#34;AMI\u0026#34; value: \u0026#34;$.imagebuilder.imageType\u0026#34; - booleanEquals: true value: \u0026#34;$.imagebuilder.collectImageMetadata\u0026#34; inputs: instanceId.$: \u0026#34;$.stepOutputs.LaunchBuildInstance.instanceId\u0026#34; - name: RunSanitizeScript action: SanitizeInstance onFailure: Abort if: and: - stringEquals: \u0026#34;AMI\u0026#34; value: \u0026#34;$.imagebuilder.imageType\u0026#34; - stringEquals: \u0026#34;Linux\u0026#34; value: \u0026#34;$.imagebuilder.platform\u0026#34; inputs: instanceId.$: \u0026#34;$.stepOutputs.LaunchBuildInstance.instanceId\u0026#34; - name: CheckBuildLogsAndApprove action: WaitForAction - name: CreateOutputAMI action: CreateImage onFailure: Abort if: stringEquals: \u0026#34;AMI\u0026#34; value: \u0026#34;$.imagebuilder.imageType\u0026#34; inputs: instanceId.$: \u0026#34;$.stepOutputs.LaunchBuildInstance.instanceId\u0026#34; - name: TerminateBuildInstance action: TerminateInstance onFailure: Continue inputs: instanceId.$: \u0026#34;$.stepOutputs.LaunchBuildInstance.instanceId\u0026#34; outputs: - name: \u0026#34;ImageId\u0026#34; value: \u0026#34;$.stepOutputs.CreateOutputAMI.imageId\u0026#34; Tạo Image Pipeline Trong ví dụ của bài blog, nhóm tạo Image Pipeline có tên CIS-AL2-L1S-Hardening-pipeline.\nEC2 Image Builder sử dụng Amazon Inspector để quét các instance test tìm lỗ hổng bảo mật trong hệ điều hành hoặc gói phần mềm. Tuy nhiên, trong trường hợp này, tính năng quét lỗ hổng mặc định được vô hiệu hóa, vì nhóm chỉ sử dụng Amazon Inspector để thực hiện CIS scan trên output image, không thực hiện quét lỗ hổng chung.\nLịch Build Schedule được đặt ở chế độ Manual. Bạn có thể định kỳ hóa bằng Schedule Builder (CRON expression).\nTiếp theo, nhóm chọn Image Recipe (CIS-AL2-L1S-Hardening-Recipe) đã tạo ở bước trước. Quá trình tạo image được định nghĩa bằng Custom Workflow, trong đó build-cis-hardened-manual-action được chọn làm Build workflow.\nIAM Role được chọn là AWSServiceRoleForImageBuilder, cung cấp quyền truy cập cần thiết cho EC2 Image Builder.\nCấu hình hạ tầng (Infrastructure Configuration) giữ nguyên mặc định, ngoại trừ việc thêm Resource Tag cho instance:\nKey: IBCISHardened Value: Yes → Thẻ này được dùng trong cấu hình Amazon Inspector làm tiêu chí lọc (filter) để quét CIS.\nDistribution Settings giữ nguyên mặc định – tức là EC2 Image Builder sẽ khởi chạy instance trong default VPC, và phân phối AMI đầu ra trong Region hiện tại.\nPhần Infrastructure Configuration này tạo IAM Role và Instance Profile được sử dụng bởi build instance để cấu hình AMI. Instance Role này gắn với EC2InstanceProfileForImageBuilder và AmazonSSMManagedInstanceCore managed policy.\nĐể chạy Amazon Inspector CIS scan thành công, Instance Profile cần gắn thêm policy AmazonInspector2ManagedCisPolicy.\nCấu hình IAM Instance Profile Role có dạng như sau:\nIAMManagedPolicyIBCisComponentS3Access: Type: \u0026#34;AWS::IAM::ManagedPolicy\u0026#34; Properties: ManagedPolicyName: \u0026#34;IBCisComponentS3Access\u0026#34; Path: \u0026#34;/\u0026#34; Description: \u0026#34;Access to S3 Bucket from EC2 ImageBuilder CIS Custom component\u0026#34; PolicyDocument: Version: \u0026#34;2012-10-17\u0026#34; Statement: - Resource: \u0026#34;arn:aws:s3:::cis-lbk-al2/*\u0026#34; Action: - \u0026#34;s3:PutObject\u0026#34; - \u0026#34;s3:GetObject\u0026#34; Effect: \u0026#34;Allow\u0026#34; IAMRoleForImageBuilderCISAL2: Type: \u0026#34;AWS::IAM::Role\u0026#34; Properties: ManagedPolicyArns: - \u0026#34;arn:aws:iam::aws:policy/EC2InstanceProfileForImageBuilder\u0026#34; - Ref: \u0026#34;IAMManagedPolicyIBCisComponentS3Access\u0026#34; - \u0026#34;arn:aws:iam::aws:policy/AmazonInspector2ManagedCisPolicy\u0026#34; - \u0026#34;arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore\u0026#34; AssumeRolePolicyDocument: Version: \u0026#34;2012-10-17\u0026#34; Statement: - Action: \u0026#34;sts:AssumeRole\u0026#34; Effect: \u0026#34;Allow\u0026#34; Principal: Service: \u0026#34;ec2.amazonaws.com\u0026#34; EC2InstanceProfileForImageBuilderCISAL2: Type: \u0026#34;AWS::IAM::InstanceProfile\u0026#34; Properties: Roles: - !Ref \u0026#34;IAMRoleForImageBuilderCISAL2\u0026#34; InstanceProfileName: \u0026#34;EC2InstanceProfileForImageBuilderCISAL2\u0026#34; Gắn Bucket Policy cho S3 Bucket cis-lbk-al2 Chính sách này chỉ cho phép IAM Role của Instance Profile truy cập bucket:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Statement1\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::7284282*****:role/IAMRoleForImageBuilderCISAL2\u0026#34; }, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::cis-lbk-al2\u0026#34; } ] } Tạo Amazon SNS Topic cho Email Notification Nhóm tạo một SNS Topic có tên ImageBuilderQueue, kèm theo Email Subscription để gửi thông báo cho người phụ trách quy trình.\nTạo Amazon EventBridge Rules để gửi thông báo Hai EventBridge rule được tạo để gửi thông báo qua SNS:\nRule 1 – Thông báo khi workflow chờ phê duyệt (WaitForAction):\nKhi EC2 Image Builder phát sự kiện \u0026ldquo;Workflow Step Waiting\u0026rdquo; cho bước CheckBuildLogsAndApprove, rule này gửi thông điệp đến SNS Topic ImageBuilderQueue.\nAWSTemplateFormatVersion: \u0026#39;2010-09-09\u0026#39; Description: CloudFormation template for EventBridge Rule ec2-imagebuilder Resources: Rule41742a2e: Type: AWS::Events::Rule Properties: Name: ec2-imagebuilder EventPattern: \u0026gt;- {\u0026#34;source\u0026#34;:[\u0026#34;aws.imagebuilder\u0026#34;],\u0026#34;detail-type\u0026#34;:[\u0026#34;EC2 Image Builder Workflow Step Waiting\u0026#34;], \u0026#34;detail\u0026#34;:{\u0026#34;workflow-step-name\u0026#34;:[\u0026#34;CheckBuildLogsAndApprove\u0026#34;]}} State: ENABLED EventBusName: default Targets: - Arn: !Sub \u0026#34;arn:${AWS::Partition}:sns:${AWS::Region}:${AWS::AccountId}:ImageBuilderQueue\u0026#34; Rule 2 – Thông báo khi log CIS được tạo trong S3 bucket:\nKhi một object CIS-LBK.log được tạo trong đường dẫn /logs/.../, EventBridge sẽ gửi thông báo đến SNS topic ImageBuilderQueue.\nAWSTemplateFormatVersion: \u0026#39;2010-09-09\u0026#39; Description: CloudFormation template for EventBridge Rule CISHardeningExitLogEvent Resources: Rule104d463b: Type: AWS::Events::Rule Properties: Name: CISHardeningExitLogEvent EventPattern: \u0026gt;- {\u0026#34;source\u0026#34;:[\u0026#34;aws.s3\u0026#34;],\u0026#34;detail-type\u0026#34;:[\u0026#34;Object Created\u0026#34;], \u0026#34;detail\u0026#34;:{\u0026#34;bucket\u0026#34;:{\u0026#34;name\u0026#34;:[\u0026#34;cis-lbk-al2\u0026#34;]}, \u0026#34;object\u0026#34;:{\u0026#34;key\u0026#34;:[{\u0026#34;wildcard\u0026#34;:\u0026#34;logs/*CIS-LBK.log\u0026#34;}]}}} State: ENABLED EventBusName: default Targets: - Arn: !Sub \u0026#34;arn:${AWS::Partition}:sns:${AWS::Region}:${AWS::AccountId}:ImageBuilderQueue\u0026#34; InputTransformer: InputPathsMap: bucketname: $.detail.bucket.name objectkey: $.detail.object.key region: $.region InputTemplate: \u0026gt;- \u0026#34;Review the output log for the CIS Hardening process in \u0026lt;bucketname\u0026gt; bucket at \u0026lt;objectkey\u0026gt;. Log URL: https://\u0026lt;bucketname\u0026gt;.s3.\u0026lt;region\u0026gt;.amazonaws.com/\u0026lt;objectkey\u0026gt;\u0026#34; Chạy Image Pipeline Bạn có thể khởi chạy pipeline từ AWS Console hoặc AWS CLI.\nLệnh CLI mẫu:\naws imagebuilder start-image-pipeline-execution \\ --image-pipeline-arn arn:aws:imagebuilder:{REGION}:{ACCOUNT_ID}:image-pipeline/CIS-AL2-L1S-Hardening-pipeline Kết quả trả về:\n{ \u0026#34;requestId\u0026#34;: \u0026#34;a1b2c3d4-5678-90ab-cdef-EXAMPLE11111\u0026#34;, \u0026#34;clientToken\u0026#34;: \u0026#34;a1b2c3d4-5678-90ab-cdef-EXAMPLE22222\u0026#34;, \u0026#34;imageBuildVersionArn\u0026#34;: \u0026#34;arn:aws:imagebuilder:{REGION}:{ACCOUNT_ID}:image/cis-al2-l1s-hardening/1.0.1/1\u0026#34; } Ghi chú imageBuildVersionArn và stepExecutionId. Pipeline sẽ tạm dừng tại bước CheckBuildLogsAndApprove.\nKiểm tra trạng thái chờ qua lệnh:\naws imagebuilder list-waiting-workflow-step Khi chạy thành công, bạn sẽ nhận 2 email thông báo:\nMột email từ S3 EventBridge chứa link log file CIS-LBK. Một email từ Image Builder yêu cầu phê duyệt bước chờ. Ví dụ nội dung log notification:\n\u0026#34;Review the output log for the CIS Hardening process in \u0026#39;cis-lbk-al2\u0026#39; bucket, location \u0026#39;logs/08_27_2024_1210/CIS-LBK.log\u0026#39;...\u0026#34; Kiểm thử Image bằng Amazon Inspector Trong giai đoạn chờ, bạn tạo CIS scan một lần (one-time) bằng Amazon Inspector:\naws inspector2 create-cis-scan-configuration \\ --scan-name cis-hardened-scan \\ --schedule oneTime={} \\ --security-level \u0026#34;LEVEL_1\u0026#34; \\ --targets \u0026#34;accountIds=\u0026lt;\u0026lt;account_id\u0026gt;\u0026gt;,targetResourceTags={IBCISHardened=Yes}\u0026#34; Theo dõi tiến trình scan:\naws inspector2 list-cis-scans \\ --filter-criteria \u0026#34;scanConfigurationArnFilters=[{comparison=EQUALS,value=\u0026lt;\u0026lt;scanConfigurationArn\u0026gt;\u0026gt;}]\u0026#34; Sau khi hoàn tất, tải báo cáo PDF:\naws inspector2 get-cis-scan-report --scan-arn \u0026lt;\u0026lt;scan-arn\u0026gt;\u0026gt; --report-format PDF Kết quả trả về URL của báo cáo, có thể mở bằng trình duyệt đã đăng nhập AWS.\nTiếp tục hoặc dừng workflow Sau khi xem log và báo cáo:\nTiếp tục pipeline:\naws imagebuilder send-workflow-step-action \\ --step-execution-id \u0026lt;\u0026lt;stepExecutionId\u0026gt;\u0026gt; \\ --image-build-version-arn \u0026lt;\u0026lt;imageBuildVersionArn\u0026gt;\u0026gt; \\ --action RESUME Hoặc dừng pipeline:\naws imagebuilder send-workflow-step-action \\ --step-execution-id \u0026lt;\u0026lt;stepExecutionId\u0026gt;\u0026gt; \\ --image-build-version-arn \u0026lt;\u0026lt;imageBuildVersionArn\u0026gt;\u0026gt; \\ --action STOP \\ --reason \u0026#34;Please fix the issue and recreate the Image\u0026#34; Khi hoàn tất, xem AMI output:\naws imagebuilder get-image \\ --image-build-version-arn \u0026lt;\u0026lt;imageBuildVersionArn\u0026gt;\u0026gt; \\ --query \u0026#39;image.outputResources.amis[0].image\u0026#39; Kết luận Trong bài viết này, chúng tôi đã thiết lập quy trình dựa trên EC2 Image Builder để harden AMI Amazon Linux 2 theo CIS Amazon Linux 2 Benchmark bằng cách sử dụng CIS Linux Build Kit do cộng đồng CIS cung cấp.\nChúng tôi cũng tận dụng thông báo dựa trên sự kiện (event-based) từ Amazon S3 và Amazon EventBridge để kích hoạt email phê duyệt và giới thiệu quy trình manual approval.\nFramework này có thể mở rộng để harden các AMI khác như Ubuntu hoặc CentOS, sử dụng các bộ LBK tương ứng từ cộng đồng CIS.\nHãy liên hệ với đại diện AWS để được hỗ trợ triển khai quy trình này cho doanh nghiệp của bạn.\nĐọc thêm CIS hardening components for EC2 Image Builder Build a pipeline for hardened container images using EC2 Image Builder and Terraform Amazon Inspector Best Practices Về tác giả Rajat Chatterjee\nRajat là Kiến trúc sư Giải pháp cấp cao (Senior Solutions Architect), làm việc cùng các khách hàng trong lĩnh vực Dịch vụ Tài chính bao gồm Ngân hàng, Bảo hiểm và Thị trường Vốn, nhằm hỗ trợ họ xây dựng các ứng dụng đáng tin cậy, an toàn và hiệu năng cao trên nền tảng đám mây.\nAnh có chuyên môn trong việc triển khai quy mô lớn các khối lượng công việc dựa trên microservices trên nền tảng container dành cho các doanh nghiệp.\n"},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/5-workshop/3-bedrock-models/","title":"Kích hoạt Bedrock Models","tags":[],"description":"","content":"Trước khi triển khai giải pháp, bạn cần kích hoạt các mô hình Amazon Bedrock cần thiết trong tài khoản AWS của mình.\nCác bước Kích hoạt Mô hình Tìm kiếm Amazon Bedrock trong AWS Console Truy cập Model catalog từ menu điều hướng bên trái Chọn tên mô hình tương ứng: Anthropic Claude 3.5 Sonnet Anthropic Claude 3 Sonnet Anthropic Claude 3 Haiku Cohere - Embed Multilingual v3 Chọn \u0026ldquo;Open in playground\u0026rdquo; và gửi một tin nhắn thử nghiệm để kích hoạt từng mô hình Lưu ý: Đảm bảo bạn kích hoạt tất cả bốn mô hình trong khu vực ap-southeast-1 (Singapore) vì giải pháp được triển khai trong khu vực này.\n"},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/4-eventparticipated/","title":"Các events đã tham gia","tags":[],"description":"","content":" Trong phần này, các bạn cần liệt kê và mô tả chi tiết các sự kiện (event) mà mình đã tham gia trong suốt quá trình thực tập hoặc làm việc.\nMỗi sự kiện nên được trình bày theo định dạng Event 1, Event 2, Event 3…, kèm theo các thông tin:\nTên sự kiện Thời gian tổ chức Địa điểm (nếu có) Vai trò của bạn trong sự kiện (người tham dự, hỗ trợ tổ chức, diễn giả, v.v.) Mô tả ngắn gọn nội dung và hoạt động chính trong sự kiện Kết quả hoặc giá trị đạt được (bài học, kỹ năng mới, đóng góp cho nhóm/dự án) Việc liệt kê này giúp thể hiện rõ sự tham gia thực tế của bạn, cũng như các kỹ năng mềm và kinh nghiệm bạn đã tích lũy qua từng sự kiện. Trong quá trình thực tập, em đã tham gia 4 events với cơ hội được AWS trao để tham dự. Mỗi event đều mang lại cho em một tầm nhìn mới và sự thúc đẩy để tìm kiếm, chinh phục những kiến thức và thử thách mới. Cùng với đó là sự kết nối, giao lưu với các member cộng đồng AWS.\nEvent 1 Tên sự kiện: BUILDING AGENTIC AI\nThời gian: 05/12/2025\nĐịa điểm: Bitexco Financial Tower, 26th Floor, 2 Hải Triều, Quận 1, TP.HCM\nVai trò trong sự kiện: Người tham dự\nNội dung chính: Tối ưu context với Amazon Bedrock, xây dựng AI agent automation, kỹ thuật RAG và prompt engineering\nEvent 2 Tên sự kiện: AWS Cloud Mastery Series #3 workshop (Security Pillar)\nThời gian: 29/11/2025\nĐịa điểm: Bitexco Financial Tower, 26th Floor, 2 Hải Triều, Quận 1, TP.HCM\nVai trò trong sự kiện: Người tham dự\nNội dung chính: AWS Well-Architected Framework – Security Pillar, IAM, Detection \u0026amp; Monitoring, Infrastructure Protection, Data Protection, Incident Response\nEvent 3 Tên sự kiện: AWS Cloud Mastery Series #2 workshop (DevOps)\nThời gian: 17/11/2025\nĐịa điểm: Bitexco Financial Tower, 26th Floor, 2 Hải Triều, Quận 1, TP.HCM\nVai trò trong sự kiện: Người tham dự\nNội dung chính: Tư duy DevOps hiện đại, CI/CD Pipeline, Infrastructure as Code (IaC), Container Services (ECS/EKS/App Runner), Monitoring \u0026amp; Observability\nEvent 4 Tên sự kiện: AWS Cloud Mastery Series #1 workshop (AI/ML/GenAI)\nThời gian: 15/11/2025\nĐịa điểm: Bitexco Financial Tower, 26th Floor, 2 Hải Triều, Quận 1, TP.HCM\nVai trò trong sự kiện: Người tham dự\nNội dung chính: Amazon SageMaker, Generative AI with Amazon Bedrock, Bedrock Agents, MLOps, CI/CD workflow for containers\n"},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/5-workshop/4-aws-cli/","title":"Cấu hình AWS CLI","tags":[],"description":"","content":"Cấu hình AWS CLI Để triển khai và quản lý giải pháp, bạn cần cấu hình AWS Command Line Interface (AWS CLI) với thông tin xác thực của mình.\nCác bước Bước 1: Kiểm tra AWS CLI đã cài đặt aws --version Nếu chưa có, cài đặt:\n# Download và cài đặt MSI installer msiexec.exe /i https://awscli.amazonaws.com/AWSCLIV2.msi Bước 2: Tạo IAM User (nếu chưa có) Đăng nhập AWS Console Tìm kiếm \u0026ldquo;IAM\u0026rdquo; → Click IAM Sidebar trái → Users → Create user User name: arc-workshop-user Click Next Attach policies directly, chọn các policies: AmazonEC2FullAccess AmazonS3FullAccess AmazonDynamoDBFullAccess AmazonCognitoPowerUser AmazonSQSFullAccess AmazonTextractFullAccess AmazonBedrockFullAccess CloudWatchFullAccess IAMFullAccess Click Create user Bước 3: Tạo Access Key Vào user vừa tạo → Tab Security credentials Scroll xuống Access keys → Click Create access key Chọn Command Line Interface (CLI) Tick \u0026ldquo;I understand\u0026hellip;\u0026rdquo; → Next Description: ARC Workshop CLI Click Create access key ⚠️ QUAN TRỌNG: Copy hoặc download .csv file\nAccess key ID: AKIAXXXXXXXXXXXXXXXX Secret access key: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx Bước 4: Configure AWS CLI Mở PowerShell và chạy:\naws configure Nhập thông tin:\nAWS Access Key ID [None]: AKIAXXXXXXXXXXXXXXXX AWS Secret Access Key [None]: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx Default region name [None]: ap-southeast-1 Default output format [None]: json Bước 5: Verify Configuration Kiểm tra identity:\naws sts get-caller-identity Output mong đợi:\n{ \u0026#34;UserId\u0026#34;: \u0026#34;AIDAXXXXXXXXXXXXXXXXX\u0026#34;, \u0026#34;Account\u0026#34;: \u0026#34;123456789012\u0026#34;, \u0026#34;Arn\u0026#34;: \u0026#34;arn:aws:iam::123456789012:user/arc-workshop-user\u0026#34; } "},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/5-workshop/5-data-preparation/","title":"Chuẩn bị Dữ liệu","tags":[],"description":"","content":"Chuẩn bị Dữ liệu Trước khi tạo AWS resources, bạn cần tải xuống tập dữ liệu mẫu để test hệ thống.\nBước 1: Tải Xuống Tập Dữ liệu Truy cập ARC Sample Data Tải dữ liệu về máy tính của bạn Giải nén file, sẽ tạo ra một thư mục có tên DATA Yêu cầu Documents Limit Value Format PDF (text-based hoặc scanned) Max size 50 MB Max pages 500 pages Recommended 10-100 pages Chuẩn bị AWS Resources Bước 2: Tạo S3 Bucket S3 Bucket dùng để lưu trữ documents PDF được upload.\nTìm kiếm S3 trong AWS Console Click Create bucket Cấu hình bucket: Bucket name: arc-documents-\u0026lt;YOUR-ACCOUNT-ID\u0026gt; (thay \u0026lt;YOUR-ACCOUNT-ID\u0026gt; bằng AWS Account ID của bạn) AWS Region: Asia Pacific (Singapore) ap-southeast-1 Giữ các settings khác mặc định Click Create bucket 💡 Tip: Để lấy AWS Account ID, chạy:\naws sts get-caller-identity --query Account --output text Hoặc tạo bằng CLI:\naws s3 mb s3://arc-documents-$(aws sts get-caller-identity --query Account --output text) --region ap-southeast-1 Bước 3: Tạo DynamoDB Table DynamoDB Table dùng để lưu metadata của documents.\nTìm kiếm DynamoDB trong AWS Console Click Create table Cấu hình table: Table name: arc-documents Partition key: doc_id (String) Sort key: sk (String) Table settings: Default settings Click Create table Hoặc tạo bằng CLI:\naws dynamodb create-table \\ --table-name arc-documents \\ --attribute-definitions \\ AttributeName=doc_id,AttributeType=S \\ AttributeName=sk,AttributeType=S \\ --key-schema \\ AttributeName=doc_id,KeyType=HASH \\ AttributeName=sk,KeyType=RANGE \\ --billing-mode PAY_PER_REQUEST \\ --region ap-southeast-1 Bước 4: Tạo SQS Queue SQS Queue dùng cho IDP pipeline xử lý documents.\nTìm kiếm SQS trong AWS Console Click Create queue Cấu hình queue: Type: Standard Name: arc-document-queue Giữ các settings khác mặc định Click Create queue Hoặc tạo bằng CLI:\naws sqs create-queue --queue-name arc-document-queue --region ap-southeast-1 Bước 5: Verify Resources Kiểm tra tất cả resources đã được tạo:\n# S3 Bucket aws s3 ls | grep arc-documents # DynamoDB Table aws dynamodb describe-table --table-name arc-documents --region ap-southeast-1 --query \u0026#34;Table.TableName\u0026#34; # SQS Queue aws sqs get-queue-url --queue-name arc-document-queue --region ap-southeast-1 Bước 6: Upload Dữ liệu lên S3 Upload các file PDF từ thư mục DATA đã tải về ở Bước 1:\n# Upload tất cả files từ thư mục DATA aws s3 cp DATA/ s3://arc-documents-\u0026lt;YOUR-ACCOUNT-ID\u0026gt;/uploads/ --recursive # Hoặc upload từng file aws s3 cp DATA/sample-document.pdf s3://arc-documents-\u0026lt;YOUR-ACCOUNT-ID\u0026gt;/uploads/ 💡 Tip: Thay \u0026lt;YOUR-ACCOUNT-ID\u0026gt; bằng AWS Account ID của bạn\nVerify upload:\naws s3 ls s3://arc-documents-\u0026lt;YOUR-ACCOUNT-ID\u0026gt;/uploads/ Checklist Trước khi tiếp tục, đảm bảo:\nAWS CLI installed và configured Terraform installed Docker installed và running Node.js 18+ installed Python 3.11+ installed Git installed Repository cloned IAM user created với đủ permissions Bedrock models được approve (Claude + Cohere) S3 Bucket created DynamoDB Table created SQS Queue created Sample documents uploaded to S3 Cấu hình bucket: Bucket name: arc-documents-\u0026lt;YOUR-ACCOUNT-ID\u0026gt; (thay \u0026lt;YOUR-ACCOUNT-ID\u0026gt; bằng AWS Account ID của bạn) AWS Region: Asia Pacific (Singapore) ap-southeast-1 Giữ các settings khác mặc định Click Create bucket 💡 Tip: Để lấy AWS Account ID, chạy: aws sts get-caller-identity --query Account --output text\nHoặc tạo bằng CLI:\naws s3 mb s3://arc-documents-$(aws sts get-caller-identity --query Account --output text) --region ap-southeast-1 Bước 3: Tạo DynamoDB Table DynamoDB Table dùng để lưu metadata của documents.\nTìm kiếm DynamoDB trong AWS Console Click Create table Cấu hình table: Table name: arc-documents Partition key: doc_id (String) Sort key: sk (String) Table settings: Default settings Click Create table Hoặc tạo bằng CLI:\naws dynamodb create-table \\ --table-name arc-documents \\ --attribute-definitions \\ AttributeName=doc_id,AttributeType=S \\ AttributeName=sk,AttributeType=S \\ --key-schema \\ AttributeName=doc_id,KeyType=HASH \\ AttributeName=sk,KeyType=RANGE \\ --billing-mode PAY_PER_REQUEST \\ --region ap-southeast-1 Bước 4: Tạo SQS Queue SQS Queue dùng cho IDP pipeline xử lý documents.\nTìm kiếm SQS trong AWS Console Click Create queue Cấu hình queue: Type: Standard Name: arc-document-queue Giữ các settings khác mặc định Click Create queue Hoặc tạo bằng CLI:\naws sqs create-queue --queue-name arc-document-queue --region ap-southeast-1 Bước 5: Verify Resources Kiểm tra tất cả resources đã được tạo:\n# S3 Bucket aws s3 ls | grep arc-documents # DynamoDB Table aws dynamodb describe-table --table-name arc-documents --region ap-southeast-1 --query \u0026#34;Table.TableName\u0026#34; # SQS Queue aws sqs get-queue-url --queue-name arc-document-queue --region ap-southeast-1 Bước 6: Upload Dữ liệu lên S3 Upload các file PDF từ thư mục DATA đã tải về ở Bước 1:\n# Upload tất cả files từ thư mục DATA aws s3 cp DATA/ s3://arc-documents-\u0026lt;YOUR-ACCOUNT-ID\u0026gt;/uploads/ --recursive # Hoặc upload từng file aws s3 cp DATA/sample-document.pdf s3://arc-documents-\u0026lt;YOUR-ACCOUNT-ID\u0026gt;/uploads/ 💡 Tip: Thay \u0026lt;YOUR-ACCOUNT-ID\u0026gt; bằng AWS Account ID của bạn\nVerify upload:\naws s3 ls s3://arc-documents-\u0026lt;YOUR-ACCOUNT-ID\u0026gt;/uploads/ Checklist Trước khi tiếp tục, đảm bảo:\nAWS CLI installed và configured Terraform installed Docker installed và running Node.js 18+ installed Python 3.11+ installed Git installed Repository cloned IAM user created với đủ permissions Bedrock models được approve (Claude + Cohere) Sample documents sẵn sàng "},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Tổng quan Trong workshop này, chúng ta sẽ xây dựng ARC (Academic Research Chatbot) - một hệ thống chatbot thông minh hoạt động trên nền tảng AWS Serverless. Giải pháp này ứng dụng Generative AI và RAG (Retrieval-Augmented Generation) để hỗ trợ nghiên cứu học thuật, truy vấn tài liệu và trả lời câu hỏi một cách linh hoạt.\nThay vì trả lời các câu hỏi dựa trên kịch bản cố định (rule-based), hệ thống sử dụng mô hình Claude 3.5 Sonnet để hiểu ngôn ngữ tự nhiên, truy vấn dữ liệu từ cơ sở vector database và phản hồi người dùng một cách chính xác.\nMục tiêu Workshop Sau khi hoàn thành workshop, bạn sẽ:\nHiểu kiến trúc RAG và cách áp dụng vào thực tế Triển khai hệ thống chatbot hoàn chỉnh trên AWS Sử dụng Amazon Bedrock (Claude 3.5 Sonnet + Cohere Embed) Xây dựng IDP pipeline với Amazon Textract Implement vector search với Qdrant Deploy infrastructure với Terraform Tích hợp authentication với Amazon Cognito Nội dung Giới thiệu Các bước chuẩn bị Kích hoạt Bedrock Models Cấu hình AWS CLI Chuẩn bị Dữ liệu Triển khai Infrastructure Thiết lập Backend API Thiết lập IDP Pipeline Thiết lập Frontend Sử dụng Chatbot Sử dụng Admin Dashboard Dọn dẹp Tài nguyên "},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/5-workshop/6-infrastructure/","title":"Triển khai giải pháp","tags":[],"description":"","content":"Trong phần này, chúng ta sẽ clone repository và triển khai toàn bộ hạ tầng AWS cho hệ thống ARC Chatbot.\nBước 1: Clone Repository Clone repository từ GitHub:\ngit clone https://github.com/CrystalJohn/ARC-project.git cd ARC-project Bước 2: Build Dashboard Trước khi triển khai ứng dụng, chúng ta cần build frontend dashboard.\nDi chuyển đến thư mục frontend cd frontend Cài đặt dependencies Chạy lệnh sau để cài đặt các thư viện cần thiết:\nnpm install Build Dashboard Sau khi cài đặt hoàn tất, chạy lệnh build:\nnpm run build Sau khi quá trình hoàn tất, một thư mục dist sẽ được tạo. Kiểm tra file index.html và thư mục assets:\nls dist/ # index.html assets/ Quay lại thư mục gốc của project cd .. Bước 3: Triển khai CDK Application Triển khai ứng dụng CDK. Quá trình sẽ mất khoảng 20-30 phút để triển khai tất cả các tài nguyên.\ncd terraform terraform init terraform apply --auto-approve ⚠️ Note: Nếu bạn gặp lỗi ở bước này, hãy đảm bảo Docker đang chạy trên máy tính của bạn.\n💡 Info: Thay thế \u0026lt;account_id\u0026gt; bằng AWS Account ID thực tế của bạn.\nBước 4: Xác minh Triển khai Sau khi hoàn thành tất cả các bước trên, môi trường của bạn đã được triển khai thành công.\nBạn có thể xác minh triển khai bằng cách kiểm tra:\nAWS Console: Kiểm tra các resources đã được tạo (EC2, S3, Cognito, DynamoDB, etc.) Terraform State: Chạy terraform state list để xem danh sách resources S3 Buckets: Bucket cho documents và frontend đã được tạo EC2 Instance: Instance cho backend đã được khởi tạo Kiểm tra Outputs terraform output Các outputs quan trọng:\nOutput Mô tả api_endpoint Backend API URL cognito_user_pool_id Cognito User Pool ID cognito_client_id Cognito App Client ID s3_bucket_name S3 bucket cho documents cloudfront_url Frontend URL Các Bước Tiếp Theo Bây giờ bạn có thể tiếp tục:\nThiết lập Backend Thiết lập IDP Pipeline Thiết lập Frontend "},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Trong suốt thời gian thực tập tại AWS - Amazon Web Services từ 12/08/2025 đến 12/11/2025, tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia dự án ARC-Chatbot - Chatbot nghiên cứu học thuật sử dụng Generative AI và RAG trên nền tảng AWS Serverless, qua đó cải thiện kỹ năng lập trình Python, thiết kế kiến trúc hệ thống, sử dụng các dịch vụ AWS (Bedrock, Textract, S3, DynamoDB, Cognito), viết tài liệu kỹ thuật và làm việc nhóm.\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ✅ ☐ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ✅ ☐ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ✅ ☐ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Nâng cao tính kỹ luật, chấp hành nghiêm chỉnh nội quy của công ty hoặc bất kỳ trong một tổ chức nào Cải thiện trong cách tư duy giải quyết vấn đề Cải thiện được kỹ năng tư duy thiết kế hệ thống một cách hiệu quả hơn. Để mang lại giá trị cao cho người dùng. "},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":"Đánh giá chung 1. Môi trường làm việc Chương trình First Cloud Journey thật sự là một trải nghiệm tuyệt vời, chương trình được thiết kế ra đã giúp cho tôi hiểu biết và trải nghiệm service AWS (1 trong những Cloud rất mạnh). Chương trình học toàn diện kéo dài 12 tuần cho phép tôi tiến bộ một cách có hệ thống từ kiến thức AWS cơ bản đến triển khai dự án ARC-Chatbot — một ứng dụng RAG Chatbot MVP. Cấu trúc worklog hàng tuần giúp tôi có có thể ghi nhận lại tiến độ công việc, tình trạng học tập hiệu quả. Môi trường khuyến khích tự học trong khi vẫn cung cấp đầy đủ tài nguyên và hỗ trợ khi cần.\n2. Sự hỗ trợ của mentor / team Sự hướng dẫn và hợp tác nhóm trong suốt chương trình rất xuất sắc. Team luôn sẵn sàng thảo luận các thách thức kỹ thuật, xem xét đề xuất kiến trúc của tôi và hướng dẫn qua các khái niệm AWS phức tạp như Bedrock, Textract, và RAG + IDP pipeline. Điều tôi đánh giá cao nhất là mentor luôn khuyến khích tôi tự nghiên cứu và đề xuất hướng giải quyết trước khi hỗ trợ — giúp tôi phát triển tư duy độc lập.\n3. Sự phù hợp giữa công việc và chuyên ngành học Nội dung chương trình rất phù hợp với các thực hành điện toán đám mây và kỹ thuật phần mềm hiện đại. Bắt đầu từ các kiến thức nền tảng về mạng (VPC, Security Groups) và tiến tới kiến trúc serverless, database, security và các dịch vụ AI/ML giúp tôi xây dựng một bộ kỹ năng cloud engineering khá toàn diện.\nDự án thực hành ARC-Chatbot — xây dựng chatbot tích hợp AI với admin dashboard, IDP pipeline, và RAG chat — cho tôi kinh nghiệm thực tế áp dụng trực tiếp vào các tình huống thực tế. Việc nhấn mạnh vào Infrastructure as Code (Terraform, CDK) và các thực hành DevOps hoàn toàn phù hợp với tiêu chuẩn ngành hiện tại.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng Hành trình 12 tuần đem đến cho tôi rất nhiều cơ hội học hỏi trên nhiều khía cạnh:\nKỹ năng kỹ thuật: Học được cách sử dụng hơn 15 dịch vụ AWS (Bedrock, Textract, SageMaker, DynamoDB, S3, Cognito, SQS, Lambda, ECS, ECR, ALB, CloudWatch, X-Ray, VPC, IAM\u0026hellip;) AI/ML Integration: Học cách tích hợp Claude 3.5, Cohere Embeddings, RAG pipeline, và Qdrant vector database Thiết kế kiến trúc: Học cách thiết kế giải pháp đám mây có khả năng mở rộng, tiết kiệm chi phí Tài liệu hóa: Cải thiện kỹ năng viết kỹ thuật qua worklog hàng tuần và dịch các bài blog AWS Giải quyết vấn đề: Phát triển kỹ năng debug bằng cách giải quyết các vấn đề như rate limiting, PDF processing, và vector search optimization Tối ưu chi phí: Học cách đưa ra quyết định kiến trúc dựa trên phân tích chi phí-lợi ích (~$65/month estimation) Sự tiến bộ từ AWS Fundamentals (Tuần 1-4) → S3 \u0026amp; Security (Tuần 5) → Serverless (Tuần 6) → Containers (Tuần 7) → AI/ML (Tuần 8) → Architecture Design (Tuần 9) → Full Implementation (Tuần 10-12) có tốc độ hợp lý và logic.\n5. Văn hóa \u0026amp; tinh thần đồng đội Chương trình FCJ nuôi dưỡng văn hóa học tập liên tục, hợp tác và đổi mới. Các cuộc họp nhóm mang tính xây dựng, với thảo luận cởi mở về các đánh đổi kỹ thuật và quyết định kiến trúc. Các workshop như \u0026ldquo;AWS Cloud Mastery Series\u0026rdquo; và \u0026ldquo;Building Agentic AI\u0026rdquo; tạo cơ hội mở rộng kiến thức ngoài chương trình cốt lõi.\n6. Chính sách / hỗ trợ của chương trình Cấu trúc chương trình được thiết kế tốt với các mục tiêu hàng tuần rõ ràng, tài liệu tham khảo toàn diện (AWS Study Group, Cloud Journey, AWS docs chính thức) và các bài lab thực hành. Sự linh hoạt để khám phá các phương pháp khác nhau (nhiều tùy chọn database, vector search, PDF extraction) trong khi vẫn tập trung vào dự án chính rất có giá trị.\nQuyền truy cập vào tài khoản AWS và hướng dẫn về quản lý ngân sách giúp học cách tối ưu chi phí ngay từ ngày đầu.\nPhản hồi chi tiết về các giai đoạn chương trình Giai đoạn 1 (Tuần 1-4): AWS Fundamentals \u0026amp; Core Services\nĐiểm mạnh: Giới thiệu đầy đủ và có hệ thống về AWS, VPC, EC2, Linux deployment. Các bài lab thực hành củng cố kiến thức lý thuyết. Giai đoạn 2 (Tuần 5-6): Security, Serverless \u0026amp; Databases\nĐiểm mạnh: Học S3, IAM, Security best practices (Tuần 5). Tiến triển vào Lambda, API Gateway, DynamoDB (Tuần 6). Giai đoạn 3 (Tuần 7-8): Containers \u0026amp; AI/ML Services\nĐiểm mạnh: Học Docker, ECR, ECS (Tuần 7). Nghiên cứu Bedrock, Textract và các dịch vụ AI/ML (Tuần 8). Giai đoạn 4 (Tuần 9): Architecture Design\nĐiểm mạnh: Thiết kế architecture cho ARC-Chatbot project, lập kế hoạch triển khai và cost estimation. Giai đoạn 5 (Tuần 10-12): Full Implementation \u0026amp; Testing\nĐiểm mạnh: Triển khai thực tế — Assessment M0 (Tuần 10), IDP Pipeline M1 (Tuần 11), RAG Chat M2 \u0026amp; Testing M3 (Tuần 12). Kinh nghiệm end-to-end deployment cực kỳ hữu ích. Điều tôi hài lòng nhất Hoàn thiện giải pháp Production-ready: Triển khai thành công hệ thống ARC-Chatbot hoàn chỉnh từ con số 0, bao gồm IDP pipeline, RAG chat, admin dashboard với tổng cộng 200+ tests passed.\nThành tựu kỹ thuật:\nPDF Detector service (17 tests passed) PDF Extractor với PyPDF2 (30 tests passed) Qdrant vector search (35 tests passed) Claude Service với streaming (20 tests passed) Rate Limiter \u0026amp; Budget Manager (45 tests passed) Bedrock Retry với exponential backoff (35 tests passed) Chiến thắng trong giải quyết vấn đề: Vượt qua các thách thức kỹ thuật như digital vs scanned PDF detection, text chunking optimization, và rate limiting cho AI APIs.\nTiến bộ đo lường được: Từ người mới bắt đầu với AWS vào Tuần 1, đến việc triển khai tự tin các kiến trúc AI/ML đa dịch vụ vào Tuần 12.\nTôi có giới thiệu chương trình này không? Chắc chắn có! Tôi rất khuyến khích chương trình First Cloud Journey cho bất kỳ ai quan tâm đến điện toán đám mây vì nhiều lý do:\nChương trình toàn diện: Bao quát tất cả các nhóm dịch vụ AWS thiết yếu từ cơ bản đến nâng cao Phương pháp thực hành: Triển khai dự án thực tế cung cấp kinh nghiệm thực tế vượt xa các chứng chỉ Tiến triển có cấu trúc: Khung thời gian 12 tuần với các mốc rõ ràng giúp duy trì động lực Cộng đồng hỗ trợ: Mentor và thành viên nhóm tích cực giúp đỡ với các thách thức kỹ thuật Phù hợp với nghề nghiệp: Kỹ năng học được (IaC, serverless, security, AI/ML, tối ưu chi phí) áp dụng trực tiếp vào các vị trí trong ngành Tính linh hoạt: Chương trình cho phép khám phá các dịch vụ khác nhau trong khi tập trung vào mục tiêu cốt lõi \u0026ldquo;Chương trình đã giúp tôi chuyển từ hiểu biết lý thuyết sang khả năng triển khai thực tế.\u0026rdquo;\nĐề xuất \u0026amp; mong muốn cho các khóa tương lai Đề xuất để cải thiện trải nghiệm thực tập:\nChuẩn bị trước thực tập tốt hơn\nCung cấp danh sách đọc trước hoặc chuỗi video về các khái niệm cloud cơ bản Thiết lập tài khoản AWS và CLI trước Tuần 1 để tối đa hóa thời gian thực hành Retrospectives hàng tuần\nCác buổi reflection có cấu trúc mỗi tuần để thảo luận thách thức và bài học Chia sẻ các vấn đề phổ biến và giải pháp trên tất cả các thực tập sinh Buổi diễn giả khách mời\nMời AWS Solutions Architects hoặc chuyên gia cloud chia sẻ kinh nghiệm thực tế Thông tin chi tiết về ngành về các dịch vụ mới nổi và best practices Trình bày Capstone\nTrình bày chính thức về dự án cuối cùng cho mentor và đồng nghiệp Thực hành truyền đạt quyết định kỹ thuật cho nhiều đối tượng khác nhau Mạng lưới Alumni\nKết nối với những người tham gia chương trình FCJ trước đây Cơ hội mentorship cho các thực tập sinh tương lai Tôi có muốn tiếp tục chương trình này trong tương lai không?\nCó, tôi rất muốn tiếp tục với các chương trình nâng cao như:\nChuyên môn AWS nâng cao: Machine Learning, Data Analytics hoặc Security specialty tracks Chuẩn bị chứng chỉ AWS: Solutions Architect Professional, DevOps Engineer Đóng góp mã nguồn mở: Đóng góp vào AWS CDK constructs hoặc các dự án cộng đồng Góp ý khác Chương trình First Cloud Journey vượt quá mong đợi của tôi về mọi mặt. 12 tuần học từ nền tảng AWS đến khi tự triển khai một giải pháp ARC-Chatbot hoàn chỉnh thực sự giúp tôi tự tin hơn hẳn. Việc nhấn mạnh vào học tập thực hành, tối ưu chi phí và best practices đã chuẩn bị tốt cho tôi cho sự nghiệp trong điện toán đám mây.\nĐiều tôi trân trọng nhất trong chương trình là:\nSự tự do để khám phá các phương pháp kiến trúc khác nhau và học hỏi từ sai lầm Môi trường nhóm hỗ trợ khuyến khích đặt câu hỏi và giải pháp sáng tạo Yêu cầu phải tài liệu hóa đầy đủ đã giúp tôi nâng cao đáng kể kỹ năng viết kỹ thuật Dự án thực tế yêu cầu tích hợp nhiều dịch vụ AWS (Bedrock, Textract, DynamoDB, S3, Cognito, SQS, ECS\u0026hellip;) Cảm ơn team FCJ, các mentor và các thực tập sinh đồng nghiệp đã có trải nghiệm học tập tuyệt vời. Kiến thức và kỹ năng đạt được trong 12 tuần này sẽ là nền tảng vững chắc cho sự nghiệp tương lai của tôi trong điện toán đám mây và kỹ thuật phần mềm.\nTóm tắt đánh giá Hạng mục Đánh giá Môi trường làm việc ⭐⭐⭐⭐⭐ (5/5) Hỗ trợ Mentor ⭐⭐⭐⭐⭐ (5/5) Sự phù hợp chương trình ⭐⭐⭐⭐⭐ (5/5) Cơ hội học tập ⭐⭐⭐⭐⭐ (5/5) Văn hóa nhóm ⭐⭐⭐⭐⭐ (5/5) Cấu trúc chương trình ⭐⭐⭐⭐☆ (4.5/5) Đánh giá chung ⭐⭐⭐⭐⭐ (5/5) "},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/5-workshop/7-backend/","title":"Thiết lập Backend API","tags":[],"description":"","content":"Thiết lập Backend API Trong phần này, bạn sẽ cấu hình Backend API (FastAPI) và Qdrant vector database trên EC2.\nKiến trúc Backend Internet → ALB (:80) → EC2 Private Subnet ├── FastAPI Container (:8000) ├── Qdrant Container (:6333) └── SQS Worker (background) 💡 Note: EC2 nằm trong Private Subnet, không có Public IP. Truy cập qua SSM Session Manager.\nBước 1: Truy cập EC2 qua Session Manager EC2 instance đã được tạo trong Private Subnet và không có Public IP. Sử dụng AWS Systems Manager Session Manager để truy cập.\nCách 1: AWS Console Mở AWS Console → EC2 → Instances Chọn instance arc-dev-app-server Click Connect → Session Manager → Connect Cách 2: AWS CLI # Lấy Instance ID từ Terraform output INSTANCE_ID=$(terraform -chdir=terraform output -raw ec2_instance_id) # Kết nối qua SSM aws ssm start-session --target $INSTANCE_ID --region ap-southeast-1 ⚠️ Yêu cầu: Cài đặt Session Manager Plugin\nBước 2: Kiểm tra Services đã chạy EC2 đã được setup tự động qua user_data script khi Terraform tạo instance. Kiểm tra các services:\n# Chuyển sang ec2-user sudo su - ec2-user # Kiểm tra Docker containers docker ps Bạn sẽ thấy 2 containers đang chạy:\napp-fastapi-1 - FastAPI server (port 8000) app-qdrant-1 - Qdrant vector database (port 6333) # Kiểm tra Qdrant curl http://localhost:6333/collections # Kiểm tra FastAPI curl http://localhost:8000/health Bước 3: Deploy Backend Code Backend code sẽ được deploy qua CI/CD Pipeline (CodePipeline → CodeBuild → CodeDeploy). Tuy nhiên, để test nhanh, bạn có thể deploy thủ công:\ncd /home/ec2-user # Clone repository git clone https://github.com/CrystalJohn/ARC-project.git cd ARC-project/backend # Stop containers cũ cd /home/ec2-user/app docker-compose down # Copy backend code cp -r /home/ec2-user/ARC-project/backend/* /home/ec2-user/app/ # Start với code mới docker-compose up -d --build Bước 4: Cấu hình Environment Variables Tạo file .env với các giá trị từ Terraform outputs:\ncd /home/ec2-user/app # Lấy values từ Terraform outputs (chạy trên máy local) # terraform -chdir=terraform output cat \u0026gt; .env \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; # AWS Configuration AWS_REGION=ap-southeast-1 # S3 S3_BUCKET_NAME=arc-documents-\u0026lt;account-id\u0026gt; # DynamoDB DYNAMODB_TABLE_NAME=arc-dev-documents # SQS SQS_QUEUE_URL=https://sqs.ap-southeast-1.amazonaws.com/\u0026lt;account-id\u0026gt;/arc-dev-document-queue # Qdrant (local container) QDRANT_HOST=qdrant QDRANT_PORT=6333 # Cognito COGNITO_USER_POOL_ID=ap-southeast-1_xxxxx COGNITO_CLIENT_ID=xxxxx # Bedrock BEDROCK_MODEL_ID=anthropic.claude-3-5-sonnet-20241022-v2:0 EMBEDDING_MODEL_ID=amazon.titan-embed-text-v2:0 EOF 💡 Tip: Thay \u0026lt;account-id\u0026gt; và các giá trị xxxxx bằng outputs thực tế từ Terraform.\nBước 5: Restart Services # Restart để load .env mới docker-compose down docker-compose up -d # Kiểm tra logs docker-compose logs -f fastapi Bước 6: Verify qua ALB Backend được expose qua Application Load Balancer. Kiểm tra từ máy local:\n# Lấy ALB DNS từ Terraform output ALB_DNS=$(terraform -chdir=terraform output -raw alb_dns_name) # Test health endpoint curl http://$ALB_DNS/health # {\u0026#34;status\u0026#34;:\u0026#34;healthy\u0026#34;} Bước 7: Kiểm tra Qdrant Collection # Trên EC2 curl http://localhost:6333/collections # Tạo collection cho documents (nếu chưa có) curl -X PUT http://localhost:6333/collections/documents \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;vectors\u0026#34;: { \u0026#34;size\u0026#34;: 1024, \u0026#34;distance\u0026#34;: \u0026#34;Cosine\u0026#34; } }\u0026#39; 💡 Note: Vector size 1024 tương ứng với Amazon Titan Embeddings v2.\nChecklist Truy cập EC2 qua Session Manager thành công Docker containers đang chạy (fastapi, qdrant) File .env đã được cấu hình Health check qua ALB thành công Qdrant collection đã được tạo Troubleshooting Không thể kết nối Session Manager # Kiểm tra SSM Agent trên EC2 sudo systemctl status amazon-ssm-agent # Kiểm tra IAM Role có policy AmazonSSMManagedInstanceCore Container không start # Xem logs docker-compose logs # Kiểm tra disk space df -h ALB health check fail # Kiểm tra Security Group cho phép port 8000 từ ALB # Kiểm tra FastAPI đang listen trên 0.0.0.0:8000 docker-compose logs fastapi "},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/5-workshop/8-idp-pipeline/","title":"Thiết lập IDP Pipeline","tags":[],"description":"","content":"Trong phần này, bạn sẽ setup SQS Worker để xử lý documents qua IDP (Intelligent Document Processing) pipeline.\nIDP Flow Upload → S3 → DynamoDB (UPLOADED) → SQS ↓ EC2 Worker ↓ PyPDF2 (digital) / Textract (scanned) ↓ Chunk Text (1000 tokens) ↓ Cohere Embed Multilingual v3 (Bedrock) ↓ Qdrant (store vectors) ↓ DynamoDB (EMBEDDING_DONE) 💡 Note: Worker sử dụng PyPDF2 cho PDF digital (text-based) và Textract cho PDF scanned (image-based).\nDocument States Status Description UPLOADED File đã upload, đang chờ xử lý IDP_RUNNING Worker đang xử lý TEXTRACT_DONE OCR hoàn tất (chỉ cho scanned PDF) EMBEDDING_DONE Hoàn tất, sẵn sàng sử dụng FAILED Có lỗi xảy ra Bước 1: Truy cập EC2 qua Session Manager # Lấy Instance ID INSTANCE_ID=$(terraform -chdir=terraform output -raw ec2_instance_id) # Kết nối aws ssm start-session --target $INSTANCE_ID --region ap-southeast-1 Sau khi kết nối:\nsudo su - ec2-user cd /home/ec2-user/backend 💡 Note: Trên EC2 có 2 folders:\napp/ - Boilerplate từ user_data script backend/ - Code thực tế được deploy qua CI/CD (chứa run_worker.py) Bước 2: Kiểm tra Worker Code Worker code nằm trong backend/run_worker.py. Kiểm tra file đã có:\nls -la # Phải có: run_worker.py, app/, requirements.txt Bước 3: Cấu hình Environment Đảm bảo file .env có đầy đủ các biến (trong folder backend/):\ncd /home/ec2-user/backend cat .env Các biến quan trọng cho IDP:\nSQS_QUEUE_URL=https://sqs.ap-southeast-1.amazonaws.com/\u0026lt;account\u0026gt;/arc-dev-document-queue S3_BUCKET=arc-documents-\u0026lt;account\u0026gt; QDRANT_HOST=localhost QDRANT_PORT=6333 AWS_REGION=ap-southeast-1 Bước 4: Start Worker Option A: Chạy trực tiếp (để debug) # Activate virtual environment (nếu có) source venv/bin/activate # Chạy worker python run_worker.py Worker sẽ hiển thị:\n============================================================ IDP Pipeline - SQS Worker ============================================================ Queue URL: https://sqs.ap-southeast-1.amazonaws.com/xxx/arc-dev-document-queue Bucket: arc-documents-xxx Region: ap-southeast-1 Qdrant: localhost:6333 ------------------------------------------------------------ Processing indefinitely (Ctrl+C to stop)... Option B: Chạy trong background với nohup nohup python run_worker.py \u0026gt; worker.log 2\u0026gt;\u0026amp;1 \u0026amp; # Kiểm tra process ps aux | grep run_worker # Xem logs tail -f worker.log Option C: Chạy trong Docker (recommended) # Thêm worker vào docker-compose.yml docker-compose up -d worker Bước 5: Test IDP Pipeline 5.1 Upload test file lên S3 # Từ máy local aws s3 cp test-sample.pdf s3://arc-documents-\u0026lt;account\u0026gt;/uploads/test-001.pdf 5.2 Tạo record trong DynamoDB aws dynamodb put-item \\ --table-name arc-dev-documents \\ --item \u0026#39;{ \u0026#34;doc_id\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;test-001\u0026#34;}, \u0026#34;sk\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;METADATA\u0026#34;}, \u0026#34;filename\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;test-sample.pdf\u0026#34;}, \u0026#34;s3_key\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;uploads/test-001.pdf\u0026#34;}, \u0026#34;status\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;UPLOADED\u0026#34;}, \u0026#34;uploaded_at\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;\u0026#39;$(date -u +%Y-%m-%dT%H:%M:%SZ)\u0026#39;\u0026#34;} }\u0026#39; 5.3 Gửi message vào SQS aws sqs send-message \\ --queue-url https://sqs.ap-southeast-1.amazonaws.com/\u0026lt;account\u0026gt;/arc-dev-document-queue \\ --message-body \u0026#39;{ \u0026#34;doc_id\u0026#34;: \u0026#34;test-001\u0026#34;, \u0026#34;s3_key\u0026#34;: \u0026#34;uploads/test-001.pdf\u0026#34;, \u0026#34;filename\u0026#34;: \u0026#34;test-sample.pdf\u0026#34; }\u0026#39; Bước 6: Monitor Processing Xem logs của worker:\n# Nếu chạy trực tiếp # Logs hiển thị trên terminal # Nếu chạy background tail -f worker.log Logs thành công sẽ như sau:\n2024-01-15 10:30:00 - INFO - Received message for doc_id: test-001 2024-01-15 10:30:01 - INFO - Downloading from S3: uploads/test-001.pdf 2024-01-15 10:30:02 - INFO - Extracting text with PyPDF2... 2024-01-15 10:30:03 - INFO - Created 8 chunks from document 2024-01-15 10:30:05 - INFO - Generating embeddings with Cohere... 2024-01-15 10:30:10 - INFO - Stored 8 vectors for test-001 2024-01-15 10:30:10 - INFO - Updated status: EMBEDDING_DONE 2024-01-15 10:30:10 - INFO - Document test-001 processed successfully Bước 7: Verify Processing 7.1 Kiểm tra DynamoDB aws dynamodb get-item \\ --table-name arc-dev-documents \\ --key \u0026#39;{\u0026#34;doc_id\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;test-001\u0026#34;},\u0026#34;sk\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;METADATA\u0026#34;}}\u0026#39; \\ --query \u0026#39;Item.{status:status.S,chunks:chunk_count.N}\u0026#39; Expected output:\n{ \u0026#34;status\u0026#34;: \u0026#34;EMBEDDING_DONE\u0026#34;, \u0026#34;chunks\u0026#34;: \u0026#34;8\u0026#34; } 7.2 Kiểm tra Qdrant # Trên EC2 curl -s http://localhost:6333/collections/arc_documents/points/count | jq Expected output:\n{ \u0026#34;result\u0026#34;: { \u0026#34;count\u0026#34;: 8 } } Xử lý Lỗi Vấn đề Nguyên nhân Giải pháp Worker không nhận message SQS URL sai Kiểm tra .env Bedrock timeout Rate limit Tăng retry delay Qdrant connection refused Container chưa start docker-compose up -d qdrant FAILED status Xem error_message trong DynamoDB Fix và retry Retry Failed Document # Cập nhật status về UPLOADED để retry aws dynamodb update-item \\ --table-name arc-dev-documents \\ --key \u0026#39;{\u0026#34;doc_id\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;test-001\u0026#34;},\u0026#34;sk\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;METADATA\u0026#34;}}\u0026#39; \\ --update-expression \u0026#34;SET #s = :s\u0026#34; \\ --expression-attribute-names \u0026#39;{\u0026#34;#s\u0026#34;:\u0026#34;status\u0026#34;}\u0026#39; \\ --expression-attribute-values \u0026#39;{\u0026#34;:s\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;UPLOADED\u0026#34;}}\u0026#39; # Gửi lại message vào SQS aws sqs send-message \\ --queue-url $SQS_QUEUE_URL \\ --message-body \u0026#39;{\u0026#34;doc_id\u0026#34;:\u0026#34;test-001\u0026#34;,\u0026#34;s3_key\u0026#34;:\u0026#34;uploads/test-001.pdf\u0026#34;,\u0026#34;filename\u0026#34;:\u0026#34;test-sample.pdf\u0026#34;}\u0026#39; Checklist Truy cập EC2 qua Session Manager Worker code có sẵn Environment variables configured Worker đang chạy Test document uploaded to S3 SQS message sent Worker processed document (logs) Status = EMBEDDING_DONE trong DynamoDB Vectors stored trong Qdrant "},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/5-workshop/9-frontend/","title":"Thiết lập Frontend","tags":[],"description":"","content":"Thiết lập Frontend Cấu hình và deploy Frontend React application với AWS Amplify.\nBước 1: Lấy Terraform Outputs cd terraform terraform output Ghi lại: cognito_user_pool_id, cognito_client_id, alb_dns_name\nBước 2: Cấu hình Environment cd ARC-project cp .env.example .env Chỉnh sửa .env:\nVITE_AWS_REGION=ap-southeast-1 VITE_COGNITO_POOL_ID=ap-southeast-1_xxxxxxx VITE_COGNITO_CLIENT_ID=xxxxxxxxxxxxxxxxxxxxxxxxxx VITE_API_URL=http://arc-chatbot-dev-alb-xxxxx.ap-southeast-1.elb.amazonaws.com Bước 3: Install \u0026amp; Test Local npm install npm run dev Mở http://localhost:5173\nBước 4: Build \u0026amp; Deploy npm run build Push code lên GitHub, Amplify sẽ tự động deploy:\ngit add . git commit -m \u0026#34;Update frontend config\u0026#34; git push origin main 💡 Amplify app đã được tạo qua Terraform và connected với GitHub.\nBước 5: Cập nhật Cognito Callback URLs Sau khi có Amplify URL:\naws cognito-idp update-user-pool-client \\ --user-pool-id ap-southeast-1_xxxxxxx \\ --client-id xxxxxxxxxx \\ --callback-urls \u0026#34;http://localhost:5173\u0026#34; \u0026#34;https://main.xxxxx.amplifyapp.com\u0026#34; \\ --logout-urls \u0026#34;http://localhost:5173\u0026#34; \u0026#34;https://main.xxxxx.amplifyapp.com\u0026#34; Bước 6: Tạo Test Users # Admin user aws cognito-idp admin-create-user \\ --user-pool-id ap-southeast-1_xxxxxxx \\ --username admin@example.com \\ --user-attributes Name=email,Value=admin@example.com \\ --temporary-password \u0026#34;TempPass123!\u0026#34; aws cognito-idp admin-add-user-to-group \\ --user-pool-id ap-southeast-1_xxxxxxx \\ --username admin@example.com \\ --group-name admin Xử lý Lỗi Lỗi Giải pháp CORS error Kiểm tra FastAPI CORS config \u0026ldquo;User pool does not exist\u0026rdquo; Kiểm tra VITE_COGNITO_POOL_ID Build failed Kiểm tra Amplify environment variables Checklist .env đã cấu hình Local dev server chạy được Amplify deploy thành công Cognito callback URLs đã cập nhật Login/Register hoạt động "},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/5-workshop/10-using-chatbot/","title":"Sử dụng Chatbot","tags":[],"description":"","content":"Hướng dẫn sử dụng ARC Chatbot để tìm kiếm thông tin từ tài liệu nghiên cứu.\nTruy cập Local: http://localhost:5173 Production: Amplify URL từ bước trước Bước 1: Đăng nhập Nhập email và password Click Login Redirect đến Chat page Bước 2: Giao diện Chat Sau khi đăng nhập, bạn sẽ thấy:\nSidebar với menu Chat, History Header với user info và dark mode toggle Chat area với welcome message Bước 3: Đặt câu hỏi Nhập câu hỏi vào input box và nhấn Enter hoặc click Send.\nCâu hỏi tốt Loại Ví dụ Định nghĩa \u0026ldquo;What is a stack data structure?\u0026rdquo; So sánh \u0026ldquo;Compare stack and queue\u0026rdquo; Giải thích \u0026ldquo;Explain binary search algorithm\u0026rdquo; Tránh ❌ Quá chung: \u0026ldquo;Tell me about programming\u0026rdquo; ❌ Ngoài tài liệu: \u0026ldquo;What\u0026rsquo;s the weather today?\u0026rdquo; Bước 4: Citations (Trích dẫn) Mỗi câu trả lời có citations hiển thị nguồn tài liệu:\n📚 Sources: [1] data-structures.pdf - Page 12 - Score: 85% [2] algorithms.pdf - Page 45 - Score: 72% Click vào citation để xem chi tiết document.\nField Mô tả [1], [2] Số thứ tự citation Filename Tên file PDF Page Số trang Score Độ liên quan (%) Bước 5: Conversation History Click History trong sidebar Xem danh sách các cuộc hội thoại trước Click vào conversation để load lại Click trash icon để xóa Bước 6: New Chat Click New Chat trong sidebar để bắt đầu cuộc hội thoại mới.\nFeatures Feature Mô tả Streaming Response hiển thị từng phần Markdown Hỗ trợ code blocks, lists, headers Dark Mode Toggle trong header History Lưu và load lại conversations Checklist Đăng nhập thành công Gửi query và nhận response Citations hiển thị đúng Click citation xem document History hoạt động New Chat hoạt động "},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/5-workshop/11-admin-dashboard/","title":"Sử dụng Admin Dashboard","tags":[],"description":"","content":"Sử dụng Admin Dashboard Hướng dẫn sử dụng Admin Dashboard để quản lý documents.\nTruy cập URL: http://localhost:5173/admin (hoặc Amplify URL) Yêu cầu: Tài khoản thuộc group admin Bước 1: Đăng nhập Admin Đăng nhập với tài khoản admin (đã tạo ở bước trước).\nBước 2: Dashboard Overview Sau khi đăng nhập, bạn sẽ thấy:\nUpload section (drag \u0026amp; drop) Documents table với pagination Status filter và auto-refresh Bước 3: Upload Tài liệu 3.1. Chọn file Drag \u0026amp; drop PDF files vào vùng upload Hoặc click Browse Files để chọn 3.2. Upload Progress Mỗi file hiển thị progress bar và status:\nuploading - Đang upload success - Upload thành công error - Upload thất bại Bước 4: Document Status Sau khi upload, document sẽ được xử lý qua IDP pipeline:\nStatus Mô tả Thời gian UPLOADED Chờ xử lý - IDP_RUNNING Đang xử lý 1-5 phút EMBEDDING_DONE Sẵn sàng - FAILED Lỗi - 💡 Tip: Bật Auto-refresh (5s) để tự động cập nhật status.\nBước 5: Quản lý Documents Filter theo Status Sử dụng dropdown Status để lọc:\nAll Uploaded Processing Done Failed Pagination Documents được phân trang (5 items/page). Sử dụng pagination controls ở footer.\nView Document Click icon 👁️ để xem chi tiết document.\nDelete Document Click icon 🗑️ để xóa document.\n⚠️ Warning: Xóa document sẽ xóa khỏi S3, DynamoDB và Qdrant.\nBước 6: Processing History Click Processing History link để xem lịch sử xử lý documents.\nXử lý Lỗi Vấn đề Giải pháp Upload failed Kiểm tra file size (\u0026lt;50MB), format (PDF only) Document stuck in IDP_RUNNING Kiểm tra worker logs trên EC2 Document FAILED Xem error message trong Processing History Checklist Đăng nhập admin dashboard Upload document thành công Document processed (EMBEDDING_DONE) Filter/pagination hoạt động Auto-refresh hoạt động "},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/5-workshop/12-cleanup/","title":"Dọn dẹp Tài nguyên","tags":[],"description":"","content":"Dọn dẹp Tài nguyên Sau khi hoàn thành workshop, dọn dẹp AWS resources để tránh phát sinh chi phí.\n⚠️ Cảnh báo: Các bước này sẽ XÓA VĨNH VIỄN tất cả data và resources!\nThứ tự Dọn dẹp Stop services trên EC2 Empty S3 buckets Terraform destroy Verify cleanup Bước 1: Stop Services trên EC2 Kết nối EC2 qua Session Manager:\nINSTANCE_ID=$(terraform -chdir=terraform output -raw ec2_instance_id) aws ssm start-session --target $INSTANCE_ID --region ap-southeast-1 Stop Docker containers:\nsudo su - ec2-user cd /home/ec2-user/app # Stop containers docker-compose down # Remove volumes docker volume rm app_qdrant_storage Bước 2: Empty S3 Buckets S3 buckets phải empty trước khi Terraform destroy:\n# Lấy bucket name từ Terraform output BUCKET=$(terraform -chdir=terraform output -raw s3_bucket_name) # Empty bucket aws s3 rm s3://$BUCKET --recursive # Hoặc force delete aws s3 rb s3://$BUCKET --force Bước 3: Terraform Destroy cd terraform terraform plan -destroy terraform destroy Nhập yes khi được hỏi. Quá trình này mất khoảng 10-15 phút.\nBước 4: Manual Cleanup (nếu cần) Nếu còn resources chưa bị xóa:\n# CloudWatch Log Groups aws logs describe-log-groups --log-group-name-prefix /aws/arc | jq -r \u0026#39;.logGroups[].logGroupName\u0026#39; | xargs -I {} aws logs delete-log-group --log-group-name {} # EC2 Key Pair (nếu tạo manual) aws ec2 delete-key-pair --key-name arc-keypair # Amplify App (nếu tạo manual) aws amplify list-apps | jq -r \u0026#39;.apps[] | select(.name | contains(\u0026#34;arc\u0026#34;)) | .appId\u0026#39; | xargs -I {} aws amplify delete-app --app-id {} Bước 5: Verify Cleanup # Check EC2 aws ec2 describe-instances --filters \u0026#34;Name=tag:Name,Values=*arc*\u0026#34; --query \u0026#39;Reservations[].Instances[].InstanceId\u0026#39; # Check S3 aws s3 ls | grep arc # Check DynamoDB aws dynamodb list-tables --query \u0026#39;TableNames[?contains(@, `arc`)]\u0026#39; # Check Cognito aws cognito-idp list-user-pools --max-results 20 --query \u0026#39;UserPools[?contains(Name, `arc`)]\u0026#39; Tất cả commands trên không nên trả về kết quả.\nBước 6: Check Costs Mở AWS Billing Dashboard Kiểm tra Bills cho tháng hiện tại Set up Budgets alert cho tương lai Xử lý Lỗi Lỗi Giải pháp DependencyViolation Destroy theo thứ tự: terraform destroy -target=module.amplify trước BucketNotEmpty aws s3 rb s3://bucket-name --force DeleteConflict (IAM) Detach policies trước khi delete role Resource in use Đợi vài phút rồi retry Kết luận Chúc mừng bạn đã hoàn thành workshop Academic Research Chatbot (ARC)! 🎉\nNhững gì bạn đã học: Triển khai RAG chatbot trên AWS Sử dụng Amazon Bedrock (Claude 3.5 Sonnet + Cohere Embed) Xây dựng IDP pipeline với PyPDF2/Textract Vector search với Qdrant Authentication với Cognito Infrastructure as Code với Terraform Tài nguyên bổ sung: AWS Bedrock Documentation Qdrant Documentation FastAPI Documentation Checklist Stop Docker containers trên EC2 Empty S3 buckets Terraform destroy thành công Verify không còn resources Check billing Cảm ơn bạn đã tham gia workshop! 🙏\n"},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://crystaljohn.github.io/fcj-workshop/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]